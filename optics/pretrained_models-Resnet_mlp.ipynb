{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functions import import_imagedata, label_oh_tf, ImageProcessor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from torchvision.models import vgg16\n",
    "from torchvision.models import resnet101\n",
    "\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "from fns4wandb import train_log, build_optimizer\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "from fns4wandb import set_lossfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = resnet101(weights=\"IMAGENET1K_V1\")#.eval\n",
    "print(model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize model with the best available weights\n",
    "#model_resnet_featlayers = resnet101(weights=\"IMAGENET1K_V1\").features#.to(device)\n",
    "#model_resnet_featlayers.eval()\n",
    "newmodel = torch.nn.Sequential(*(list(model_resnet.children())[:-1]))\n",
    "newmodel=newmodel.to(device)\n",
    "newmodel = newmodel.eval()\n",
    "#print(newmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize the inference transforms\n",
    "# This does some preprocessing behind the scenes,\n",
    "\n",
    "# 1) Resized of the input to resize_size=[256];\n",
    "# 2) Followed by a central crop of crop_size=[224];\n",
    "\n",
    "# vgg16 and resnet accept input image size of 224×224\n",
    "\n",
    "\n",
    "\n",
    "#print(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create MLP, linear classification, function\n",
    "\n",
    "class Three_Lay_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Three_Lay_MLP, self).__init__()\n",
    "        \n",
    "        self.lins = nn.Sequential(\n",
    "            nn.Linear(2048, 100), #1024x7 and 1024x100. 7, 1024\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(100,11),\n",
    "            nn.Linear(11,11),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.lins(x)\n",
    "        return x\n",
    "        \n",
    "#lin    conv output -> 100\n",
    "#relu    ()\n",
    "#lin    100 -> 100\n",
    "#relu    ()\n",
    "#do     ~0.5\n",
    "#lin    100 -> 11\n",
    "#softmax ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(labels, predictions): #TypeError: Singleton array tensor(3) cannot be considered a valid collection.\n",
    "    #print('l  ',label) #len(11)\n",
    "\n",
    "    labels = [np.argmax(label.cpu().detach().numpy()) for label in labels]\n",
    "    predictions = [np.argmax(prediction.cpu().detach().numpy()) for prediction in predictions]\n",
    "\n",
    "\n",
    "    avg_f1_score = f1_score(labels, predictions, average='macro')\n",
    "\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return avg_f1_score, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# creating a function for normalizing the feature vector\n",
    "# using a standard scaling (results in mean=0 and standard deviation=1)\n",
    "def scale_feats(feat_vec):\n",
    "  # Scaling the features to the same range of values\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(feat_vec)\n",
    "  scaled_feat_vec = scaler.transform(feat_vec)\n",
    "  print(\"\\n A peek at the scaled dataset features: \\n\"+str(scaled_feat_vec))\n",
    "\n",
    "  return scaled_feat_vec\n",
    "\n",
    "# normalize the feature vector\n",
    "scaled_feats_28 = scale_feats(feats_28)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temi code. week 6. notebook used vgg16 pretrained features, and trained a MLP for classification of beans\n",
    "# this is the method I am following \n",
    "\n",
    "IP = ImageProcessor(device='cpu')\n",
    "\n",
    "# Temi func. get features from passing through images into vgg16 conv/ feature layers.\n",
    "# creating a function to get features learnt in the pretrained VGG16\n",
    "# extracting these features for our own list of images\n",
    "def get_img_feats(img_path): \n",
    "    #print(img_path)\n",
    "    img = cv2.imread(img_path) #\n",
    "    #print(img)\n",
    "    img = IP.blank_padding(img, (224,224))\n",
    "    img = IP.to_tensor(img).to(device)\n",
    "    #print('image shape post read and pad: \\n ',img.shape)\n",
    "    # Step 3: Apply inference preprocessing transforms\n",
    "    #img = preprocess(img).unsqueeze(0) # preprocess is the model with weights\n",
    "    #img = preprocess(img)#.unsqueeze(0)\n",
    "\n",
    "    # Step 4: Use the model and print the predicted category\n",
    "    #print('get_img_feats img', img.shape) \n",
    "    #auto_feats = auto_feats.detach().numpy() \n",
    "    #Tensor.cpu() to copy the tensor to host memory first\n",
    "    auto_feats = newmodel(img).squeeze(0)\n",
    "    \n",
    "    \n",
    "    #print('get_img_feats auto_feats', auto_feats.shape)\n",
    "    \n",
    "    # AttributeError: 'builtin_function_or_method' object has no attribute 'detach' --- current error\n",
    "    #AttributeError: 'numpy.ndarray' object has no attribute 'to'\n",
    "    auto_feats = auto_feats.cpu().detach().numpy()\n",
    "    \n",
    "    #print('get_img_feats auto_feats detached', auto_feats.shape)\n",
    "    auto_feats = np.mean(auto_feats, axis=1,keepdims=False) #, keepdims=False\n",
    "    #print('get_img_feats auto_feats np mean', auto_feats.shape)\n",
    "    #print('get_img_feats autofeats', auto_feats)\n",
    "    #print('auto_feat: \\n ', auto_feats)\n",
    "    auto_feats= torch.tensor(auto_feats, dtype=torch.float32)\n",
    "    return auto_feats.to(device)\n",
    "\n",
    "\n",
    "# class to manage data and turn imgs into vgg16 features\n",
    "\n",
    "\"\"\"class AutoFeature(): # file_path, number\n",
    "    def __init__(self, img_files, labels):\n",
    "        self.img_files = img_files\n",
    "        self.label = label_oh_tf(labels, device='cpu', num_classes=11)\n",
    "        \n",
    "        #self.labels=[label_oh_tf(label, device='cpu', num_classes=11) for label in labels]\n",
    "        #self.labels= [int(label) for label in labels]\n",
    "        #self.labels = torch.tensor(labels, dtype=torch.long) # tensofy the labels\n",
    "        #self.labels = label_oh_tf(labels, device, 11)\n",
    "    #def __len__(self):\n",
    "    #    return len(self.labels)\n",
    "    def __getitem__(self):\n",
    "        #given an index, will return items within that index range\n",
    "        # extracting features using pretrained model\n",
    "        feats = get_img_feats(self.img_files) #[idx]\n",
    "        \n",
    "        feats_tensor = torch.tensor(feats, dtype=torch.float32)\n",
    "        #print(type(self.labels))\n",
    "        #print(self.labels[3])\n",
    "        return feats_tensor, self.label #[idx]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get len of \n",
    "\n",
    "file_path = r'/its/home/nn268/optics/AugmentedDS_IDSW/'\n",
    "random_seed =1\n",
    "img_len = len(os.listdir(file_path))\n",
    "\n",
    "ids = np.arange(0, img_len)\n",
    "#print(ids[4])\n",
    "\n",
    "\n",
    "train_ids, test_ids = train_test_split(ids, test_size=0.2, train_size=0.8,\n",
    "                                 random_state=random_seed, shuffle=True)\n",
    "train_ids, val_ids = train_test_split(train_ids, test_size=0.1, train_size=0.8,\n",
    "                                 random_state=random_seed, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title = f'IDSW_RESNET_MLP_hp_80_112023'\n",
    "save_dict = {'Run' : title,\n",
    "            'Current_Epoch': 0}\n",
    "\n",
    "save_location = r'pickles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: edhshryy\n",
      "Sweep URL: https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/sweeps/edhshryy\n"
     ]
    }
   ],
   "source": [
    "run_title = \"IDSW_RESNET_MLP_hp_80_112023\"\n",
    "\n",
    "config = {\n",
    "    'method': 'random',\n",
    "    'metric':{\n",
    "        'goal': 'minimize',\n",
    "        'name': 'val_loss'},\n",
    "    'parameters': {\n",
    "        #'dropout':{\n",
    "        #    'values': [0.5, 0.4, 0.3]\n",
    "        #},\n",
    "        'epochs':{\n",
    "            'value': 100\n",
    "        },\n",
    "        'first_lin_lay':{\n",
    "            'values':[248832]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam']\n",
    "        },\n",
    "            'learning_rate': {\n",
    "                # a flat distribution between 0 and 0.1\n",
    "                'distribution': 'log_uniform_values',\n",
    "                'min': 1e-7,\n",
    "                'max': 1e-2\n",
    "            },\n",
    "        'loss_fn': {\n",
    "            'values': ['CrossEntropy', 'MSE'] #'MSE', \n",
    "        },\n",
    "        'data_set':{\n",
    "            'values':['Augmented']\n",
    "        },\n",
    "            'scheduler': {\n",
    "            'values': [0.2, 0.3, 0.4, 0.6]\n",
    "        },\n",
    "        'ks': {\n",
    "            'values': [(3,5)]\n",
    "        },\n",
    "        'channels':{\n",
    "            'values': [3]\n",
    "        },\n",
    "        'num_classes': {\n",
    "            'values': [11]\n",
    "        },\n",
    "        'model_name' : {'values': ['resnet_mlp']},\n",
    "        'channels' : {'values': [3]},\n",
    "        'image_path': {\n",
    "            'values': [r'/its/home/nn268/optics/AugmentedDS_IDSW/']\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "\n",
    "sweep_id = wandb.sweep(config, project=f\"{run_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "from fns4wandb import train_log, build_optimizer\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# split data intro train, val, test\n",
    "\n",
    "# instancing the autofeature class\n",
    "# creating an object for train, val test\n",
    "\n",
    "#train_set = AutoFeature(x[train_ids], y[train_ids])\n",
    "#val_set = AutoFeature(x[val_ids], y[val_ids])\n",
    "#test_set = AutoFeature(x[test_ids], y[test_ids])\n",
    "\n",
    "#print('train set 0: \\n',train_set[0])\n",
    "#print('what is train set?', type(train_set))\n",
    "#print('train set len', len(train_set))\n",
    "\n",
    "\n",
    "\n",
    "#x_test, y_test = test_set\n",
    "#x_test = [i[0] for i in test_set]\n",
    "#y_test = [i[1] for i in test_set]\n",
    "\n",
    "#train_dl = DataLoader(train_set, batch_size=1)\n",
    "#val_dl = DataLoader(val_set, batch_size=1)\n",
    "#test_dl = DataLoader(test_set, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"config = dict(\n",
    "    epochs= 2, #80, #30, \n",
    "    learning_rate =1e-5,\n",
    "    architecture ='CNN',\n",
    "    optimizer= 'adam',\n",
    "    weight_decay= 4e-5,\n",
    "    ks = 3,\n",
    "    scheduler=0.2,\n",
    "    f_lin_lay = 7168 #1024*7 = 7168\n",
    ")\n",
    "\"\"\"\n",
    "# pass in ids\n",
    "# create class instance for single ids\n",
    "# index that class to get img feature and label FOR THAT ids.\n",
    "# per epoch\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_ids, val_ids, config, best_acc=0): #train_dl, val_dl, \n",
    "    #wandb.watch(model, loss_fn, log='all', log_freq=10)\n",
    "    \n",
    "    loss_fn = set_lossfn(config.loss_fn) # ****\n",
    "    \n",
    "    lr = config['learning_rate'] #1e-5 #config.learning_rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)#build_optimizer(model, optimizer=torch.optim.Adam(model.parameters(), lr=lr))#config.optimizer, config.learning_rate, config.weight_decay)\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=config['scheduler'], last_epoch=-1) #gamma=config.scheduler, last_epoch=-1)\n",
    "    \n",
    "    x, y = import_imagedata(file_path)\n",
    "    #print(x[1].shape)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "    \n",
    "    \n",
    "    total_epochs = 0\n",
    "    \n",
    "    for epoch in tqdm(range(config['epochs'])): #config.epochs)):\n",
    "        print('Epoch:   ', epoch)\n",
    "        v_correct = 0\n",
    "        t_correct = 0\n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_model = deepcopy(model)\n",
    "        #train_ids = random.shuffle(train_ids)\n",
    "        #print(type(train_ids))\n",
    "        print('training...')\n",
    "        for idx in train_ids: \n",
    "            model.train()\n",
    "            \n",
    "            x_train = get_img_feats(x[idx])\n",
    "            tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "            tensor = tensor.flatten()\n",
    "\n",
    "            train_prediction = model.forward(tensor)\n",
    "            train_label = label_oh_tf(y[idx], device, num_classes=11)\n",
    "            \n",
    "            t_loss = loss_fn(train_prediction, train_label)\n",
    "            if train_prediction.argmax() == train_label.argmax():\n",
    "                t_correct+=1\n",
    "   \n",
    "            t_loss_list.append(t_loss)\n",
    "            t_predict_list.append(train_prediction)\n",
    "            \n",
    "            train_acc = t_correct/len(train_ids)\n",
    "            t_label_list.append(train_label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            t_loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            \n",
    "        print('validation... ')\n",
    "        for idx in val_ids:\n",
    "            model.eval()\n",
    "            \n",
    "            x_val = get_img_feats(x[idx])\n",
    " \n",
    "            tensor = torch.tensor(x_val, dtype=torch.float32)\n",
    "            tensor = tensor.flatten()\n",
    "            y_val = label_oh_tf(y[idx], device, num_classes=11)\n",
    "\n",
    "            val_prediction = model.forward(tensor)\n",
    "            #print('val prediction \\n     ',val_prediction.argmax())\n",
    "            v_loss = loss_fn(val_prediction, y_val)\n",
    "            \n",
    "            if val_prediction.argmax() == y_val.argmax():\n",
    "                v_correct +=1\n",
    "            \n",
    "            val_acc = (v_correct / len(val_ids))\n",
    "            v_loss_list.append(v_loss)\n",
    "            v_predict_list.append(val_prediction)\n",
    "            #print('val predict list \\n       ',v_predict_list)\n",
    "            v_label_list.append(y_val)\n",
    "            #print('val label list \\n      ',v_label_list)\n",
    "            \n",
    "        print('Val Acc:   ',val_acc) \n",
    "        \n",
    "            #print('val accuracy:     ', v_correct/len(val_ids))\n",
    "            #val_avg_f1_score, val_acc = metrics(y_val, val_prediction)\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model = deepcopy(model)\n",
    "            \n",
    "            save_dict['Current_Epoch'] += config['epochs']\n",
    "            save_dict['model.state_dict'] = model.state_dict()\n",
    "            save_dict['training_samples'] = len(train_ids)\n",
    "            save_dict['validation_samples'] = len(val_ids)\n",
    "            save_dict['t_loss_list'] = t_loss_list\n",
    "            save_dict['v_loss_list'] = v_loss_list\n",
    "            save_dict['t_predict_list'] = t_predict_list  \n",
    "            save_dict['v_predict_list'] = v_predict_list\n",
    "            save_dict['t_accuracy_list'] = t_accuracy_list  #\n",
    "            save_dict['v_accuracy_list'] = v_accuracy_list \n",
    "            save_dict['t_labels'] = t_label_list\n",
    "            save_dict['v_labels'] = v_label_list\n",
    "            title = save_dict['Run']\n",
    "            with open(f'{save_location}{title}.pkl', 'wb+') as f:\n",
    "                pickle.dump(save_dict, f)\n",
    "            \n",
    "            \n",
    "            print('improvment in metrics. model saved')\n",
    "        \n",
    "        if (epoch+1)%2==0:\n",
    "            print('updating wandb')\n",
    "            train_log(t_loss, v_loss, epoch)\n",
    "            wandb.log({'train_accuracy_%': train_acc, 'epoch':epoch})\n",
    "            wandb.log({'val_accuracy_%': val_acc, 'epoch':epoch})\n",
    "            \n",
    "    model = best_model\n",
    "\n",
    "    return model, save_dict\n",
    "\n",
    "\n",
    "def pipeline(config): \n",
    "    \n",
    "    loss_list=[]\n",
    "    #loss_fn = nn.CrossEntropyLoss()\n",
    "    with wandb.init(project=title, config=config):\n",
    "        config = wandb.config\n",
    "        model = Three_Lay_MLP().to(device)\n",
    "\n",
    "        model, save_dict = train_model(model, train_ids, val_ids, config) #train_dl, val_dl\n",
    "        \n",
    "    return model, save_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qwpr6wzw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchannels: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_set: Augmented\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_lin_lay: 248832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_path: /its/home/nn268/optics/AugmentedDS_IDSW/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tks: [3, 5]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000208212303935189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_fn: MSE\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: resnet_mlp\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_classes: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/its/home/nn268/antvis/optics/wandb/run-20231121_113334-qwpr6wzw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/runs/qwpr6wzw' target=\"_blank\">copper-sweep-1</a></strong> to <a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/sweeps/edhshryy' target=\"_blank\">https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/sweeps/edhshryy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023' target=\"_blank\">https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/sweeps/edhshryy' target=\"_blank\">https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/sweeps/edhshryy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/runs/qwpr6wzw' target=\"_blank\">https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/runs/qwpr6wzw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:qwpr6wzw) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copper-sweep-1</strong> at: <a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/runs/qwpr6wzw' target=\"_blank\">https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/runs/qwpr6wzw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231121_113334-qwpr6wzw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:qwpr6wzw). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/its/home/nn268/antvis/optics/wandb/run-20231121_113338-qwpr6wzw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/runs/qwpr6wzw' target=\"_blank\">copper-sweep-1</a></strong> to <a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/sweeps/edhshryy' target=\"_blank\">https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/sweeps/edhshryy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023' target=\"_blank\">https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/sweeps/edhshryy' target=\"_blank\">https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/sweeps/edhshryy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/runs/qwpr6wzw' target=\"_blank\">https://wandb.ai/antvis/IDSW_RESNET_MLP_hp_80_112023/runs/qwpr6wzw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]<ipython-input-109-e88fb3493d24>:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor = torch.tensor(x_train, dtype=torch.float32)\n",
      "/its/home/nn268/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-e88fb3493d24>:121: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor = torch.tensor(x_val, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [00:47<1:18:09, 47.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improvment in metrics. model saved\n",
      "Epoch:    1\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [01:36<1:19:09, 48.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    2\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [02:27<1:19:47, 49.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    3\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [03:17<1:19:32, 49.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    4\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [04:06<1:18:20, 49.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    5\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [04:54<1:16:47, 49.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    6\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [05:43<1:16:07, 49.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    7\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [06:33<1:15:24, 49.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    8\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [07:23<1:15:05, 49.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    9\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [08:12<1:13:57, 49.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    10\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [09:01<1:13:13, 49.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    11\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [09:51<1:12:27, 49.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    12\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [10:40<1:11:26, 49.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    13\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [11:29<1:10:47, 49.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    14\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [12:18<1:09:33, 49.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    15\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [13:05<1:08:01, 48.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    16\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [13:54<1:07:17, 48.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    17\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [14:45<1:07:25, 49.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    18\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [15:35<1:06:50, 49.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    19\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [16:24<1:06:00, 49.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    20\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [17:14<1:05:10, 49.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    21\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [18:01<1:03:35, 48.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    22\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [18:50<1:02:38, 48.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    23\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [19:39<1:01:56, 48.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    24\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [20:28<1:01:20, 49.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    25\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [21:18<1:00:50, 49.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    26\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [22:08<1:00:01, 49.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    27\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [22:57<59:20, 49.46s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    28\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [23:46<58:06, 49.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    29\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [24:35<57:26, 49.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    30\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [25:24<56:19, 48.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    31\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [26:13<55:32, 49.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    32\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [27:02<54:54, 49.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    33\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [27:52<54:06, 49.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    34\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [28:39<52:40, 48.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    35\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [29:28<51:58, 48.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    36\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [30:21<52:31, 50.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    37\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [31:13<52:22, 50.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    38\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [32:03<51:20, 50.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    39\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [32:53<50:13, 50.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "updating wandb\n",
      "Epoch:    40\n",
      "training...\n",
      "validation... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [35:09<1:14:51, 76.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:    0.09818181818181818\n",
      "Epoch:    41\n",
      "training...\n"
     ]
    }
   ],
   "source": [
    "def tr(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        model, save_dict = pipeline(config)\n",
    "\n",
    "wandb.agent(sweep_id, tr, count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model, save_dict = pipeline(config) #7,168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion(predictions:list, actual:list, title:str):\n",
    "    predict_list = [int(t.argmax()) for t in predictions]\n",
    "    actual = [int(l.argmax()) for l in actual]\n",
    "\n",
    "    actual = np.array(actual)\n",
    "    predict_list = np.array(predict_list)\n",
    "\n",
    "\n",
    "    #FixedLocator locations (3), usually from a call to set_ticks, does not match the number of labels (11).\n",
    "    print(f'\\n     {title}')\n",
    "    train_epoch_matrix = confusion_matrix(actual, predict_list, labels= [0,1,2,3,4,5,6,7,8,9,10])\n",
    "    disp= ConfusionMatrixDisplay(train_epoch_matrix, display_labels=[0,1,2,3,4,5,6,7,8,9,10])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#t_predict = predictions[0]\n",
    "#v_predict = predictions[1]\n",
    "#t_labels = labels[0]\n",
    "#v_labels = labels[1]\n",
    "\n",
    "#print(len(labels))\n",
    "#for label in labels:\n",
    "#    print(label[1])\n",
    "    #t_labels = label[0]\n",
    "    #v_labels = label[1]\n",
    "#print(len(t_labels))\n",
    "#print(len(v_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_predict = save_dict['t_predict_list']\n",
    "t_labels = save_dict['t_labels']\n",
    "\n",
    "v_predict = save_dict['v_predict_list'] # WHY IS THERE NOTHING IN V OREDICT LIST!\n",
    "v_labels = save_dict['v_labels']\n",
    "\n",
    "\n",
    "print(len(v_labels))\n",
    "print(len(v_predict))\n",
    "\n",
    "print(len(t_labels))\n",
    "print(len(t_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(t_predict, t_labels, 'Train Confusion Matrix'+str(save_dict['Current_Epoch']))\n",
    "plot_confusion(v_predict, v_labels, 'Validation Confusion Matrix'+str(save_dict['Current_Epoch']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
