{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4fd19-5a09-4232-bdc4-42bbef0b6802",
   "metadata": {},
   "source": [
    "last updated 11 03 24\n",
    "\n",
    "This notebook is to get the run times for each model on the highets and lowest Resolutions; to estimate an average run time.IG DICITONARY!\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6be64f-3efe-4c20-885c-1333846ffbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364e97a-adf8-4aa3-aadf-a32df7852d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6dbd95-2129-42b5-b70b-ee9f057b24c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg16\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch.Utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import collections\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "from functions import import_imagedata, ImageProcessor, label_oh_tf, IDSWDataSetLoader2\n",
    "from fns4wandb import set_lossfn\n",
    "from architectures import sevennet, smallnet1, smallnet2, smallnet3\n",
    "from architectures import PrintLayer, smallnet3\n",
    "from loop_fns import loop#, loop_batch, test_loop_batch\n",
    "from plotting import learning_curve, accuracy_curve, plot_confusion\n",
    "\n",
    "\n",
    "\n",
    "#import torch.Utils.data.DataLoader as DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6ace79-5b6a-4955-9fd3-52aeaddf0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = torch.cuda.memory_summary(device, abbreviated=False)\n",
    "#Pp = pprint.PrettyPrinter(indent=4)\n",
    "#Pp.pprint(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c1e605-9a3b-48dc-a38e-8a955bd3c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "_save_location = r'/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/7c3l/' #vgg16\n",
    "\n",
    "data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "\n",
    "gitHASH = ' d86ac0b281df66330854cade05a02009c9010f8b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1481ccd-4d87-4c05-84d5-77e29ee981b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaughticalnonsence\u001b[0m (\u001b[33mantvis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49eb7e06-506f-48e6-b28c-8caa7641b11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install datetime\n",
    "\n",
    "d = date.today()\n",
    "#print(str(d), type(str(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87383b",
   "metadata": {},
   "source": [
    "452 144 5/452 *100 = 1%\n",
    "226 72 5/226 *100 = 2%\n",
    "113 36 5/113 *100 = 4% -- 2/113 *100= 1.7% ~ 2%\n",
    "57 18 (56.5,) 5/57 *100 = 8% -- 2/57 *100 = 3.5% ~ 4%. 1/57 = 1.75%\n",
    "29 9 (28.5,) 5/29 *100 = 17% -- 2/29 *100 = 6.89 ~ 7% 1/28 = 3.57 ~ 4%\n",
    "15 5 (14.5, 4.5)\n",
    "8 3 (7.5,2.5)\n",
    "4, 2 (, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ddbb49-828b-4de8-a31c-2a576cd736f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries                                                                                  * * * *   SETTINGS   * * * *\n",
    "\n",
    "date = date.today()\n",
    "\n",
    "model_card_vgg = {'name': 'vgg', 'model': 'vgg16',\n",
    "                  'f_lin_lay':[200704,#200704,     #129024,#4096,  # (1x229376 and 25088x4096)  1x229376 and 25088x4096) 1x229376 and 25088x4096)\n",
    "                             200704,      #(16x64512 and 129024x4096)    (16x200704 and 64512x4096)\n",
    "                             14336,\n",
    "                             3584,\n",
    "                             768,\n",
    "                             4096,\n",
    "                             4096, # (1x7962624 and 248832x100)\n",
    "                            ],\n",
    "                 'idx': 0,\n",
    "                 'dropout':0.2}\n",
    "\n",
    "\n",
    "model_card_7c3l = {'name': '7c3l', 'model': '7c3l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[248832,    # 452 144 # p5\n",
    "                            59904,      # 226 72 # p5\n",
    "                            11264,      # 113 36 # p2\n",
    "                            1536,       # 57 18 # p1\n",
    "                            172032,           # 29 9\n",
    "                            172032,          # 15 5\n",
    "                            172032,         # 8 3\n",
    "                              ], \n",
    "                   'idx': 1,\n",
    "                  'dropout':0.2}\n",
    "\n",
    "\n",
    "\n",
    "model_card_4c3l = {'name': '4c3l', 'model': '4c3l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[539904,    # 452 144 # p5\n",
    "                             141056,    # 226 72 # p5\n",
    "                             304640,     # 113 36 # p2\n",
    "                             9984,      # 57 18 # p1\n",
    "                             2304,      # 29 9\n",
    "                             512,       # 15 5\n",
    "                             256],      # 8 3\n",
    "                  'idx': 2,\n",
    "                  'dropout':0.2}      \n",
    "\n",
    "model_card_3c2l = {'name': '3c2l', 'model': '3c2l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[1069888,    # 452 144 # p5\n",
    "                             274688,     #226 72 # p5\n",
    "                             68096,      # 113 36 # p2\n",
    "                             17280,      # 57 18 # p1\n",
    "                             3840,       # 29 9\n",
    "                             960,        # 15 5\n",
    "                             256],\n",
    "                  'idx': 3,\n",
    "                  'dropout':0.2}       # 8 3\n",
    "\n",
    "model_card_2c2l = {'name': '2c2l', 'model': '2c2l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[1055232 , #1032192,# 16883712,#33767424,    # 452 144 # p5 # (1x33767424 and 1055232x100) (1x5276160 and 15828480x100) 1x33767424 and 5276160x100)\n",
    "                             267264,     #226 72 # p5                   (1x1032192 and 64512x100)\n",
    "                             64512,#   1032192,#64512,      # 113 36 # p2    ### (16x1055232 and 1032192x100) ###  16x1055232 and 1032192x100)\n",
    "                             15552,      # 57 18 # p1\n",
    "                             3072,       # 29 9\n",
    "                             640,        # 15 5\n",
    "                             128],\n",
    "                  'idx': 4,\n",
    "                  'dropout':0.1}       # 8 3\n",
    "\n",
    "resolution_card_452144 = {'resolution':[452,144], 'padding':5, 'index':0}\n",
    "resolution_card_22672 = {'resolution':[226,72], 'padding':5, 'index':1}\n",
    "resolution_card_11336 = {'resolution':[113,36], 'padding':2, 'index':2}\n",
    "resolution_card_5715 = {'resolution':[57,18], 'padding':1, 'index':3}\n",
    "\n",
    "resolution_card_299 = {'resolution':[29,9], 'padding':0, 'index':4} # \n",
    "resolution_card_155 = {'resolution':[15,5], 'padding':0, 'index':5}\n",
    "resolution_card_83 = {'resolution':[8,3], 'padding':0, 'index':6}\n",
    "\n",
    "\n",
    "\n",
    "resolution_cards = [resolution_card_452144, resolution_card_22672, resolution_card_11336, resolution_card_5715, resolution_card_299, resolution_card_155, resolution_card_83]#]#resolution_card_452144, resolution_card_22672, resolution_card_11336, \n",
    "#resolution_cards = [resolution_card_11336]\n",
    "\n",
    "#learning_rate_cards = [5e-5, 6e-5, 8e-5]\n",
    "#learning_rate_cards = [8.21592E-05, 6.62E-05, 6.01E-05, 5.97E-05]\n",
    "#learning_rate_cards=  [0.0001,6e-5, 7e-5, 8e-5]#, 6e-5, 7e-5, 8e-5]\n",
    "learning_rate_cards=  [0.1,0.01, 1e-3,1e-4,1e-5]\n",
    "#wd_cards = [4e-5, 5e-5, 3.00E-05, 2.00E-05]\n",
    "wd_cards =[0] #[2.00E-05]\n",
    "scheduler_cards = [0]#, 0.1, 0.2]\n",
    "\n",
    "seeds = [8,2,6]#,2,3] # 4, 5,6\n",
    "\n",
    "#model_cards =[model_card_vgg, model_card_7c3l, model_card_4c3l, model_card_3c2l, model_card_2c2l]\n",
    "model_cards =[model_card_7c3l]\n",
    "\n",
    "loss_fn_cards = ['MSE','CrossEntropy' ] #,'CrossEntropy' \n",
    "                        \n",
    "config = dict({'parameters': 'parameters for big loop run log lr'})\n",
    "config.update({'model_cards':model_cards})\n",
    "config.update({'resolution_cards':resolution_cards})\n",
    "config.update({'learning_rate_cards':learning_rate_cards})\n",
    "config.update({'wd_cards':wd_cards})\n",
    "config.update({'scheduler_cards':scheduler_cards})\n",
    "config.update({'seeds':seeds})\n",
    "config.update({'loss_fn_cards': loss_fn_cards})\n",
    "\n",
    "\n",
    "config.update({'batch_size': 64})\n",
    "config.update({'epochs': 60})\n",
    "\n",
    "#print(model_card_vgg)\n",
    "#print('')\n",
    "#Pp.pprint(Config) # dictionary of dictionaries of lists and lists of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87dc8393-e7da-43eb-b0e7-b11c4a46c8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def save2csv_nest_dict(nested_dict, file_name, save_location:str):\n",
    "    # flattern nested dictionary\n",
    "    flatterend_dict = {}\n",
    "    for k,v in nested_dict.items():\n",
    "        if isinstance(v, dict):\n",
    "            for nested_key, nested_val in v.items():\n",
    "                flatterend_dict[f\"{k}_{nested_key}\"] = nested_val\n",
    "        else:\n",
    "            flatterend_dict[k] =v\n",
    "    \n",
    "    columns = list(flatterend_dict.keys())\n",
    "    \n",
    "    with open(save_location+str(file_name)+'.csv', \"a+\", newline=\"\") as f:\n",
    "        # using dictwriter\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        # using writeheader function\n",
    "        if f.tell() == 0:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(flatterend_dict)\n",
    "        f.close()\n",
    "\n",
    "# check dictionary values for json and csv\n",
    "\n",
    "def check_obj4np(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: check_obj4np(value) for key, value in obj.items()}\n",
    "    if isinstance(obj,list):\n",
    "        return [check_obj4np(item) for item in obj]\n",
    "    if isinstance(obj,np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# save to json\n",
    "def save2josn_nested_dict(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    with open(save_location+str(file_name)+'.json', 'a+') as f:\n",
    "        f.write(json_obj)\n",
    "        f.close()\n",
    "\n",
    "    \n",
    "#save_location+str(file_name)+'.csv'\n",
    "def save2csv(nested_dict, file_name, save_location:str):\n",
    "    \n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    \n",
    "    columns = list(nested_dict.keys())\n",
    "    path = os.path.join(save_location, file_name +\".csv\")\n",
    "    try:\n",
    "        with open(path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            # using dictwriter\n",
    "            # using writeheader function\n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(nested_dict)\n",
    "            f.close()\n",
    "    except IOError as e:\n",
    "        print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "    except ValueError:\n",
    "              print(\"could not convert to string\")\n",
    "    except:\n",
    "              print(\"unexpected error: \", sys.exc_info()[0])\n",
    "        \n",
    "\n",
    "def save2json(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    #print(nested_dict)\n",
    "    #print(nested_dict.items())\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    #print(json_obj)\n",
    "    path = os.path.join(save_location, file_name+\".json\")\n",
    "    #print(path)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(json_obj)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def read_in_json(file_path, file_name):\n",
    "    path = os.path.join(file_path, 'file_name')\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            #obj = f.read()\n",
    "            dj = json.load(f, object_pairs_hook= collections.OrderedDict) #obj, \n",
    "            #print(dj)\n",
    "    except Exception as e:\n",
    "        print(\"Error decoding Json\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "class Flattern(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flattern, self).__init__()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.flatten()\n",
    "        return x\n",
    "\n",
    "\n",
    "def choose_model(model_name, lin_lay, dropout):\n",
    "\n",
    "    if model_name == '4c3l':\n",
    "        return smallnet1(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '3c2l':\n",
    "        return smallnet2(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks = (3,5), dropout=dropout)\n",
    "    elif model_name == '2c2l':\n",
    "        return smallnet3(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '7c3l':\n",
    "        return sevennet(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == 'vgg16':\n",
    "        #model_vgg16 = vgg16(weights=\"IMAGENET1K_V1\")\n",
    "        #vgg_feats = model_vgg16.features\n",
    "        #vgg_classifier = model_vgg16.classifier\n",
    "        #vgg_classifier.pop(6)\n",
    "\n",
    "        #vgg = nn.Sequential(\n",
    "        #    vgg_feats,\n",
    "        #    Flattern(),\n",
    "        #    vgg_classifier,\n",
    "        #    nn.Linear(4096,11), # cheanging the output layer\n",
    "        #    nn.Softmax(dim=0),    (1x1032192 and 4096x4096)\n",
    "        #    )\n",
    "        \n",
    "        class VGG16Smaller(nn.Module):\n",
    "            def __init__(self,lin_lay, num_classes=11): #64512\n",
    "                super(VGG16Smaller, self).__init__()\n",
    "                self.layer1 = nn.Sequential(\n",
    "                    nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU())\n",
    "                self.layer2 = nn.Sequential(\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU(), \n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "                self.layer3 = nn.Sequential(\n",
    "                    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(128),\n",
    "                    nn.ReLU())\n",
    "                self.layer4 = nn.Sequential(\n",
    "                    nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "                self.layer5 = nn.Sequential(\n",
    "                    nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(256),\n",
    "                    nn.ReLU())\n",
    "                self.layer6 = nn.Sequential(\n",
    "                    nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(256),\n",
    "                    nn.ReLU())\n",
    "                self.layer7 = nn.Sequential(\n",
    "                    nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "                self.fc = nn.Sequential(\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(lin_lay, 4096), # 1032192 and 4096x4096)\n",
    "                    nn.ReLU())\n",
    "                self.fc1 = nn.Sequential(\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(4096, 4096),\n",
    "                    nn.ReLU())\n",
    "                self.fc2= nn.Sequential(\n",
    "                    nn.Linear(4096, num_classes))\n",
    "                \n",
    "            def forward(self, x):\n",
    "                out = self.layer1(x)\n",
    "                out = self.layer2(out)\n",
    "                out = self.layer3(out)\n",
    "                out = self.layer4(out)\n",
    "                out = self.layer5(out)\n",
    "                out = self.layer6(out)\n",
    "                out = self.layer7(out)\n",
    "                PrintLayer()\n",
    "                out = out.reshape(out.size(0), -1)\n",
    "                out = out.flatten(start_dim=1)\n",
    "                PrintLayer()\n",
    "                out = self.fc(out)\n",
    "                out = self.fc1(out)\n",
    "                out = self.fc2(out)\n",
    "                out = F.log_softmax(out, dim=1) \n",
    "                return out\n",
    "        vgg = VGG16Smaller(lin_lay)\n",
    "        return vgg\n",
    "    else:\n",
    "        print('Model Name Not Recognised')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_model_sizes_bits(model):\n",
    "    bits = 32\n",
    "    mods = list(model.modules())\n",
    "    sizes = []\n",
    "    total_bits = 0\n",
    "    \n",
    "    for i in range(1,len(mods)):\n",
    "        m = mods[i]\n",
    "        p = list(m.parameters())\n",
    "        for j in range(len(p)):\n",
    "            sizes.append(np.array(p[j].size()))\n",
    "    \n",
    "    for i in range(len(sizes)):\n",
    "        s = sizes[i]\n",
    "        bitz = np.prod(np.array(s))*bits\n",
    "        total_bits += bitz\n",
    "    total_bytes = total_bits/8\n",
    "    total_megabytes = total_bytes/1e+6\n",
    "    total_gigabytes = total_megabytes/1000\n",
    "    print(total_bits, 'bits    ', total_bytes, \"bytes    \", total_megabytes, \"MegaBytes    \", total_gigabytes,\"GigaBytes\") # 148480\n",
    "\n",
    "\n",
    "def ptrblk_fin_mod_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    size_all_gb = size_all_mb/953.674\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))\n",
    "    print('model size: {:.3f}GB'.format(size_all_gb))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "495f38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_batch(model, train, val, loop_run_name, save_dict, lr, loss_fn, epochs, batch_size, optimizer, scheduler_value, device): #train_dl, val_dl, \n",
    "    #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3) \n",
    "    model.train()\n",
    "\n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "    sample = False\n",
    "    \n",
    "    \n",
    "    total_epochs = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        if epoch == 1:\n",
    "            sample = True\n",
    "            random_value = random.randrange(0,batch_size)\n",
    "        else:\n",
    "            random_value = None\n",
    "            sample = False\n",
    "        #print(random_value)\n",
    "\n",
    "        \n",
    "        print('Training...')\n",
    "        #!nvidia-smi\n",
    "        #print(len(train)) #Using a target size \n",
    "\n",
    "        \n",
    "        t_loss, train_prediction, train_targets, t_correct, model, optimizer = loop_batch(model, train, loss_fn, batch_size,sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =optimizer, scheduler= scheduler_value, train =True) #, scheduler =scheduler\n",
    "        print('training..  2')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        t_loss_list.append(t_loss)\n",
    "        [t_predict_list.append(pred.argmax()) for pred in train_prediction]\n",
    "        wandb.log({'t_loss':t_loss})\n",
    "    \n",
    "        train_acc = (t_correct/(len(train)*batch_size)*100) ###\n",
    "        print('train accuracy: ', train_acc )\n",
    "        t_accuracy_list.append(train_acc)\n",
    "        wandb.log({'train_acc':train_acc})\n",
    "        \n",
    "        \n",
    "            \n",
    "        print('validating...')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        v_loss, val_prediction, val_targets, val_correct= loop_batch(model, val, loss_fn, batch_size,sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =None, scheduler= None, train =False)\n",
    "\n",
    "        v_loss_list.append(v_loss)\n",
    "        [v_predict_list.append(pred.argmax()) for pred in val_prediction]\n",
    "        wandb.log({'v_loss':v_loss})\n",
    "        \n",
    "        val_acc = (val_correct/(len(val)*batch_size)*100)\n",
    "        v_accuracy_list.append(val_acc)\n",
    "        print('validation accuracy: ', val_acc )\n",
    "        wandb.log({'val_acc':val_acc})\n",
    "    \n",
    "        total_epochs += 1\n",
    "        \n",
    "    save_dict['Current_Epoch'] = epochs\n",
    "    save_dict['training_samples'] = len(train)\n",
    "    save_dict['validation_samples'] = len(val)\n",
    "    \n",
    "    save_dict['t_accuracy_list'] = t_accuracy_list \n",
    "    save_dict['v_accuracy_list'] = v_accuracy_list  #\n",
    "            \n",
    "    #model = best_model\n",
    "    save_dict['t_loss_list'] = t_loss_list\n",
    "    save_dict['v_loss_list'] = v_loss_list\n",
    "    \n",
    "    save_dict['t_labels'] = train_targets\n",
    "    save_dict['v_labels'] = val_targets\n",
    "    \n",
    "    save_dict['t_predict_list'] = t_predict_list \n",
    "    save_dict['v_predict_list'] = v_predict_list  #\n",
    "    \n",
    "    return model, save_dict\n",
    "\n",
    "from functions import ImageProcessor\n",
    "\n",
    "def loop_batch(model, data, loss_fn, batch_size, sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =None, scheduler= None, train =True):\t# Train and Val loops. Default is train\n",
    "    model = model\n",
    "    total_samples = len(data)\n",
    "    #scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=scheduler_value) \n",
    "    if train:\n",
    "        model.train()\n",
    "        where ='tra'\n",
    "        #lr_ls = []\n",
    "    else:\n",
    "        model.eval()   #  (torch.Size([16, 11])) that is different to the input size (torch.Size([11]))\n",
    "        where = 'val'\n",
    "\n",
    "    predict_list = []\n",
    "    total_count = 0\n",
    "    num_correct = 0\n",
    "    current_loss = 0\n",
    "    labels =[]\n",
    "\n",
    "    \n",
    "    for i, batch in enumerate(data,0):\n",
    "        #print('loop batch 1')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        if sample == True:\n",
    "            IP = ImageProcessor(device) #img, scale:int, save_dict;dict, epoch:int, where:str\n",
    "            i = IP.view(x_batch[random_value],1, loop_run_name, save_dict, epoch, where)\n",
    "            # \n",
    "            sample= False\n",
    "\n",
    "        prediction = model.forward(x_batch)\n",
    "\n",
    "        #print(prediction.shape)  # torch.Size([11])\n",
    "        #print(y_batch.shape)     # torch.Size([16, 11])\n",
    "\n",
    "        #print('loop batch 3')\n",
    "        #!nvidia-smi\n",
    "        #print(\"checking range nums  \", len(y_batch), len(y_batch)-1)\n",
    "        #print(\"len x batch \", len(x_batch))\n",
    "        #print(\"len prediction \", len(prediction))\n",
    "        #print(\"prediction  \", prediction.argmax(), prediction.shape)\n",
    "        #print(\"prediction[1]\", prediction[1].argmax())\n",
    "        #print(\"y batch[1]\", y_batch[1].argmax(), y_batch[1].shape)\n",
    "\n",
    "        loss = loss_fn(prediction, y_batch)\n",
    "        \n",
    "        #print('loop batch 4')\n",
    "        #!nvidia-smi\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #print('loop batch 5')\n",
    "        #!nvidia-smi\n",
    "            \n",
    "        [predict_list.append(pred.argmax()) for pred in prediction]#.argmax())\n",
    "        [labels.append(y.argmax()) for y in y_batch]\n",
    "        \n",
    "        \n",
    "        for i in range(len(y_batch)-1):\n",
    "            if y_batch[i].argmax() == prediction[i].argmax():\n",
    "                num_correct +=1\n",
    "\n",
    "        \"\"\"\n",
    "        if y_batch[i].argmax() == prediction[i].argmax():\n",
    "        IndexError: index 11 is out of bounds for dimension 0 with size 11\n",
    "        \"\"\"\n",
    "\n",
    "        total_count+= batch_size\n",
    "        current_loss += loss.item()\n",
    "\n",
    "    if scheduler and scheduler >0:\n",
    "        scheduler.step()\n",
    "\n",
    "    if train:\n",
    "        return current_loss, predict_list, y_batch, num_correct, model, optimizer #, lr_ls\n",
    "    else:\n",
    "        return current_loss, predict_list, y_batch, num_correct\n",
    "\n",
    "\n",
    "def test_loop(model, model_name, X, Y, res, pad, save_dict, loss_fn, device, av_lum, num_classes=11):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    current_loss = 0\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    colour ='colour'\n",
    "    size =  res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print('Testing...') \n",
    "        for idx, img in enumerate(X):\n",
    "\n",
    "            #image pre processing\n",
    "            prepro = ImageProcessor(device)\n",
    "            if model_name == 'vgg16':\n",
    "                tense = prepro.colour_size_tense(img, colour, size, av_lum, pad, vg=True) #[29, 9], 15, 5, [8,3]\n",
    "            elif (model_name == '7c3l' and size == [29, 9]) or (model_name == '7c3l' and size == [15, 5]) or (model_name == '7c3l' and size ==[8, 3]):\n",
    "                tense = prepro.colour_size_tense(img, colour, size, av_lum, pad, vg=True)\n",
    "            else:\n",
    "                tense = prepro.colour_size_tense(img, colour, size,av_lum,  pad)\n",
    "\n",
    "\n",
    "            tense = tense.unsqueeze(dim=0)\n",
    "\n",
    "            prediction = model.forward(tense)\n",
    "            label = label_oh_tf(Y[idx], num_classes).to(device)\n",
    "\n",
    "            label = label.unsqueeze(dim=0)\n",
    "\n",
    "            loss = loss_fn(prediction, label)\n",
    "\n",
    "            if prediction.argmax()==label.argmax():\n",
    "                num_correct +=1\n",
    "            total_count +=1\n",
    "            correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "\n",
    "            predict_list.append(prediction.argmax())\n",
    "\n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        current_loss += loss.item()\n",
    "        \n",
    "    return accuracy, predict_list, Y, current_loss\n",
    "\n",
    "## model, data, loss_fn, device, optimizer =None, scheduler= None, train =True\n",
    "def test_loop_batch(model,data, loss_fn, batch_size, device):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    label_list = []\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data,0):\n",
    "            #tense = tense.to(device)\n",
    "            tense, label = batch\n",
    "            label = label.to(device)\n",
    "            \n",
    "            prediction = model.forward(tense.to(device))\n",
    "            for i in range(len(label)-1):\n",
    "                #print(len(label), label[0].argmax(), len(label)-1)\n",
    "                if label[i].argmax() == prediction[i].argmax():\n",
    "                    num_correct +=1\n",
    "            [predict_list.append(pred.argmax()) for pred in prediction]\n",
    "            [label_list.append(lab.argmax()) for lab in label]\n",
    "\n",
    "            total_count += batch_size\n",
    "            #correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "    \n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "\n",
    "        print(accuracy)\n",
    "\n",
    "        #print(len(predict_list), len(label_list))\n",
    "    \n",
    "        #X = list(X)\n",
    "        #log_test_score(acc, accuracy, X) # test_acc,test_predict_list, y_test, test_loss \n",
    "        return accuracy, predict_list, label_list\n",
    "\n",
    "\n",
    "\n",
    "def get_data(random_seed):\n",
    "    file_path =  data_path\n",
    "    #print(file_path)\n",
    "    img_len = len(os.listdir(file_path))\n",
    "    \n",
    "    x, y = import_imagedata(file_path)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "    \n",
    "def get_lin_lay(model_card, resolution):\n",
    "    if resolution == [452, 144]:\n",
    "        lin_lay = model_card['f_lin_lay'][0]\n",
    "    elif resolution == [226, 72]:\n",
    "        lin_lay = model_card['f_lin_lay'][1]\n",
    "    elif resolution == [113, 36]:\n",
    "        lin_lay = model_card['f_lin_lay'][2]\n",
    "    elif resolution == [57, 18]:\n",
    "        lin_lay = model_card['f_lin_lay'][3]\n",
    "    elif resolution == [29, 9]:\n",
    "        lin_lay = model_card['f_lin_lay'][4]\n",
    "    elif resolution == [15, 5]:\n",
    "        lin_lay = model_card['f_lin_lay'][5]\n",
    "    elif resolution == [8, 3]:\n",
    "        lin_lay = model_card['f_lin_lay'][6]\n",
    "    else:\n",
    "        print(\"PARAMETER NOT FOUND: \\n f_lin_lay FROM MODEL CARD\")\n",
    "    return lin_lay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf5ca7f-b59a-427b-8da3-2848fa6d3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def _go(config=None):\n",
    "\n",
    "    if len(gitHASH) <1:\n",
    "        print(\"YOU FORGET THE GIT HASH\")\n",
    "        return\n",
    "    else:\n",
    "        #print('Git Hash registered')\n",
    "        pass\n",
    "        \n",
    "    with wandb.init(config=config, project=f\"fixed DL.Big Loop batching of model 7c3l\", notes=\"big loop batcing 7c3l. Full parameters.\",):\n",
    "        config = wandb.config\n",
    "        start = time.process_time()\n",
    "            \n",
    "        for model_idx, model_card in enumerate(config['model_cards']):\n",
    "            #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                    \n",
    "            model_name = model_card['model']\n",
    "            model_index = model_card['idx']\n",
    "            dropout = model_card['dropout'] \n",
    "            for res_idx, resolution_card in enumerate(config['resolution_cards']):\n",
    "                #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "            \n",
    "                resolution = resolution_card['resolution']\n",
    "                pad = resolution_card['padding']\n",
    "                lin_lay = get_lin_lay(model_card, resolution)\n",
    "                print('lin lay', lin_lay)\n",
    "            \n",
    "                for lr_idx, lr in enumerate(config['learning_rate_cards']):\n",
    "                    for wd_idx, wd_card in enumerate(wd_cards):\n",
    "                        for sched_idx, scheduler_value in enumerate(config['scheduler_cards']):\n",
    "                            for seed_idx, seed in enumerate(config['seeds']):\n",
    "                                seed = seed\n",
    "                                for lossfn_idx, loss in enumerate(config['loss_fn_cards']):\n",
    "                                    \n",
    "                                    torch.cuda.empty_cache()\n",
    "\n",
    "  \n",
    "                                    config['batch_size']\n",
    "\n",
    "                                    print('Model: ', str(model_name), f\" idx: {model_idx} / {len(config.model_cards)}\")\n",
    "                                    print('resolution: ', str(resolution), f\" idx: {res_idx} / {len(config['resolution_cards'])}\")\n",
    "                                    print('learning rate: ', str(lr), f\" idx: {lr_idx} / {len(config['learning_rate_cards'])}\")\n",
    "                                    print('weight decay: ', str(wd_card), f\" idx: {wd_idx} / {len(config['wd_cards'])}\")\n",
    "                                    print('scheduler: ', str(scheduler_value), f\" idx: {sched_idx} / {len(config['scheduler_cards'])}\")\n",
    "                                    print('seed: ', str(seed), f\" idx: {seed_idx} / {len(config['seeds'])}\")\n",
    "                                    print('loss function: ', str(loss), f\" idx: {lossfn_idx} / {len(config['loss_fn_cards'])}\")\n",
    "                                    print('Batch size: ', config['batch_size'])\n",
    "                                    print('Training epochs: ', config['epochs'])\n",
    "                                    run_start_time = time.process_time()\n",
    "                                    print('start time: ',run_start_time)\n",
    "   \n",
    "                                    print(time.process_time() - start)\n",
    "\n",
    "                                    epochs = config['epochs'] #40\n",
    "\n",
    "                                    IP = ImageProcessor(device)\n",
    "\n",
    "                                    wandb.log({'gitHash':gitHASH})\n",
    "                                    wandb.log({'Epochs': epochs})\n",
    "\n",
    "                                    # set save dictionary\n",
    "                                    save_dict = {'Run' : f\"{model_name}_{resolution}_{date}\",\n",
    "                                                 'Current_Epoch': 0,\n",
    "                                                 'save_location' : _save_location}\n",
    "          \n",
    "                                    model = choose_model(model_name, lin_lay, dropout).to(device)\n",
    "\n",
    "                                    print(\"After model init, Before data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "                                    x_train, y_train, x_val, y_val, x_test, y_test = get_data(seed)\n",
    "                                    av_lum = IP.new_luminance(x_train)\n",
    "                                    #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                                    \n",
    "                                    train_ds = IDSWDataSetLoader2(x_train, y_train, resolution,pad,av_lum,model_name, device)# av_lum, res,pad,\n",
    "                                    train = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "\n",
    "                                    \n",
    "                                    test_ds = IDSWDataSetLoader2(x_test, y_test, resolution,pad,av_lum,model_name, device)\n",
    "                                    test = DataLoader(test_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "                                    #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                                    val_ds = IDSWDataSetLoader2(x_val, y_val, resolution,pad,av_lum,model_name, device)\n",
    "                                    val = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "                                    \n",
    "                                    print(\"After data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "                                    loss_fn = set_lossfn(loss)\n",
    "                                    \n",
    "                                    # set optimizer\n",
    "                                    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "                                    wandb.watch(model, loss_fn, log='all', log_freq=2, idx = model_index)\n",
    "                                    loop_run_name = f\"{save_dict['Run']}_{resolution}_{lr}_{scheduler_value}_{seed}_{loss}\"\n",
    "         \n",
    "                                    model, save_dict=  train_val_batch(model, train,val, loop_run_name,save_dict, lr, loss_fn,epochs, config['batch_size'], optimizer, scheduler_value, device)\n",
    "\n",
    "                                    test_acc,test_predict_list, y_test = test_loop_batch(model,test, loss_fn, config['batch_size'], device) #model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\n",
    "\n",
    "                                    print(' \\n train Acc: ', save_dict['t_accuracy_list'][-1])\n",
    "                                    print(' \\n val Acc: ', save_dict['v_accuracy_list'][-1])\n",
    "                                    print(' \\n test Acc: ', test_acc)\n",
    "                                    \n",
    "                                    save_dict.update({'test_acc': test_acc})\n",
    "                                    save_dict.update({'test_predict': test_predict_list})\n",
    "                                    save_dict.update({'test_labels': list(y_test)})\n",
    "\n",
    "                                    learning_curve(save_dict['t_loss_list'], save_dict['v_loss_list'], save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                                    accuracy_curve(save_dict['t_accuracy_list'], save_dict['v_accuracy_list'],save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                                    test_predict_list=[pred.cpu() for pred in test_predict_list]\n",
    "                                    plot_confusion(predictions= test_predict_list, actual= y_test, title = \"Confusion matrix\", run_name = loop_run_name,save_location =save_dict['save_location'])\n",
    "                                    \n",
    "                                    wandb.log({'test_acc': test_acc})\n",
    "                                    wandb.log({'test_predict': test_predict_list})\n",
    "                                    wandb.log({'test_labels': list(y_test)})\n",
    "                                    #saving\n",
    "                                    diction = {}\n",
    "                                    d = date.today()\n",
    "                                    d=str(d)\n",
    "                                    diction.update({'Date':d})\n",
    "                                    diction.update({'gitHASH':str(gitHASH)})\n",
    "                                    diction.update({'model_name': str(model_name)})\n",
    "                                    diction.update({'loss_fn': str(loss)})\n",
    "                                    diction.update({'lr': str(lr)})\n",
    "                                    diction.update({'wd': str(wd_card)})\n",
    "                                    diction.update({'scheduler value': str(scheduler_value)})\n",
    "                                    diction.update({'seed': str(seed)})\n",
    "                                    diction.update({'resolution': str(resolution)})\n",
    "                                    diction.update({'pad': int(pad)})\n",
    "                                    diction.update({'lin_lay': int(lin_lay)})\n",
    "                                    diction.update({'run time': (time.process_time() - run_start_time)})\n",
    "                                    diction.update(save_dict)\n",
    "                                    \n",
    "                                    save_location = save_dict['save_location']\n",
    "                                    title = save_dict['Run']\n",
    "                                    save2json(diction, loop_run_name, save_location)\n",
    "                                    save2csv(diction, title, save_location)\n",
    "        \n",
    "                                    diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "        \n",
    "                                    #with open(f\"{save_location}{loop_run_name}.pkl\", 'wb+') as f:\n",
    "                                    #pickle.dump(diction, f)\n",
    "                                    torch.save(diction, f\"{save_location}{loop_run_name}.pkl\")\n",
    "                                    \n",
    "                                    clear_output()\n",
    "                                    \n",
    "                                    print(f' \\n END {model_name} {resolution} Run Time: ',time.process_time() - run_start_time)\n",
    "                                    #!nvidia-smi\n",
    "                                    torch.cuda.empty_cache()\n",
    "        print('Final Run time: ',time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d7d27-ef9d-43d9-98a8-1f11ff50090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " END 7c3l [57, 18] Run Time:  21887.93111612997\n",
      "Model:  7c3l  idx: 0 / 1\n",
      "resolution:  [57, 18]  idx: 0 / 4\n",
      "learning rate:  0.001  idx: 2 / 5\n",
      "weight decay:  0  idx: 0 / 1\n",
      "scheduler:  0  idx: 0 / 1\n",
      "seed:  2  idx: 1 / 3\n",
      "loss function:  MSE  idx: 0 / 2\n",
      "Batch size:  64\n",
      "Training epochs:  60\n",
      "start time:  273921.51743744\n",
      "273909.87096359796\n",
      "After model init, Before data loading - Current allocated memory (GB): 0.0\n",
      "After data loading - Current allocated memory (GB): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/nn268/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training..  2\n",
      "train accuracy:  8.533653846153847\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–                       | 1/60 [00:31<30:59, 31.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACrCAYAAAD7C5/9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATfElEQVR4nO3dS4/c2HnG8YfFYt26urrV3ZKskQYj2+PZBAhiBEkQJKt84ez8Abx0gAAxECDjTJzJSBqNWn2p6u66sMgisxggq+R9jiHFlzn/3/aUDsnDQ9arAt6ni77vewEAgGwN/tAnAAAA/rAoBgAAyBzFAAAAmaMYAAAgcxQDAABkjmIAAIDMUQwAAJA5igEAADJHMQAAQOaGqR/8/PPP/z/P44+KC2X8GKGNhQr3AT9HkfChH4iu68Lxj3JPPsJ6uvNw15EyRzGIz3NQ+BrfzVEkzOHO83A4xP8+YS0Gg/g8Uu6ZO4+2bcPxLmFvleY8y6F/1br16Hu3Xin71+ythPUsy9KM+2vN6d31x+Crr76yn+GXAQAAMkcxAABA5igGAADIHMUAAACZoxgAACBzFAMAAGQuubVwaFpjfl+tIodD3AY0GMRtL3Vd22N0XdyKVJpjSNLBtAnNprNwvD009hjuWlPuyX6/D8ddW5YkjUajcNztnZyk7L/9Pv7Mfuf3xodKaadzu8u2oCXsC9eK6fbexziPtvHr3ZjPpDwDB9M6OBpW8TFK/3+71f19OD4wayVJ693OfsZx7ya3t0aVv+9jszdS9s6Hcu9XyV+LawOWPs73L78MAACQOYoBAAAyRzEAAEDmKAYAAMgcxQAAAJmjGAAAIHMUAwAAZI5iAACAzCWnwbjwj5Rwmu1mE46PJ5PU0/m/5xjHoRkpQRM2QCTh73U3u2043pu/K+5CiySpbeM1r6o4pCTlMyn39UP3hvub9SlSwnzG43E4vjH7s08I4mlNKNYuKfTKHMeMp+SPuCCeto2vQ5LmR0fh+GQ6DcdT9ufH4PbnwCxYWfj96fb41KyF5PfX3ryX3t3e2mMcu3s29u/gkTkPt56SNPnAd33Ks7her8Nx9wykcHvLfZdIUmXCpHr3PlDae9rhlwEAADJHMQAAQOYoBgAAyBzFAAAAmaMYAAAgcxQDAABkjmIAAIDMJecMuJ7MlJ7N4TA+XErvqOsFl5nD9T5LUmt6Q12/uiTN5/NwfG/6zfuEnAHn4eHefqau9+H4IKUX1/TB9qbt+GSxsIdwfe8p97Xe7exnItOJP8b17Y35hO/BPvRxz7DrFXfjku9Zv7+7s3OMzHPgMj122ziLQ/L31fV5Sx/eT16N/P+ZTkYnH3QMSbpZLsPxu1387usS+vs/MXtju/XPSGlyQVKyXO7M/irMtaTkFNjvrEHCvjBL6r7TUvZe15m8mIT1/BiZCfwyAABA5igGAADIHMUAAACZoxgAACBzFAMAAGSOYgAAgMxRDAAAkDmKAQAAMpccOvQxuCCJgQmzkHyYjwsh2SYEnbjzTAk6ORziIAmZY4wTQjU+RjCHC58ZJASZ3D88hOMbs+br9doeY2rCZy7fvbNzVFUc3lHv4wCmuyK+TklqmngOt38laWpCRvb7OLDqu9rv8bNFHJLz5MkTO4d7DtwzkBJotTf3ZFRVdg53noMifu/08mFo7llcP/g9vjV7R2a9ns6P7TFcrttsNrNzNOad4cYl6fg4Pld3z2oT2ib5ELu69gFLrdnD7jo2Ce+242Mfuvb7wC8DAABkjmIAAIDMUQwAAJA5igEAADJHMQAAQOYoBgAAyBzFAAAAmfsdcgZcRoDvR+870+Tqp5Br+a1M33HnzkHSeh33k7tjSPY0NR6Pw3HXtyz5nuFePg9hNIrP4+bmys6xML3zw6GpOXt/rQ8my+D87MzO4XqXd6Z3uTb9/ZJUDeO9MU/o43Z5B5XiHIJ49Hsu0+PV+0s7xycXF+F4YR5o+z6QNJ58+HOyvr8Lx49mR+H4buf70R9MP/nC9KNLUmfeGm49hwOf29CbZ8D11Us+R2Cz8TkX02mcgeLyI45S8hDaNhx3GRaSf4+7LI2UvJidyTuYTv21pnz/2jk+eAYAAPAnjWIAAIDMUQwAAJA5igEAADJHMQAAQOYoBgAAyBzFAAAAmaMYAAAgc8mhQy7SYFD4uqLp4rCKIiE4YTj8HXKS/hcTE/YjSYdDHFbhwmkkaT6Pg0y22ziY42g2tcdwUnIoNts4LKUa+Qiby5ubcHw0jMNQ5kc+kKU0ITluPSVpaYKLehMgMkwImxqYa3WBQpJ0v92E4xNzT1JCcuYmBOfieGHneHP9Phw/GcV7OCW8y933d5c+HOnxkyfh+M31dXwOCe+c87PzcHxj7mmKSRWfR0qIjgvFSnkHH5u9kxIENTdBZb1JVEs5RmtCh1zYVIqdCSJz+1eSbq7j9+csJXQo4fvXzvHBMwAAgD9pFAMAAGSOYgAAgMxRDAAAkDmKAQAAMkcxAABA5igGAADIXHLT/tEs7nVM6Z8emb7iIqEns23jrILxeBKODxKOsd7Evfcp19o/xH2ybWMyF+wRpLKMe9oPjc9DcJqEax2Wpv/Z9Awvl0t7jMUi7ntfru7sHDJ92p25J2rjHAJJOj85CceXmzjrQJL6Ll6vgxmfmmdVktbreI8XZm9JUmmW466J8w4eJ2R+1CbTYzzxcxRm/3Wmt36SkDPg3hkPZlzyPf4T85yVI3+eq4f4OXl0+sjO0R26cHxU+WyS7SbOXTg5OQ3HU/IQNmaPu+8KSarMO2Ns9nBrsksk2Ze9++6V0r6THH4ZAAAgcxQDAABkjmIAAIDMUQwAAJA5igEAADJHMQAAQOYoBgAAyBzFAAAAmUsOHer6OGjChQFJUtO04bgLePj+OHGIg8sxOSSEQOx2cdBJSjjS0TQOini/uQ7Hy70PDDq08Xqq89d6akJGfrTwISTfvHkdjhdmuZ6/+NQe4/YmXq++9CEkTRsHcwxNkEnKfXfhR8XQh/mojENyNtttOP74/Mwe4uZ26c/DGBTxeg0O8XXcJQQwzSbTcLxxz4Ck7S4OP2rMu2tt3luS1Hbx+1EJITkHxXPMjo7C8fv1vT3Gs8dPw/FJQohTZ6716urKznFkrqUyz8nO3FNJOj+Ln4NBQrCWC71SvMV1+f7SHuPEBJW5714p7fvX4ZcBAAAyRzEAAEDmKAYAAMgcxQAAAJmjGAAAIHMUAwAAZI5iAACAzCXnDLx6/SYc//Fnn9k5VqtVOD4ZT+wc1bwKx1vTd7xv4l5zybcED4fxOUjS5e1NPIfrcS0S+tH7uLf0+XPfv7/ebMLxG3MdklQN421k2tH121f/aY/R7uP7Ohz5ezIq4/PsTT9v3fjsh4EJuujdYkhq6/i+VuZa1ykZFaZBemLWSpL6Lp7j/Ow8HH+z9P3oheknP10s7ByPzXmsHuJsiPEszgyRpPUm7vGvlJAzcIj337QaheOrhGOU5uV2Z97RkjQz63F+Hq+3JO12cVbGzU383plO4/wJSbq9vQ3HU87T5Qjcrpbh+CdPf2QPUe/j7yT33Sulff86/DIAAEDmKAYAAMgcxQAAAJmjGAAAIHMUAwAAZI5iAACAzFEMAACQueScgfpwCMdvE/rRe9OzOTE92pK0b+Ie7NEo7sXdmL56SVocx39fuqz8st2t1+F4o3g964S/9X48i/8meNvGx5CkS/O3xxfzuZ3j8cVFOP7122/D8UHlMwLKLu6Pbht/rZ3JKijK+BhFwuPSlnF93e18BkBvHpRtHV9r55qjJbXmM417WCWNTN7B1b3JFSn9fe9N63zbxPdUkt5fx+8ml7lwvYlzCCTp5eO4n/x1wt+1H5jskYHJqHjx+Kk9xmQSZ7mUA59v4vZn5TJUJF2u4lyG9hDf1/PzM3uM0jyLB5NJI0nHCe+/iPsekKRrk4dgg1qU9v3r8MsAAACZoxgAACBzFAMAAGSOYgAAgMxRDAAAkDmKAQAAMkcxAABA5igGAADIXHLoUGUCRl588sLOcXkVB280JlBIklbLZTh+enoajqeEDh26LhwvEkIg3CcmJmhnZ0KeJGmz3Ybjb7Y7O0c1ioOe1gn35O03X4fjwz6+1uYQr7ckVUMzR+cDREaTaTjuwlSKsX9citqE9RQ+aGc0je9J3cTBRd3B78/RMA6G2ZnQF0nat/G1Ds1SmBwpSVKveG/4p8Q/a3UfH2Nu9o0kbev4WRuYQCtJNmFpc4ifxeHeB1otpvG1HJ0s7BydeV67zgdWyey/2SR+Bpp6bw/R7OPPHJ3E4XKS1JhnbTKO99abyzhcSZIuzh6F46uE4KKU71+HXwYAAMgcxQAAAJmjGAAAIHMUAwAAZI5iAACAzFEMAACQOYoBAAAyl5wzMBuPwvEvf/vvdo7TRdzX+erNazvHmckRePfuu3D8yZMn9hj1Pu7ndT3FkrQ3/fnbJu6BPbS+9/74OO4JrmufEVDv4n7yzrfFa1LFvcttG3eDDxL6kvdtvF7z+amdY1jFe3i1W4bjs87Xzv1R/EiVpldckvZmfxVDcwyT6yBJ9T7O26gG/tXQtPHeqffxeDFMWM9h3HvfmmwISbpdx73elVnPcRn3xEvSF5+9DMf/+d/+1c6xN/373y1vwvG//7M/t8cYV3H//s3y1s5RlPF6LY7mdo6RyWpZzOJ3yiEhh2VQxPur7/0c681DOL4z71iXWSNJTRvP4b57pbTvX4dfBgAAyBzFAAAAmaMYAAAgcxQDAABkjmIAAIDMUQwAAJA5igEAADJHMQAAQOaSQ4cKk+2x3m7tHM0+Do65ODv35zGIwypevvxxOH51fWWPcb1cheONCdGRpKEJMun6+DqKgQ+OaUygRTnwtd6hN6FDWx/qUozjay1cgE1f22NoGs/RJ4R7rO+X4fh4GAeyrE14jSRNizhwpRrHYSqSVBVxyM1qvQ7H94d4XJKms/g8mz5+ViWpPMTnuY+XU5M2fgYkqe7iZ63exuFJUsJzYLZ4m7C3vn4dB6aV5p5KkjoTYFPE57E07y1J+vbqMhz/eUJwkXsjvLuMg98k6Yuf/Swcv75+H46/v44DmCTpJy9fhuO7nf/O+vT5p+H4t9+9Dcfdsyr59Rz4V3DS96/DLwMAAGSOYgAAgMxRDAAAkDmKAQAAMkcxAABA5igGAADIHMUAAACZS84ZuDi/CMfv7x/8HBdPw/Gi9w2VW9NP+eXVb8LxvvD1T6e4/3kyndg51nfxeiyOT8Lxut7ZY/RNnBHQpqxnHc8xTMgqmJht9NCaXvCR34Z9Hfe997ORnWM8Ow7H9zvXs+7Xs2vj+3b34HvB3XHKKt5/jenNl6Ta9D8PSt8XX5rsh2cnz8Lx5cpnfshcSzX09701c/RdQiO38dd/8Vfh+C9/9Us7RxHHDJi3kvTN9Tt7jKfz+L3z6vV/2Tn2Ji/mbuffXW9u4ryDzry7ioPPftg3cX7Ji2fP7Rz1dhkfw7wz/uFv/84e459+/S/h+OkivmdS2vevwy8DAABkjmIAAIDMUQwAAJA5igEAADJHMQAAQOYoBgAAyBzFAAAAmaMYAAAgc8mhQ48WcWDLq7EP/7ip78Px/Z0LfZHKQXzK5XAcjrcmMON7caBF3/pAlmFVxePj+DybhFCN7hAHBnX7OHRDkqaj+Dxm84WdoxjGNWUxPQrHV5ev/TH6eD2aXbzekjQ7ij8zKOL72vfxektS07gAGx9wY4OeChOKNZvbY/RtvJ6tCbSSpGYfp+TcXMfBMpPZzB6j3sbn0e/9etrlHHz4Pbt8H+/hovBzuE8MzD2rtz7s58688qcz/xztu/iePD9/Yuf4m7/8eTj+j7/4RTh+n3CtO7Oiv/ry13aOx5P4WXrx7EU4fnUVPwOSNBrG98R990pp378OvwwAAJA5igEAADJHMQAAQOYoBgAAyBzFAAAAmaMYAAAgcxQDAABkruj73jfASvrsi8/D8X1CL+7UjB9PfX90u4t7m6W4B7tLuNz3y1U4fnJyYufoi7jOaus4A2C1vLXHKMu4L3525M9zuzP9up3PKvj05U/D8W+vb+IJdmt7jOXNVTg+O0641nWcczGdn4bjh4PvbW53cVZG0x7sHMMy7jt2OQL393cJxzDZECbLQJJc63xpetabvc8yKCamB3v22M6x2lyH4y5sZT5zby7p04uzcPybm/gcJGm12YbjU/MoTo99bkOxiHNFfnL8yM5RmndsP/A5LAfznLx+H6/Xs5/G/f2SdDGKn5PXb7+zc3TD+FpWdXzPqi4hB6OPd+BG/p3hvn/f/uY//HnYTwAAgB80igEAADJHMQAAQOYoBgAAyBzFAAAAmaMYAAAgcxQDAABkjmIAAIDMubyN//HyPA73eOuCZSS1+304ft/FQRSSdDo9Csd3TZzMsd364JjFaBSOH0zQhCQ1bRyOVFVxmMXZybE9xsaElDRbHz5zaOLzHA99vfj+7ZtwfGTya1brOORJkkaj+DwG6uwclQvaac19bX0A03QSB50sKh/ms354MKcRhzRNRz70pbNhKAlZZMP49VGYrJTJMA4lkiR3mpu7OIxKktxyFOb/REO/tVTX8cWWvb8n86EJDerjkKZ27NdztosXdD2O39GSNBjH78e28XOUR/Ec0z4OP3pnQokk6aGK3/XldGLn6Po4pOloEK/5YuC/YptBvP+elP6dkfL96/DLAAAAmaMYAAAgcxQDAABkjmIAAIDMUQwAAJA5igEAADJHMQAAQOaKvu8TGooBAMAPFb8MAACQOYoBAAAyRzEAAEDmKAYAAMgcxQAAAJmjGAAAIHMUAwAAZI5iAACAzFEMAACQuf8G/aDTfFrnqNEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training..  2\n",
      "train accuracy:  10.276442307692307\n",
      "validating...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Š                       | 2/60 [01:07<32:54, 34.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.375\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.63701923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–ˆâ–                      | 3/60 [01:40<31:51, 33.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.090909090909092\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.516826923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–ˆâ–Œ                      | 4/60 [02:13<31:19, 33.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.375\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.997596153846153\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–ˆâ–ˆ                      | 5/60 [02:47<30:48, 33.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.090909090909092\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.9375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆâ–ˆâ–                     | 6/60 [03:20<30:07, 33.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.948863636363637\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  11.177884615384617\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–ˆâ–Š                     | 7/60 [03:55<29:56, 33.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.232954545454545\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.795673076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–ˆâ–ˆâ–                    | 8/60 [04:31<29:52, 34.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.948863636363637\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.9375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–ˆâ–ˆâ–Œ                    | 9/60 [05:01<28:11, 33.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.090909090909092\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  11.057692307692307\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–ˆâ–ˆâ–Š                   | 10/60 [05:33<27:14, 32.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.948863636363637\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.036057692307693\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–                  | 11/60 [06:06<26:47, 32.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.375\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.877403846153847\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 12/60 [06:39<26:22, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.45673076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 13/60 [07:13<26:02, 33.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.090909090909092\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.877403846153847\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 14/60 [07:43<24:39, 32.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.375\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.516826923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 15/60 [08:16<24:24, 32.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.975961538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 16/60 [08:48<23:49, 32.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.576923076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 17/60 [09:22<23:31, 32.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.948863636363637\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  11.23798076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 18/60 [09:56<23:08, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.090909090909092\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.697115384615383\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 19/60 [10:25<21:47, 31.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.232954545454545\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.9375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 20/60 [10:54<20:48, 31.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.090909090909092\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.036057692307693\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 21/60 [11:25<20:14, 31.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.948863636363637\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.576923076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 22/60 [12:01<20:29, 32.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.090909090909092\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  11.117788461538462\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 23/60 [12:39<21:09, 34.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.375\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.697115384615383\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 24/60 [13:12<20:13, 33.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.948863636363637\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.877403846153847\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 25/60 [13:37<18:15, 31.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.232954545454545\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.15625\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 26/60 [14:11<18:12, 32.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.232954545454545\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.9375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 27/60 [14:47<18:10, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.817307692307693\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 28/60 [15:19<17:29, 32.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.375\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  11.057692307692307\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 29/60 [15:52<17:03, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.090909090909092\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.396634615384617\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 30/60 [16:29<17:06, 34.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.232954545454545\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  11.298076923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 31/60 [17:06<16:53, 34.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.232954545454545\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.396634615384617\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 32/60 [17:37<15:45, 33.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.375\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.9375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 33/60 [18:06<14:30, 32.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.375\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.9375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 34/60 [18:39<14:07, 32.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.948863636363637\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.576923076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 35/60 [18:53<11:12, 26.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.090909090909092\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.795673076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 36/60 [19:31<12:04, 30.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.375\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  11.598557692307693\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 37/60 [20:02<11:43, 30.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.517045454545455\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.336538461538462\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 38/60 [20:36<11:36, 31.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.948863636363637\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.757211538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 39/60 [21:10<11:15, 32.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.517045454545455\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.9375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 40/60 [21:46<11:06, 33.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  9.090909090909092\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  10.216346153846153\n",
      "validating...\n"
     ]
    }
   ],
   "source": [
    "_go(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964b31e-4bae-4f65-bc46-ee1334a8f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.04 GiB is free\n",
    "23.65-8.04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59daceaa-fa47-4c76-90d6-f23550f85694",
   "metadata": {},
   "source": [
    "\n",
    "pred torch.Size([11])\n",
    "\n",
    "lab  torch.Size([5, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5d251-dbcc-482b-aac0-ac24617279e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
