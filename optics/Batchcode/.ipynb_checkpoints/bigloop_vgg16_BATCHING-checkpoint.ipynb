{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4fd19-5a09-4232-bdc4-42bbef0b6802",
   "metadata": {},
   "source": [
    "last updated 11 03 24\n",
    "\n",
    "This notebook is to get the run times for each model on the highets and lowest Resolutions; to estimate an average run time.IG DICITONARY!\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6be64f-3efe-4c20-885c-1333846ffbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364e97a-adf8-4aa3-aadf-a32df7852d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6dbd95-2129-42b5-b70b-ee9f057b24c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg16\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch.Utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import collections\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "from functions import import_imagedata, ImageProcessor, label_oh_tf, IDSWDataSetLoader2\n",
    "from fns4wandb import set_lossfn\n",
    "\n",
    "from loop_fns import loop#, loop_batch, test_loop_batch\n",
    "from plotting import learning_curve, accuracy_curve, plot_confusion\n",
    "\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "\n",
    "#import torch.Utils.data.DataLoader as DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6ace79-5b6a-4955-9fd3-52aeaddf0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = torch.cuda.memory_summary(device, abbreviated=False)\n",
    "#Pp = pprint.PrettyPrinter(indent=4)\n",
    "#Pp.pprint(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c1e605-9a3b-48dc-a38e-8a955bd3c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "_save_location = r'/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/vgg16/' #vgg16\n",
    "\n",
    "data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "\n",
    "gitHASH = '069656012e2992e78ab1c36de20b6dcf8dfa7006'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1481ccd-4d87-4c05-84d5-77e29ee981b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaughticalnonsence\u001b[0m (\u001b[33mantvis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ddbb49-828b-4de8-a31c-2a576cd736f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries                                                                                  * * * *   SETTINGS   * * * *\n",
    "\n",
    "date = date.today()\n",
    "#model_name = model_card['model']\n",
    "model_card_vgg = {'name': 'vgg', 'model': 'vgg16',\n",
    "                  'f_lin_lay':[200704,#200704,     #129024,#4096,  # (32x200704 and 3584x4096)\n",
    "                             200704,      #(16x64512 and 129024x4096)    (16x200704 and 64512x4096)\n",
    "                             200704,#14336#(16x200704 and 14336x4096)\n",
    "                             200704,\n",
    "                             200704, ##(32x200704 and 3584x4096)\n",
    "                             200704,\n",
    "                             200704,\n",
    "                            ],\n",
    "                 'idx': 0,\n",
    "                 'dropout':0.2}\n",
    "\n",
    "\n",
    "model_card_7c3l = {'name': '7c3l', 'model': '7c3l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[248832,    # 452 144 # p5\n",
    "                            59904,      # 226 72 # p5\n",
    "                            11264,      # 113 36 # p2\n",
    "                            1536,       # 57 18 # p1\n",
    "                            172032,           # 29 9\n",
    "                            172032,          # 15 5\n",
    "                            172032,         # 8 3\n",
    "                              ], \n",
    "                   'idx': 1,\n",
    "                  'dropout':0.2}\n",
    "\n",
    "\n",
    "\n",
    "model_card_4c3l = {'name': '4c3l', 'model': '4c3l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[539904,    # 452 144 # p5\n",
    "                             141056,    # 226 72 # p5\n",
    "                             304640,     # 113 36 # p2\n",
    "                             9984,      # 57 18 # p1\n",
    "                             2304,      # 29 9\n",
    "                             512,       # 15 5\n",
    "                             256],      # 8 3\n",
    "                  'idx': 2,\n",
    "                  'dropout':0.2}      \n",
    "\n",
    "model_card_3c2l = {'name': '3c2l', 'model': '3c2l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[1069888,    # 452 144 # p5\n",
    "                             274688,     #226 72 # p5\n",
    "                             68096,      # 113 36 # p2\n",
    "                             17280,      # 57 18 # p1\n",
    "                             3840,       # 29 9\n",
    "                             960,        # 15 5\n",
    "                             256],\n",
    "                  'idx': 3,\n",
    "                  'dropout':0.2}       # 8 3\n",
    "\n",
    "model_card_2c2l = {'name': '2c2l', 'model': '2c2l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[1055232 , #1032192,# 16883712,#33767424,    # 452 144 # p5 # (1x33767424 and 1055232x100) (1x5276160 and 15828480x100) 1x33767424 and 5276160x100)\n",
    "                             267264,     #226 72 # p5                   (1x1032192 and 64512x100)\n",
    "                             64512,#   1032192,#64512,      # 113 36 # p2    ### (16x1055232 and 1032192x100) ###  16x1055232 and 1032192x100)\n",
    "                             15552,      # 57 18 # p1\n",
    "                             3072,       # 29 9\n",
    "                             640,        # 15 5\n",
    "                             128],\n",
    "                  'idx': 4,\n",
    "                  'dropout':0.1}       # 8 3\n",
    "\n",
    "resolution_card_452144 = {'resolution':[452,144], 'padding':5, 'index':0}\n",
    "resolution_card_22672 = {'resolution':[226,72], 'padding':5, 'index':1}\n",
    "resolution_card_11336 = {'resolution':[113,36], 'padding':2, 'index':2}\n",
    "resolution_card_5715 = {'resolution':[57,18], 'padding':1, 'index':3}\n",
    "\n",
    "resolution_card_299 = {'resolution':[29,9], 'padding':0, 'index':4} # \n",
    "resolution_card_155 = {'resolution':[15,5], 'padding':0, 'index':5}\n",
    "resolution_card_83 = {'resolution':[8,3], 'padding':0, 'index':6}\n",
    "\n",
    "\n",
    "\n",
    "resolution_cards = [resolution_card_5715,resolution_card_299, resolution_card_155, resolution_card_83]#]#resolution_card_452144, resolution_card_22672, resolution_card_11336, \n",
    "#resolution_cards = [resolution_card_11336] #resolution_card_452144, resolution_card_22672, resolution_card_11336, resolution_card_5715,resolution_card_299, resolution_card_155, resolution_card_83\n",
    "\n",
    "#learning_rate_cards = [5e-5, 6e-5, 8e-5]\n",
    "#learning_rate_cards = [8.21592E-05, 6.62E-05, 6.01E-05, 5.97E-05]\n",
    "learning_rate_cards=  [0.1,0.01, 1e-3,1e-5, 1e-5]#, 6e-5, 7e-5, 8e-5]\n",
    "#wd_cards = [4e-5, 5e-5, 3.00E-05, 2.00E-05]\n",
    "wd_cards =[0]\n",
    "scheduler_cards = [0]#, 0.1, 0.2]\n",
    "\n",
    "seeds = [8,2,4]#,2,3] # 4, 5,6\n",
    "\n",
    "#model_cards =[model_card_vgg, model_card_7c3l, model_card_4c3l, model_card_3c2l, model_card_2c2l]\n",
    "model_cards =[model_card_vgg]\n",
    "\n",
    "loss_fn_cards = ['MSE','CrossEntropy' ] #\n",
    "                        \n",
    "config = dict({'parameters': 'parameters for big loop run'})\n",
    "config.update({'model_cards':model_cards})\n",
    "config.update({'resolution_cards':resolution_cards})\n",
    "config.update({'learning_rate_cards':learning_rate_cards})\n",
    "config.update({'wd_cards':wd_cards})\n",
    "config.update({'scheduler_cards':scheduler_cards})\n",
    "config.update({'seeds':seeds})\n",
    "config.update({'loss_fn_cards': loss_fn_cards})\n",
    "\n",
    "\n",
    "config.update({'batch_size': 64})\n",
    "config.update({'epochs': 60})\n",
    "\n",
    "#print(model_card_vgg)\n",
    "#print('')\n",
    "#Pp.pprint(Config) # dictionary of dictionaries of lists and lists of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49eb7e06-506f-48e6-b28c-8caa7641b11b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass VGG16Smaller(nn.Module):\\n            def __init__(self,lin_lay, num_classes=11): #64512\\n                super(VGG16Smaller, self).__init__()\\n                self.layer1 = nn.Sequential(\\n                    nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\\n                    #nn.BatchNorm2d(64),                                  # removed batchnorm 070524\\n                    nn.ReLU(),#)\\n                    #self.layer2 = nn.Sequential(\\n                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\\n                    #nn.BatchNorm2d(64),\\n                    nn.ReLU(), \\n                    nn.MaxPool2d(kernel_size = 2, stride = 2),#)\\n                    #self.layer3 = nn.Sequential(\\n                    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\\n                    #nn.BatchNorm2d(128),\\n                    nn.ReLU(),#)\\n                    #self.layer4 = nn.Sequential(\\n                    nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\\n                    #nn.BatchNorm2d(128),\\n                    nn.ReLU(),\\n                    nn.MaxPool2d(kernel_size = 2, stride = 2),#)\\n                    #self.layer5 = nn.Sequential(\\n                    nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\\n                    #nn.BatchNorm2d(256),\\n                    nn.ReLU(),#)\\n                    #self.layer6 = nn.Sequential(\\n                    nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\\n                    #nn.BatchNorm2d(256),\\n                    nn.ReLU(),#)\\n                    #self.layer7 = nn.Sequential(\\n                    nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\\n                    #nn.BatchNorm2d(256),\\n                    nn.ReLU(),\\n                    nn.MaxPool2d(kernel_size = 2, stride = 2))\\n                self.fc = nn.Sequential(\\n                    #nn.Dropout(0.5),\\n                    nn.Linear(lin_lay, 4096), # 1032192 and 4096x4096)\\n                    nn.ReLU())\\n                self.fc1 = nn.Sequential(\\n                    #nn.Dropout(0.5),\\n                    nn.Linear(4096, 4096),\\n                    nn.ReLU())\\n                self.fc2= nn.Sequential(\\n                    nn.Linear(4096, num_classes))\\n                \\n            def forward(self, x):\\n                out = self.layer1(x)\\n                #out = self.layer2(out)\\n                #out = self.layer3(out)\\n                #out = self.layer4(out)\\n                #out = self.layer5(out)\\n                #out = self.layer6(out)\\n                #out = self.layer7(out)\\n                #PrintLayer()\\n                out = out.reshape(out.size(0), -1)\\n                out = out.flatten(start_dim=1)\\n                #PrintLayer()\\n                out = self.fc(out)\\n                out = self.fc1(out)\\n                out = self.fc2(out)\\n                out = F.log_softmax(out, dim=1) \\n                return out\\n        vgg = VGG16Smaller(lin_lay)\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install datetime\n",
    "\n",
    "d = date.today()\n",
    "#print(str(d), type(str(d)))\n",
    "\n",
    "\"\"\"\n",
    "class VGG16Smaller(nn.Module):\n",
    "            def __init__(self,lin_lay, num_classes=11): #64512\n",
    "                super(VGG16Smaller, self).__init__()\n",
    "                self.layer1 = nn.Sequential(\n",
    "                    nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "                    #nn.BatchNorm2d(64),                                  # removed batchnorm 070524\n",
    "                    nn.ReLU(),#)\n",
    "                    #self.layer2 = nn.Sequential(\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "                    #nn.BatchNorm2d(64),\n",
    "                    nn.ReLU(), \n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2),#)\n",
    "                    #self.layer3 = nn.Sequential(\n",
    "                    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "                    #nn.BatchNorm2d(128),\n",
    "                    nn.ReLU(),#)\n",
    "                    #self.layer4 = nn.Sequential(\n",
    "                    nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "                    #nn.BatchNorm2d(128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2),#)\n",
    "                    #self.layer5 = nn.Sequential(\n",
    "                    nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "                    #nn.BatchNorm2d(256),\n",
    "                    nn.ReLU(),#)\n",
    "                    #self.layer6 = nn.Sequential(\n",
    "                    nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                    #nn.BatchNorm2d(256),\n",
    "                    nn.ReLU(),#)\n",
    "                    #self.layer7 = nn.Sequential(\n",
    "                    nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                    #nn.BatchNorm2d(256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "                self.fc = nn.Sequential(\n",
    "                    #nn.Dropout(0.5),\n",
    "                    nn.Linear(lin_lay, 4096), # 1032192 and 4096x4096)\n",
    "                    nn.ReLU())\n",
    "                self.fc1 = nn.Sequential(\n",
    "                    #nn.Dropout(0.5),\n",
    "                    nn.Linear(4096, 4096),\n",
    "                    nn.ReLU())\n",
    "                self.fc2= nn.Sequential(\n",
    "                    nn.Linear(4096, num_classes))\n",
    "                \n",
    "            def forward(self, x):\n",
    "                out = self.layer1(x)\n",
    "                #out = self.layer2(out)\n",
    "                #out = self.layer3(out)\n",
    "                #out = self.layer4(out)\n",
    "                #out = self.layer5(out)\n",
    "                #out = self.layer6(out)\n",
    "                #out = self.layer7(out)\n",
    "                #PrintLayer()\n",
    "                out = out.reshape(out.size(0), -1)\n",
    "                out = out.flatten(start_dim=1)\n",
    "                #PrintLayer()\n",
    "                out = self.fc(out)\n",
    "                out = self.fc1(out)\n",
    "                out = self.fc2(out)\n",
    "                out = F.log_softmax(out, dim=1) \n",
    "                return out\n",
    "        vgg = VGG16Smaller(lin_lay)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87383b",
   "metadata": {},
   "source": [
    "452 144 5/452 *100 = 1%\n",
    "226 72 5/226 *100 = 2%\n",
    "113 36 5/113 *100 = 4% -- 2/113 *100= 1.7% ~ 2%\n",
    "57 18 (56.5,) 5/57 *100 = 8% -- 2/57 *100 = 3.5% ~ 4%. 1/57 = 1.75%\n",
    "29 9 (28.5,) 5/29 *100 = 17% -- 2/29 *100 = 6.89 ~ 7% 1/28 = 3.57 ~ 4%\n",
    "15 5 (14.5, 4.5)\n",
    "8 3 (7.5,2.5)\n",
    "4, 2 (, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87dc8393-e7da-43eb-b0e7-b11c4a46c8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \n",
    "\n",
    "Pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def save2csv_nest_dict(nested_dict, file_name, save_location:str):\n",
    "    # flattern nested dictionary\n",
    "    flatterend_dict = {}\n",
    "    for k,v in nested_dict.items():\n",
    "        if isinstance(v, dict):\n",
    "            for nested_key, nested_val in v.items():\n",
    "                flatterend_dict[f\"{k}_{nested_key}\"] = nested_val\n",
    "        else:\n",
    "            flatterend_dict[k] =v\n",
    "    \n",
    "    columns = list(flatterend_dict.keys())\n",
    "    \n",
    "    with open(save_location+str(file_name)+'.csv', \"a+\", newline=\"\") as f:\n",
    "        # using dictwriter\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        # using writeheader function\n",
    "        if f.tell() == 0:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(flatterend_dict)\n",
    "        f.close()\n",
    "\n",
    "# check dictionary values for json and csv\n",
    "\n",
    "def check_obj4np(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: check_obj4np(value) for key, value in obj.items()}\n",
    "    if isinstance(obj,list):\n",
    "        return [check_obj4np(item) for item in obj]\n",
    "    if isinstance(obj,np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# save to json\n",
    "def save2josn_nested_dict(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    with open(save_location+str(file_name)+'.json', 'a+') as f:\n",
    "        f.write(json_obj)\n",
    "        f.close()\n",
    "\n",
    "    \n",
    "#save_location+str(file_name)+'.csv'\n",
    "def save2csv(nested_dict, file_name, save_location:str):\n",
    "    \n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    \n",
    "    columns = list(nested_dict.keys())\n",
    "    path = os.path.join(save_location, file_name +\".csv\")\n",
    "    try:\n",
    "        with open(path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            # using dictwriter\n",
    "            # using writeheader function\n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(nested_dict)\n",
    "            f.close()\n",
    "    except IOError as e:\n",
    "        print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "    except ValueError:\n",
    "              print(\"could not convert to string\")\n",
    "    except:\n",
    "              print(\"unexpected error: \", sys.exc_info()[0])\n",
    "        \n",
    "\n",
    "def save2json(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    #print(nested_dict)\n",
    "    #print(nested_dict.items())\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    #print(json_obj)\n",
    "    path = os.path.join(save_location, file_name+\".json\")\n",
    "    #print(path)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(json_obj)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def read_in_json(file_path, file_name):\n",
    "    path = os.path.join(file_path, 'file_name')\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            #obj = f.read()\n",
    "            dj = json.load(f, object_pairs_hook= collections.OrderedDict) #obj, \n",
    "            #print(dj)\n",
    "    except Exception as e:\n",
    "        print(\"Error decoding Json\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "class Flattern(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flattern, self).__init__()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.flatten()\n",
    "        return x\n",
    "\n",
    "\n",
    "def choose_model(model_name, lin_lay, dropout):\n",
    "\n",
    "    if model_name == '4c3l':\n",
    "        return smallnet1(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '3c2l':\n",
    "        return smallnet2(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks = (3,5), dropout=dropout)\n",
    "    elif model_name == '2c2l':\n",
    "        return smallnet3(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '7c3l':\n",
    "        return sevennet(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == 'vgg16':\n",
    "        #self.flatten = nn.Flatten()\n",
    "        model_vgg16 = vgg16()\n",
    "        vgg_feats = model_vgg16.features\n",
    "        vgg_classifier = model_vgg16.classifier\n",
    "        vgg_classifier.pop(6)\n",
    "\n",
    "        vgg = nn.Sequential(\n",
    "            vgg_feats,\n",
    "            nn.Flatten(),\n",
    "            vgg_classifier,\n",
    "            nn.Linear(4096,11), # cheanging the output layer\n",
    "            nn.Softmax(dim=0),  \n",
    "            )\n",
    "        \n",
    "        \n",
    "        return vgg\n",
    "    else:\n",
    "        print('Model Name Not Recognised')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_model_sizes_bits(model):\n",
    "    bits = 32\n",
    "    mods = list(model.modules())\n",
    "    sizes = []\n",
    "    total_bits = 0\n",
    "    \n",
    "    for i in range(1,len(mods)):\n",
    "        m = mods[i]\n",
    "        p = list(m.parameters())\n",
    "        for j in range(len(p)):\n",
    "            sizes.append(np.array(p[j].size()))\n",
    "    \n",
    "    for i in range(len(sizes)):\n",
    "        s = sizes[i]\n",
    "        bitz = np.prod(np.array(s))*bits\n",
    "        total_bits += bitz\n",
    "    total_bytes = total_bits/8\n",
    "    total_megabytes = total_bytes/1e+6\n",
    "    total_gigabytes = total_megabytes/1000\n",
    "    print(total_bits, 'bits    ', total_bytes, \"bytes    \", total_megabytes, \"MegaBytes    \", total_gigabytes,\"GigaBytes\") # 148480\n",
    "\n",
    "\n",
    "def ptrblk_fin_mod_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    size_all_gb = size_all_mb/953.674\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))\n",
    "    print('model size: {:.3f}GB'.format(size_all_gb))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "495f38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_batch(model, train, val, loop_run_name, save_dict, lr, loss_fn, epochs, batch_size, optimizer, scheduler_value, device): #train_dl, val_dl, \n",
    "    #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3) \n",
    "    model.train()\n",
    "    \n",
    "\n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "    sample = False\n",
    "    \n",
    "    \n",
    "    total_epochs = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        if epoch == 1:\n",
    "            sample = True\n",
    "            random_value = random.randrange(0,batch_size)\n",
    "        else:\n",
    "            random_value = None\n",
    "            sample = False\n",
    "        #print(random_value)\n",
    "\n",
    "        \n",
    "        print('Training...')\n",
    "        #!nvidia-smi\n",
    "        #print(len(train)) #Using a target size \n",
    "\n",
    "        \n",
    "        t_loss, train_prediction, train_targets, t_correct, model, optimizer = loop_batch(model, train, loss_fn, batch_size,sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =optimizer, scheduler= scheduler_value, train =True) #, scheduler =scheduler\n",
    "        print('training..  2')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        t_loss_list.append(t_loss)\n",
    "        [t_predict_list.append(pred.argmax()) for pred in train_prediction]\n",
    "        wandb.log({'t_loss':t_loss})\n",
    "    \n",
    "        train_acc = (t_correct/(len(train)*batch_size)*100) ###\n",
    "        print('train accuracy: ', train_acc )\n",
    "        t_accuracy_list.append(train_acc)\n",
    "        wandb.log({'train_acc':train_acc})\n",
    "        \n",
    "        \n",
    "            \n",
    "        print('validating...')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        v_loss, val_prediction, val_targets, val_correct= loop_batch(model, val, loss_fn, batch_size,sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =None, scheduler= None, train =False)\n",
    "\n",
    "        v_loss_list.append(v_loss)\n",
    "        [v_predict_list.append(pred.argmax()) for pred in val_prediction]\n",
    "        wandb.log({'v_loss':v_loss})\n",
    "        \n",
    "        val_acc = (val_correct/(len(val)*batch_size)*100)\n",
    "        v_accuracy_list.append(val_acc)\n",
    "        print('validation accuracy: ', val_acc )\n",
    "        wandb.log({'val_acc':val_acc})\n",
    "    \n",
    "        total_epochs += 1\n",
    "        \n",
    "    save_dict['Current_Epoch'] = epochs\n",
    "    save_dict['training_samples'] = len(train)\n",
    "    save_dict['validation_samples'] = len(val)\n",
    "    \n",
    "    save_dict['t_accuracy_list'] = t_accuracy_list \n",
    "    save_dict['v_accuracy_list'] = v_accuracy_list  #\n",
    "            \n",
    "    #model = best_model\n",
    "    save_dict['t_loss_list'] = t_loss_list\n",
    "    save_dict['v_loss_list'] = v_loss_list\n",
    "    \n",
    "    save_dict['t_labels'] = train_targets\n",
    "    save_dict['v_labels'] = val_targets\n",
    "    \n",
    "    save_dict['t_predict_list'] = t_predict_list \n",
    "    save_dict['v_predict_list'] = v_predict_list  #\n",
    "    \n",
    "    return model, save_dict\n",
    "\n",
    "from functions import ImageProcessor\n",
    "\n",
    "def loop_batch(model, data, loss_fn, batch_size, sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =None, scheduler= None, train =True):\t# Train and Val loops. Default is train\n",
    "    model = model\n",
    "    total_samples = len(data)\n",
    "    #scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=scheduler_value) \n",
    "    if train:\n",
    "        model.train()\n",
    "        where ='tra'\n",
    "        #lr_ls = []\n",
    "    else:\n",
    "        model.eval()   #  (torch.Size([16, 11])) that is different to the input size (torch.Size([11]))\n",
    "        where = 'val'\n",
    "\n",
    "    predict_list = []\n",
    "    total_count = 0\n",
    "    num_correct = 0\n",
    "    current_loss = 0\n",
    "    labels =[]\n",
    "\n",
    "    \n",
    "    for i, batch in enumerate(data,0):\n",
    "        #print('loop batch 1')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        if sample == True:\n",
    "            IP = ImageProcessor(device) #img, scale:int, save_dict;dict, epoch:int, where:str\n",
    "            i = IP.view(x_batch[random_value],1, loop_run_name, save_dict, epoch, where)\n",
    "            # \n",
    "            sample= False\n",
    "\n",
    "        #print(\"x_batch item check \", x_batch[0].shape)\n",
    "        #print(\"y_batch item check \", y_batch[0].shape)\n",
    "        #print(\"-----   x batch shape   -----\",x_batch.shape) #torch.Size([16, 3, 144, 462])\n",
    "\n",
    "        #print(x_batch[0].shape) # torch.Size([3, 144, 462])\n",
    "        #print(y_batch[0].shape) # torch.Size([11])\n",
    "\n",
    "        #print('loop batch 2')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        \n",
    "        \n",
    "        prediction = model.forward(x_batch)\n",
    "\n",
    "        #print(prediction.shape)  # torch.Size([11])\n",
    "        #print(y_batch.shape)     # torch.Size([16, 11])\n",
    "\n",
    "        #print('loop batch 3')\n",
    "        #!nvidia-smi\n",
    "        #print(\"checking range nums  \", len(y_batch), len(y_batch)-1)\n",
    "        #print(\"len x batch \", len(x_batch))\n",
    "        #print(\"len prediction \", len(prediction))\n",
    "        #print(\"prediction  \", prediction.argmax(), prediction.shape)\n",
    "        #print(\"prediction[1]\", prediction[1].argmax())\n",
    "        #print(\"y batch[1]\", y_batch[1].argmax(), y_batch[1].shape)\n",
    "\n",
    "        loss = loss_fn(prediction, y_batch)\n",
    "        \n",
    "        #print('loop batch 4')\n",
    "        #!nvidia-smi\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #print('loop batch 5')\n",
    "        #!nvidia-smi\n",
    "            \n",
    "        #[predict_list.append(pred.argmax()) for pred in prediction]#.argmax())\n",
    "        #[labels.append(y.argmax()) for y in y_batch]\n",
    "        \n",
    "        \n",
    "        for i in range(len(y_batch)-1):\n",
    "            \n",
    "            #print(\"y \",y_batch[i].argmax())\n",
    "            #print(\"pred \", prediction[i].argmax())\n",
    "            if y_batch[i].argmax() == prediction[i].argmax():\n",
    "                num_correct +=1\n",
    "            [predict_list.append(pred.argmax()) for pred in prediction]#.argmax())\n",
    "            [labels.append(y.argmax()) for y in y_batch]\n",
    "\n",
    "        \"\"\"\n",
    "        if y_batch[i].argmax() == prediction[i].argmax():\n",
    "        IndexError: index 11 is out of bounds for dimension 0 with size 11\n",
    "        \"\"\"\n",
    "\n",
    "        total_count+= batch_size\n",
    "        current_loss += loss.item()\n",
    "\n",
    "        #print('loop batch 6')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "    if scheduler and scheduler >0:\n",
    "        scheduler.step()\n",
    "\n",
    "    if train:\n",
    "        return current_loss, predict_list, y_batch, num_correct, model, optimizer #, lr_ls\n",
    "    else:\n",
    "        return current_loss, predict_list, y_batch, num_correct\n",
    "\n",
    "\n",
    "def test_loop(model, model_name, X, Y, res, pad, save_dict, loss_fn, device, av_lum, num_classes=11):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    current_loss = 0\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    colour ='colour'\n",
    "    size =  res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print('Testing...') \n",
    "        for idx, img in enumerate(X):\n",
    "\n",
    "            #image pre processing\n",
    "            prepro = ImageProcessor(device)\n",
    "            if model_name == 'vgg16':\n",
    "                tense = prepro.colour_size_tense(img, colour, size, av_lum, pad, vg=True) #[29, 9], 15, 5, [8,3]\n",
    "            elif (model_name == '7c3l' and size == [29, 9]) or (model_name == '7c3l' and size == [15, 5]) or (model_name == '7c3l' and size ==[8, 3]):\n",
    "                tense = prepro.colour_size_tense(img, colour, size, av_lum, pad, vg=True)\n",
    "            else:\n",
    "                tense = prepro.colour_size_tense(img, colour, size,av_lum,  pad)\n",
    "\n",
    "\n",
    "            tense = tense.unsqueeze(dim=0)\n",
    "\n",
    "            prediction = model.forward(tense)\n",
    "            label = label_oh_tf(Y[idx], num_classes).to(device)\n",
    "\n",
    "            label = label.unsqueeze(dim=0)\n",
    "\n",
    "            loss = loss_fn(prediction, label)\n",
    "\n",
    "            if prediction.argmax()==label.argmax():\n",
    "                num_correct +=1\n",
    "            total_count +=1\n",
    "            correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "\n",
    "            predict_list.append(prediction.argmax())\n",
    "\n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        current_loss += loss.item()\n",
    "        \n",
    "    return accuracy, predict_list, Y, current_loss\n",
    "\n",
    "## model, data, loss_fn, device, optimizer =None, scheduler= None, train =True\n",
    "def test_loop_batch(model,data, loss_fn, batch_size, device):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    label_list = []\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data,0):\n",
    "            #tense = tense.to(device)\n",
    "            tense, label = batch\n",
    "            label = label.to(device)\n",
    "            \n",
    "            prediction = model.forward(tense.to(device))\n",
    "            #print('p', prediction.shape, 'l ', label.shape)\n",
    "            #label = label_oh_tf(Y[idx], device, num_classes)\n",
    "            for i in range(len(label)-1):\n",
    "                #print(len(label), label[0].argmax(), len(label)-1)\n",
    "                if label[i].argmax() == prediction[i].argmax():\n",
    "                    num_correct +=1\n",
    "            [predict_list.append(pred.argmax()) for pred in prediction]\n",
    "            [label_list.append(lab.argmax()) for lab in label]\n",
    "            # label[i] == predictoin[i]. \n",
    "    \n",
    "            #if prediction.argmax()==label.argmax():\n",
    "            #    num_correct +=1\n",
    "            total_count += batch_size\n",
    "            #correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "    \n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "\n",
    "        print(accuracy)\n",
    "\n",
    "        #print(len(predict_list), len(label_list))\n",
    "    \n",
    "        #X = list(X)\n",
    "        #log_test_score(acc, accuracy, X) # test_acc,test_predict_list, y_test, test_loss \n",
    "        return accuracy, predict_list, label_list\n",
    "\n",
    "\n",
    "\n",
    "def get_data(random_seed):\n",
    "    file_path =  data_path\n",
    "    #print(file_path)\n",
    "    img_len = len(os.listdir(file_path))\n",
    "    \n",
    "    x, y = import_imagedata(file_path)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "    \n",
    "def get_lin_lay(model_card, resolution):\n",
    "    if resolution == [452, 144]:\n",
    "        lin_lay = model_card['f_lin_lay'][0]\n",
    "    elif resolution == [226, 72]:\n",
    "        lin_lay = model_card['f_lin_lay'][1]\n",
    "    elif resolution == [113, 36]:\n",
    "        lin_lay = model_card['f_lin_lay'][2]\n",
    "    elif resolution == [57, 18]:\n",
    "        lin_lay = model_card['f_lin_lay'][3]\n",
    "    elif resolution == [29, 9]:\n",
    "        lin_lay = model_card['f_lin_lay'][4]\n",
    "    elif resolution == [15, 5]:\n",
    "        lin_lay = model_card['f_lin_lay'][5]\n",
    "    elif resolution == [8, 3]:\n",
    "        lin_lay = model_card['f_lin_lay'][6]\n",
    "    else:\n",
    "        print(\"PARAMETER NOT FOUND: \\n f_lin_lay FROM MODEL CARD\")\n",
    "    return lin_lay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf5ca7f-b59a-427b-8da3-2848fa6d3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def _go(config=None):\n",
    "    #print('1')\n",
    "    #!nvidia-smi\n",
    "    \n",
    "    #print(\"Max allocated memory (GB):\", torch.cuda.max_memory_allocated() / 1024 ** 3)\n",
    "    \n",
    "    if len(gitHASH) <1:\n",
    "        print(\"YOU FORGET THE GIT HASH\")\n",
    "        return\n",
    "    else:\n",
    "        #print('Git Hash registered')\n",
    "        pass\n",
    "        \n",
    "    with wandb.init(config=config, project=f\"Big Loop batching of model 3c3l\", notes=\"big loop batcing 3c2l. 220524.\",):\n",
    "        config = wandb.config\n",
    "        start = time.process_time()\n",
    "            \n",
    "        for model_idx, model_card in enumerate(config['model_cards']):\n",
    "            #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                    \n",
    "            model_name = model_card['model']\n",
    "            model_index = model_card['idx']\n",
    "            dropout = model_card['dropout'] \n",
    "            for res_idx, resolution_card in enumerate(config['resolution_cards']):\n",
    "                #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "            \n",
    "                resolution = resolution_card['resolution']\n",
    "                pad = resolution_card['padding']\n",
    "                lin_lay = get_lin_lay(model_card, resolution)\n",
    "                print('lin lay', lin_lay)\n",
    "            \n",
    "                for lr_idx, lr in enumerate(config['learning_rate_cards']):\n",
    "                    for wd_idx, wd_card in enumerate(wd_cards):\n",
    "                        for sched_idx, scheduler_value in enumerate(config['scheduler_cards']):\n",
    "                            for seed_idx, seed in enumerate(config['seeds']):\n",
    "                                seed = seed\n",
    "                                for lossfn_idx, loss in enumerate(config['loss_fn_cards']):\n",
    "                                    \n",
    "                                    torch.cuda.empty_cache()\n",
    "                                    #print('2')\n",
    "                                    #!nvidia-smi\n",
    "  \n",
    "                                    config['batch_size']\n",
    "\n",
    "                                    print('Model: ', str(model_name), f\" idx: {model_idx} / {len(config.model_cards)}\")\n",
    "                                    print('resolution: ', str(resolution), f\" idx: {res_idx} / {len(config['resolution_cards'])}\")\n",
    "                                    print('learning rate: ', str(lr), f\" idx: {lr_idx} / {len(config['learning_rate_cards'])}\")\n",
    "                                    print('weight decay: ', str(wd_card), f\" idx: {wd_idx} / {len(config['wd_cards'])}\")\n",
    "                                    print('scheduler: ', str(scheduler_value), f\" idx: {sched_idx} / {len(config['scheduler_cards'])}\")\n",
    "                                    print('seed: ', str(seed), f\" idx: {seed_idx} / {len(config['seeds'])}\")\n",
    "                                    print('loss function: ', str(loss), f\" idx: {lossfn_idx} / {len(config['loss_fn_cards'])}\")\n",
    "                                    print('Batch size: ', config['batch_size'])\n",
    "                                    print('Training epochs: ', config['epochs'])\n",
    "                                    run_start_time = time.process_time()\n",
    "                                    print('start time: ',run_start_time)\n",
    "   \n",
    "                                    print(time.process_time() - start)\n",
    "\n",
    "                                    epochs = config['epochs'] #40\n",
    "\n",
    "                                    IP = ImageProcessor(device)\n",
    "\n",
    "                                    wandb.log({'gitHash':gitHASH})\n",
    "                                    wandb.log({'Epochs': epochs})\n",
    "                                    \n",
    "                                    #print('3')\n",
    "                                    #!nvidia-smi\n",
    "                                    \n",
    "                                    # set save dictionary\n",
    "                                    save_dict = {'Run' : f\"{model_name}_{resolution}_{date}\",\n",
    "                                                 'Current_Epoch': 0,\n",
    "                                                 'save_location' : _save_location}\n",
    "          \n",
    "                                    model = choose_model(model_name, lin_lay, dropout).to(device)\n",
    "                                    #print(\"Before model init - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                                    #model = smallnet3(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout).to(device)\n",
    "\n",
    "                                    #print('4')\n",
    "                                    #!nvidia-smi\n",
    "\n",
    "                                    print(\"After model init, Before data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "                                    x_train, y_train, x_val, y_val, x_test, y_test = get_data(seed)\n",
    "                                    av_lum = IP.new_luminance(x_train)\n",
    "                                    #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                                    \n",
    "                                    train_ds = IDSWDataSetLoader2(x_train, y_train, resolution,pad,av_lum,model_name, device)# av_lum, res,pad,\n",
    "                                    train = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "\n",
    "                                    \n",
    "                                    test_ds = IDSWDataSetLoader2(x_test, y_test, resolution,pad,av_lum,model_name, device)\n",
    "                                    test = DataLoader(test_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "                                    #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                                    val_ds = IDSWDataSetLoader2(x_val, y_val, resolution,pad,av_lum,model_name, device)\n",
    "                                    val = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "                                    \n",
    "                                    print(\"After data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "\n",
    "                                    #print('5')\n",
    "                                    #!nvidia-smi\n",
    "\n",
    "                                    loss_fn = set_lossfn(loss)\n",
    "                                    \n",
    "                                    # set optimizer\n",
    "                                    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "                                    wandb.watch(model, loss_fn, log='all', log_freq=2, idx = model_index)\n",
    "                                    #print('6')\n",
    "                                    #!nvidia-smi\n",
    "                                    loop_run_name = f\"{save_dict['Run']}_{resolution}_{lr}_{scheduler_value}_{seed}_{loss}\"\n",
    "         \n",
    "                                    model, save_dict=  train_val_batch(model, train,val, loop_run_name,save_dict, lr, loss_fn,epochs, config['batch_size'], optimizer, scheduler_value, device)\n",
    "\n",
    "                                    test_acc,test_predict_list, y_test = test_loop_batch(model,test, loss_fn, config['batch_size'], device) #model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\n",
    "                                    \n",
    "                                    #print(test_predict_list)\n",
    "                                    print(' \\n train Acc: ', save_dict['t_accuracy_list'][-1])\n",
    "                                    print(' \\n val Acc: ', save_dict['v_accuracy_list'][-1])\n",
    "                                    print(' \\n test Acc: ', test_acc)\n",
    "                                    \n",
    "                                    save_dict.update({'test_acc': test_acc})\n",
    "                                    save_dict.update({'test_predict': test_predict_list})\n",
    "                                    save_dict.update({'test_labels': list(y_test)})\n",
    "                                    #save_dict.update({'test_loss':test_loss})\n",
    "\n",
    "                                    \n",
    "\n",
    "\n",
    "                                    learning_curve(save_dict['t_loss_list'], save_dict['v_loss_list'], save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                                    accuracy_curve(save_dict['t_accuracy_list'], save_dict['v_accuracy_list'],save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                                    test_predict_list=[pred.cpu() for pred in test_predict_list]\n",
    "                                    plot_confusion(predictions= test_predict_list, actual= y_test, title = \"Test Confusion matrix\", run_name = loop_run_name,save_location =save_dict['save_location'])\n",
    "                                    \n",
    "                                    wandb.log({'test_acc': test_acc})\n",
    "                                    wandb.log({'test_predict': test_predict_list})\n",
    "                                    wandb.log({'test_labels': list(y_test)})\n",
    "                                    #saving\n",
    "                                    diction = {}\n",
    "                                    d = date.today()\n",
    "                                    d=str(d)\n",
    "                                    diction.update({'Date':d})\n",
    "                                    diction.update({'gitHASH':str(gitHASH)})\n",
    "                                    diction.update({'model_name': str(model_name)})\n",
    "                                    diction.update({'loss_fn': str(loss)})\n",
    "                                    diction.update({'lr': str(lr)})\n",
    "                                    diction.update({'wd': str(wd_card)})\n",
    "                                    diction.update({'scheduler value': str(scheduler_value)})\n",
    "                                    diction.update({'seed': str(seed)})\n",
    "                                    diction.update({'resolution': str(resolution)})\n",
    "                                    diction.update({'pad': int(pad)})\n",
    "                                    diction.update({'lin_lay': int(lin_lay)})\n",
    "                                    diction.update({'run time': (time.process_time() - run_start_time)})\n",
    "                                    diction.update(save_dict)\n",
    "                                    \n",
    "                                    save_location = save_dict['save_location']\n",
    "                                    title = save_dict['Run']\n",
    "                                    save2json(diction, loop_run_name, save_location)\n",
    "                                    save2csv(diction, title, save_location)\n",
    "        \n",
    "                                    diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "        \n",
    "                                    with open(f\"{save_location}{loop_run_name}.pkl\", 'wb+') as f:\n",
    "                                        pickle.dump(diction, f)\n",
    "                                    \n",
    "                                    clear_output()\n",
    "                                    \n",
    "                                    print(f' \\n END {model_name} {resolution} Run Time: ',time.process_time() - run_start_time)\n",
    "                                    #!nvidia-smi\n",
    "                                    torch.cuda.empty_cache()\n",
    "        print('Final Run time: ',time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d7d27-ef9d-43d9-98a8-1f11ff50090d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/its/home/nn268/antvis/antvis/optics/Batchcode/wandb/run-20240603_100215-dxslrrx5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antvis/Big%20Loop%20batching%20of%20model%203c3l/runs/dxslrrx5' target=\"_blank\">blooming-dragon-81</a></strong> to <a href='https://wandb.ai/antvis/Big%20Loop%20batching%20of%20model%203c3l' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antvis/Big%20Loop%20batching%20of%20model%203c3l' target=\"_blank\">https://wandb.ai/antvis/Big%20Loop%20batching%20of%20model%203c3l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antvis/Big%20Loop%20batching%20of%20model%203c3l/runs/dxslrrx5' target=\"_blank\">https://wandb.ai/antvis/Big%20Loop%20batching%20of%20model%203c3l/runs/dxslrrx5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin lay 200704\n",
      "Model:  vgg16  idx: 0 / 1\n",
      "resolution:  [57, 18]  idx: 0 / 4\n",
      "learning rate:  0.1  idx: 0 / 5\n",
      "weight decay:  0  idx: 0 / 1\n",
      "scheduler:  0  idx: 0 / 1\n",
      "seed:  8  idx: 0 / 3\n",
      "loss function:  MSE  idx: 0 / 2\n",
      "Batch size:  64\n",
      "Training epochs:  60\n",
      "start time:  10.084538816\n",
      "0.0010985029999996954\n",
      "After model init, Before data loading - Current allocated memory (GB): 0.0\n",
      "After data loading - Current allocated memory (GB): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.555288461538462\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎                    | 1/60 [07:00<6:53:41, 420.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training..  2\n",
      "train accuracy:  8.713942307692307\n",
      "validating...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▋                    | 2/60 [14:03<6:47:52, 421.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.735576923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█                    | 3/60 [21:02<6:39:24, 420.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█▍                   | 4/60 [28:04<6:33:04, 421.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.238636363636363\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.555288461538462\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█▊                   | 5/60 [35:00<6:24:17, 419.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.89423076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██                   | 6/60 [42:00<6:17:33, 419.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.653846153846153\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██▍                  | 7/60 [49:06<6:12:32, 421.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.238636363636363\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.954326923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██▊                  | 8/60 [56:13<6:07:01, 423.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.194711538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██▊                | 9/60 [1:03:12<5:58:34, 421.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.29326923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███               | 10/60 [1:10:07<5:49:57, 419.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.774038461538462\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███▎              | 11/60 [1:17:08<5:43:13, 420.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.555288461538462\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███▌              | 12/60 [1:24:07<5:35:54, 419.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.89423076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███▉              | 13/60 [1:31:07<5:28:47, 419.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.67548076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████▏             | 14/60 [1:38:06<5:21:42, 419.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.134615384615383\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████▌             | 15/60 [1:45:04<5:14:17, 419.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.353365384615383\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████▊             | 16/60 [1:52:03<5:07:23, 419.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.85576923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████             | 17/60 [1:59:01<5:00:04, 418.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████▍            | 18/60 [2:05:50<4:50:59, 415.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.413461538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████▋            | 19/60 [2:12:46<4:44:18, 416.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.413461538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████            | 20/60 [2:19:46<4:38:08, 417.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████▎           | 21/60 [2:26:39<4:30:20, 415.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.795673076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████▌           | 22/60 [2:33:32<4:22:53, 415.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.194711538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████▉           | 23/60 [2:40:25<4:15:26, 414.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.014423076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████▏          | 24/60 [2:47:22<4:09:06, 415.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.238636363636363\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.194711538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████▌          | 25/60 [2:54:16<4:01:56, 414.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.194711538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████▊          | 26/60 [3:01:19<3:56:32, 417.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.915865384615383\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████          | 27/60 [3:08:15<3:49:17, 416.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.473557692307693\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████▍         | 28/60 [3:15:19<3:43:24, 418.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.948863636363637\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.533653846153847\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████▋         | 29/60 [3:22:18<3:36:32, 419.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.314903846153847\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████         | 30/60 [3:29:19<3:29:48, 419.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.096590909090908\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.735576923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████▎        | 31/60 [3:36:23<3:23:24, 420.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.495192307692307\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████▌        | 32/60 [3:43:08<3:14:10, 416.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.07451923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████▉        | 33/60 [3:50:10<3:08:01, 417.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.07451923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████▏       | 34/60 [3:57:03<3:00:31, 416.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.713942307692307\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████▌       | 35/60 [4:04:02<2:53:53, 417.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████▊       | 36/60 [4:10:57<2:46:39, 416.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.435096153846153\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████       | 37/60 [4:17:55<2:39:48, 416.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.238636363636363\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.774038461538462\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████▍      | 38/60 [4:24:58<2:33:34, 418.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.014423076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████▋      | 39/60 [4:32:06<2:27:31, 421.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.713942307692307\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████      | 40/60 [4:39:10<2:20:44, 422.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.07451923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████▎     | 41/60 [4:46:13<2:13:47, 422.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.314903846153847\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████▌     | 42/60 [4:53:07<2:05:56, 419.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.173076923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████▉     | 43/60 [5:00:06<1:58:51, 419.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████▏    | 44/60 [5:07:06<1:51:55, 419.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.254807692307693\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████▌    | 45/60 [5:14:05<1:44:51, 419.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.89423076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████▊    | 46/60 [5:20:52<1:37:04, 416.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.653846153846153\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████    | 47/60 [5:28:00<1:30:52, 419.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.014423076923077\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████▍   | 48/60 [5:35:05<1:24:14, 421.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  7.954545454545454\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.254807692307693\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████▋   | 49/60 [5:41:59<1:16:48, 418.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.533653846153847\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████   | 50/60 [5:48:59<1:09:53, 419.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.615384615384617\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████▎  | 51/60 [5:55:54<1:02:41, 417.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.653846153846153\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████▎  | 52/60 [6:03:01<56:04, 420.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.555288461538462\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████▋  | 53/60 [6:10:12<49:27, 423.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.948863636363637\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "_go(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964b31e-4bae-4f65-bc46-ee1334a8f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.04 GiB is free\n",
    "23.65-8.04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59daceaa-fa47-4c76-90d6-f23550f85694",
   "metadata": {},
   "source": [
    "\n",
    "pred torch.Size([11])\n",
    "\n",
    "lab  torch.Size([5, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5d251-dbcc-482b-aac0-ac24617279e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = choose_model('vgg16', 200704, 0)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0ade6-cd6d-46db-ac95-6b368cbea443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
