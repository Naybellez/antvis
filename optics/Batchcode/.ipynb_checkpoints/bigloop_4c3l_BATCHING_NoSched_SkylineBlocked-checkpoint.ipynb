{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4fd19-5a09-4232-bdc4-42bbef0b6802",
   "metadata": {},
   "source": [
    "last updated 07 11 24\n",
    "\n",
    "This notebook is to get the run times for each model on the highets and lowest Resolutions; to estimate an average run time.IG DICITONARY!\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6be64f-3efe-4c20-885c-1333846ffbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a364e97a-adf8-4aa3-aadf-a32df7852d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I want to load in a model\n",
    "# and then test it! on blocked skyline images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6dbd95-2129-42b5-b70b-ee9f057b24c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16\n",
    "#import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg16\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch.Utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import collections\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "from functions import import_imagedata, ImageProcessor, label_oh_tf, IDSWDataSetLoader8\n",
    "from fns4wandb import set_lossfn\n",
    "from architectures import sevennet, smallnet1, smallnet2, smallnet3, PrintLayer\n",
    "#from architectures import , smallnet3\n",
    "from loop_fns import loop#, loop_batch, test_loop_batch\n",
    "from plotting import learning_curve, accuracy_curve, plot_confusion\n",
    "from modelManagment import get_lin_lay, choose_model2\n",
    "\n",
    "import copy\n",
    "\n",
    "from modelManagment import get_lin_lay, choose_model\n",
    "from functions import get_data\n",
    "from loop_fns import train_val_batch, test_loop_batch\n",
    "from fileManagment import save2csv, save2json\n",
    "\n",
    "#import torch.Utils.data.DataLoader as DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6ace79-5b6a-4955-9fd3-52aeaddf0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = torch.cuda.memory_summary(device, abbreviated=False)\n",
    "#Pp = pprint.PrettyPrinter(indent=4)\n",
    "#Pp.pprint(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c1e605-9a3b-48dc-a38e-8a955bd3c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "_save_location = r'/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/BlockSkyLine/4c/' #vgg16\n",
    "\n",
    "data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "\n",
    "gitHASH = '3e1975b1ac9d8c07dae424e08dacb2d2ce5f54f9'\n",
    "\n",
    "\n",
    "\n",
    "load_in_model = False\n",
    "dir_pkl = f\"/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/schedulerRuns/4c/70E/\"\n",
    "#pkl_name = f\"{model_name}_{resolution}_2024-11-19_{optimmy}_{int(config['start_epoch'])}E_{Var_WB_sched}_{resolution}_{str(lr)}_{str(wd_card)}_{seed}_CrossEntropy.pkl\"\n",
    "\n",
    "\n",
    "pkl_name_57 = \"4c3l_[57, 18]_2025-01-08_Adam_70E_NoSched_run_[57, 18]_0.001_0_42_MSE.pkl\"\n",
    "pkl_name_113 =\"4c3l_[113, 36]_2025-01-08_Adam_70E_NoSched_run_[113, 36]_0.001_0_42_MSE.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1481ccd-4d87-4c05-84d5-77e29ee981b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49eb7e06-506f-48e6-b28c-8caa7641b11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install datetime\n",
    "\n",
    "d = date.today()\n",
    "#print(str(d), type(str(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87383b",
   "metadata": {},
   "source": [
    "452 144 5/452 *100 = 1%\n",
    "226 72 5/226 *100 = 2%\n",
    "113 36 5/113 *100 = 4% -- 2/113 *100= 1.7% ~ 2%\n",
    "57 18 (56.5,) 5/57 *100 = 8% -- 2/57 *100 = 3.5% ~ 4%. 1/57 = 1.75%\n",
    "29 9 (28.5,) 5/29 *100 = 17% -- 2/29 *100 = 6.89 ~ 7% 1/28 = 3.57 ~ 4%\n",
    "15 5 (14.5, 4.5)\n",
    "8 3 (7.5,2.5)\n",
    "4, 2 (, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ddbb49-828b-4de8-a31c-2a576cd736f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries                                                                                  * * * *   SETTINGS   * * * *\n",
    "\n",
    "date = date.today()\n",
    "\n",
    "model_card_vgg = {'name': 'vgg', 'model': 'vgg16',\n",
    "                  'f_lin_lay':[200704,#200704,     #129024,#4096,  # (1x229376 and 25088x4096)  1x229376 and 25088x4096) 1x229376 and 25088x4096)\n",
    "                             200704,      #(16x64512 and 129024x4096)    (16x200704 and 64512x4096)\n",
    "                             14336,\n",
    "                             3584,\n",
    "                             768,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                            ],\n",
    "                 'idx': 0,\n",
    "                 'dropout':0.2}\n",
    "\n",
    "\n",
    "model_card_7c3l = {'name': '7c3l', 'model': '7c3l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[248832,    # 452 144 # p5\n",
    "                            59904,      # 226 72 # p5\n",
    "                            11264,      # 113 36 # p2\n",
    "                            1536,       # 57 18 # p1\n",
    "                            172032,           # 29 9\n",
    "                            172032,          # 15 5\n",
    "                            172032,         # 8 3\n",
    "                              ], \n",
    "                   'idx': 1,\n",
    "                  'dropout':0.2}\n",
    "\n",
    "\n",
    "\n",
    "model_card_4c3l = {'name': '4c3l', 'model': '4c3l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[539904,# 1055232,#539904,    # 452 144 # p5  (64x539904 and 1055232x100)\n",
    "                             141056, #141056,    # 226 72 # p5   64x141056 and 267264x100)\n",
    "                             34560, #35840,     # 113 36 # p2   (64x35840 and 304640x100)\n",
    "                             9984,      # 57 18 # p1 \n",
    "                             2304,      # 29 9\n",
    "                             512,       # 15 5\n",
    "                             256],      # 8 3\n",
    "                  'idx': 2,\n",
    "                  'dropout':0.2}      \n",
    "\n",
    "model_card_3c2l = {'name': '3c2l', 'model': '3c2l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[1069888,    # 452 144 # p5\n",
    "                             274688,     #226 72 # p5\n",
    "                             68096,      # 113 36 # p2\n",
    "                             17280,      # 57 18 # p1\n",
    "                             3840,       # 29 9\n",
    "                             960,        # 15 5\n",
    "                             256],\n",
    "                  'idx': 3,\n",
    "                  'dropout':0.2}       # 8 3\n",
    "\n",
    "model_card_2c2l = {'name': '2c2l', 'model': '2c2l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[1055232 , #1032192,# 16883712,#33767424,    # 452 144 # p5 # (1x33767424 and 1055232x100) (1x5276160 and 15828480x100) 1x33767424 and 5276160x100)\n",
    "                             267264,     #226 72 # p5                   (1x1032192 and 64512x100)\n",
    "                             64512,#   1032192,#64512,      # 113 36 # p2    ### (16x1055232 and 1032192x100) ###  16x1055232 and 1032192x100)\n",
    "                             15552,      # 57 18 # p1\n",
    "                             3072,       # 29 9\n",
    "                             640,        # 15 5\n",
    "                             128],\n",
    "                  'idx': 4,\n",
    "                  'dropout':0.1}       # 8 3\n",
    "\n",
    "resolution_card_452144 = {'resolution':[452,144], 'padding':5, 'index':0}\n",
    "resolution_card_22672 = {'resolution':[226,72], 'padding':5, 'index':1}\n",
    "resolution_card_11336 = {'resolution':[113,36], 'padding':2, 'index':2}\n",
    "resolution_card_5715 = {'resolution':[57,18], 'padding':1, 'index':3}\n",
    "\n",
    "resolution_card_299 = {'resolution':[29,9], 'padding':0, 'index':4} # \n",
    "resolution_card_155 = {'resolution':[15,5], 'padding':0, 'index':5}\n",
    "resolution_card_83 = {'resolution':[8,3], 'padding':0, 'index':6}\n",
    "\n",
    "\n",
    "\n",
    "resolution_cards = [resolution_card_11336, resolution_card_5715]\n",
    "                      #[resolution_card_11336, resolution_card_5715,,resolution_card_155\n",
    "#resolution_card_299, resolution_card_155, resolution_card_83]#]#resolution_card_452144, \n",
    "#resolution_cards = [resolution_card_11336]\n",
    "\n",
    "#learning_rate_cards = [5e-5, 6e-5, 8e-5]\n",
    "#learning_rate_cards = [8.21592E-05, 6.62E-05, 6.01E-05, 5.97E-05]\n",
    "#learning_rate_cards=  [1e-3] #[0.1,0.01, 1e-3,1e-4, 1e-5]#, 6e-5, 7e-5, 8e-5]\n",
    "#wd_cards = [4e-5, 5e-5, 3.00E-05, 2.00E-05]\n",
    "#wd_cards =[0]\n",
    "#scheduler_cards = [0]#, 0.1, 0.2]\n",
    "\n",
    "seeds = [8,2,4, 42]#,2,3] # 4, 5,6\n",
    "\n",
    "#model_cards =[model_card_vgg, model_card_7c3l, model_card_4c3l, model_card_3c2l, model_card_2c2l]\n",
    "model_cards =[model_card_4c3l]\n",
    "\n",
    "#loss_fn_cards = ['MSE'] #,'CrossEntropy' \n",
    "                        \n",
    "config = dict({'parameters': 'parameters for big loop run'})\n",
    "config.update({'model_cards':model_cards})\n",
    "config.update({'resolution_cards':resolution_cards})\n",
    "#config.update({'learning_rate_cards':learning_rate_cards})\n",
    "#config.update({'wd_cards':wd_cards})\n",
    "#config.update({'scheduler_cards':scheduler_cards})\n",
    "config.update({'seeds':seeds})\n",
    "#config.update({'loss_fn_cards': loss_fn_cards})\n",
    "\n",
    "\n",
    "config.update({'batch_size': 64})\n",
    "config.update({'epochs': 60}) #60\n",
    "\n",
    "#print(model_card_vgg)\n",
    "#print('')\n",
    "#Pp.pprint(Config) # dictionary of dictionaries of lists and lists of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf5ca7f-b59a-427b-8da3-2848fa6d3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def _go(config=None):\n",
    "    if len(gitHASH) <1:\n",
    "        print(\"YOU FORGET THE GIT HASH\")\n",
    "        return\n",
    "    else:\n",
    "        #print('Git Hash registered')\n",
    "        pass\n",
    "\n",
    "    start = time.process_time()\n",
    "        \n",
    "    for model_idx, model_card in enumerate(config['model_cards']):\n",
    "\n",
    "        model_name = model_card['model']\n",
    "        model_index = model_card['idx']\n",
    "        dropout = model_card['dropout'] \n",
    "        for res_idx, resolution_card in enumerate(config['resolution_cards']):\n",
    "            resolution = resolution_card['resolution']\n",
    "            pad = resolution_card['padding']\n",
    "            lin_lay = get_lin_lay(model_card, resolution)\n",
    "            print('lin lay', lin_lay)\n",
    "        \n",
    "            for seed_idx, seed in enumerate(config['seeds']):\n",
    "                seed = seed\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                config['batch_size']\n",
    "\n",
    "                print('Model: ', str(model_name), f\" idx: {model_idx} / {len(config['model_cards'])}\")\n",
    "                print('resolution: ', str(resolution), f\" idx: {res_idx} / {len(config['resolution_cards'])}\")\n",
    "                print('seed: ', str(seed), f\" idx: {seed_idx} / {len(config['seeds'])}\")\n",
    "                print('Batch size: ', config['batch_size'])\n",
    "                \n",
    "\n",
    "                run_start_time = time.process_time()\n",
    "                print('start time: ',run_start_time)\n",
    "\n",
    "                print(time.process_time() - start)\n",
    "\n",
    "                IP = ImageProcessor(device)\n",
    "\n",
    "\n",
    "                save_dict = {'Run' : f\"{model_name}_{resolution}_{date}_BlockSkyLine_test\",\n",
    "                             'Current_Epoch': 0,\n",
    "                             'save_location' : _save_location}\n",
    "\n",
    "                model = choose_model2(model_name, lin_lay, dropout).to(device)\n",
    "                if load_in_model:\n",
    "                    if resolution == \"[57, 18]\":\n",
    "                        pkl_name = pkl_name_57\n",
    "\n",
    "                    elif resolution == \"[113, 32]\":\n",
    "                        pkl_name_113\n",
    "                    else:\n",
    "                        print(\"Resolution not recognised!\")\n",
    "                    with open(dir_pkl+pkl_name, 'rb') as f:\n",
    "                        model_pkl = pickle.load(f)\n",
    "                    #model_pkl = pickle.load(dir_pkl+pkl_name)\n",
    "                    model.load_state_dict(model_pkl['model.state_dict'])\n",
    "                # this is where is load in a pretrained model\n",
    "                #print(\"Before model init - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                #model = smallnet3(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout).to(device)\n",
    "\n",
    "                #print('4')\n",
    "                #!nvidia-smi\n",
    "\n",
    "                #print(\"After model init, Before data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "                x_train, y_train, x_val, y_val, x_test, y_test = get_data(seed,  file_path=data_path)\n",
    "                av_lum = IP.new_luminance(x_train)\n",
    "                #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                \n",
    "                #train_ds = IDSWDataSetLoader8(x_train, y_train, resolution,pad,av_lum,model_name, device)# av_lum, res,pad,\n",
    "                #train = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "\n",
    "                #  img_path, labels, av_lum, transform=None, res = (452, 144), vgg=False\n",
    "                test_ds = IDSWDataSetLoader8(x_test, y_test,av_lum, res=resolution)\n",
    "                test = DataLoader(test_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "\n",
    "                #loss_fn = set_lossfn(loss)\n",
    "\n",
    "                loop_run_name = f\"TEST_SKYLINE_OBTRUSION_{save_dict['Run']}_{resolution}_{seed}\"\n",
    "                #                                                   (model,data, loss_fn, batch_size, device\n",
    "                test_acc,test_predict_list, y_test = test_loop_batch(model,test, loss_fn=None, batch_size=config['batch_size'], device=device) #model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\n",
    "                print(\"in go, after the test_loop_batch, type len  pred:\", type(test_predict_list), len(test_predict_list), \" y_test:\", type(y_test), len(y_test))\n",
    "                #print(test_predict_list)\n",
    "\n",
    "                print(' \\n test Acc: ', test_acc)\n",
    "                \n",
    "                save_dict.update({'test_acc': test_acc})\n",
    "                save_dict.update({'test_predict': test_predict_list})\n",
    "                save_dict.update({'test_labels': list(y_test)})\n",
    "                #save_dict.update({'test_loss':test_loss})\n",
    "\n",
    "                #test_predict_list=[pred.cpu() for pred in test_predict_list]\n",
    "                plot_confusion(predictions= test_predict_list, actual= y_test, title = \"Test Confusion matrix\", run_name = loop_run_name,save_location =save_dict['save_location'])\n",
    "                \n",
    "                #saving\n",
    "                diction = {}\n",
    "                d = date.today()\n",
    "                d=str(d)\n",
    "                diction.update({'Date':d})\n",
    "                diction.update({'gitHASH':str(gitHASH)})\n",
    "                diction.update({'model_name': str(model_name)})\n",
    "                diction.update({'seed': str(seed)})\n",
    "                diction.update({'resolution': str(resolution)})\n",
    "                diction.update({'pad': int(pad)})\n",
    "                diction.update({'lin_lay': int(lin_lay)})\n",
    "                diction.update({'run time': (time.process_time() - run_start_time)})\n",
    "                diction.update(save_dict)\n",
    "                \n",
    "                save_location = save_dict['save_location']\n",
    "                title = save_dict['Run']\n",
    "                save2json(diction, loop_run_name, save_location)\n",
    "                save2csv(diction, title, save_location)\n",
    "\n",
    "                diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "\n",
    "                with open(f\"{save_location}{loop_run_name}.pkl\", 'wb+') as f:\n",
    "                    torch.save(diction, f)\n",
    "                \n",
    "                clear_output()\n",
    "                \n",
    "                print(f' \\n END {model_name} {resolution} Run Time: ',time.process_time() - run_start_time)\n",
    "                #!nvidia-smi\n",
    "                torch.cuda.empty_cache()\n",
    "    print('Final Run time: ',time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b58d7d27-ef9d-43d9-98a8-1f11ff50090d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin lay 34560\n",
      "Model:  4c3l  idx: 0 / 1\n",
      "resolution:  [113, 36]  idx: 0 / 2\n",
      "seed:  8  idx: 0 / 4\n",
      "Batch size:  64\n",
      "start time:  12.485252338\n",
      "7.376499999978137e-05\n",
      "/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/nn268/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in test bAtch. pred: 64 lab: 2\n",
      "in test bAtch. pred: 128 lab: 4\n",
      "in test bAtch. pred: 192 lab: 6\n",
      "in test bAtch. pred: 256 lab: 8\n",
      "in test bAtch. pred: 320 lab: 10\n",
      "in test bAtch. pred: 384 lab: 12\n",
      "in test bAtch. pred: 448 lab: 14\n",
      "in test bAtch. pred: 512 lab: 16\n",
      "in test bAtch. pred: 576 lab: 18\n",
      "in test bAtch. pred: 640 lab: 20\n",
      "in test bAtch. pred: 704 lab: 22\n",
      "in test bAtch. pred: 768 lab: 24\n",
      "in test bAtch. pred: 832 lab: 26\n",
      "in test bAtch. pred: 896 lab: 28\n",
      "in test bAtch. pred: 960 lab: 30\n",
      "in test bAtch. pred: 1024 lab: 32\n",
      "0.0\n",
      " \n",
      " test Acc:  0.0\n",
      "1024 32\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [32, 1024]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m_go\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 98\u001b[0m, in \u001b[0;36m_go\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     94\u001b[0m save_dict\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_labels\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(y_test)})\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m#save_dict.update({'test_loss':test_loss})\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#test_predict_list=[pred.cpu() for pred in test_predict_list]\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[43mplot_confusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_predict_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest Confusion matrix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloop_run_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_location\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msave_location\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m#saving\u001b[39;00m\n\u001b[1;32m    101\u001b[0m diction \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/antvis/antvis/optics/Batchcode/.././plotting.py:46\u001b[0m, in \u001b[0;36mplot_confusion\u001b[0;34m(predictions, actual, title, run_name, save_location)\u001b[0m\n\u001b[1;32m     43\u001b[0m font1 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserif\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdarkblue\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m16\u001b[39m}\n\u001b[1;32m     44\u001b[0m font2 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserif\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdarkblue\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m15\u001b[39m}\n\u001b[0;32m---> 46\u001b[0m train_epoch_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m disp\u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(train_epoch_matrix, display_labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m])\n\u001b[1;32m     48\u001b[0m disp\u001b[38;5;241m.\u001b[39mplot(cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplasma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [32, 1024]"
     ]
    }
   ],
   "source": [
    "_go(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964b31e-4bae-4f65-bc46-ee1334a8f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.04 GiB is free\n",
    "23.65-8.04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59daceaa-fa47-4c76-90d6-f23550f85694",
   "metadata": {},
   "source": [
    "\n",
    "pred torch.Size([11])\n",
    "\n",
    "lab  torch.Size([5, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5d251-dbcc-482b-aac0-ac24617279e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
