{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4fd19-5a09-4232-bdc4-42bbef0b6802",
   "metadata": {},
   "source": [
    "last updated 11 03 24\n",
    "\n",
    "This notebook is to get the run times for each model on the highets and lowest Resolutions; to estimate an average run time.IG DICITONARY!\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6be64f-3efe-4c20-885c-1333846ffbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364e97a-adf8-4aa3-aadf-a32df7852d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6dbd95-2129-42b5-b70b-ee9f057b24c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg16\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch.Utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import collections\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "from functions import import_imagedata, ImageProcessor, label_oh_tf, IDSWDataSetLoader2\n",
    "from fns4wandb import set_lossfn\n",
    "\n",
    "from loop_fns import loop#, loop_batch, test_loop_batch\n",
    "from plotting import learning_curve, accuracy_curve, plot_confusion\n",
    "\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "\n",
    "#import torch.Utils.data.DataLoader as DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6ace79-5b6a-4955-9fd3-52aeaddf0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = torch.cuda.memory_summary(device, abbreviated=False)\n",
    "#Pp = pprint.PrettyPrinter(indent=4)\n",
    "#Pp.pprint(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c1e605-9a3b-48dc-a38e-8a955bd3c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "_save_location = r'/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/best_mods/' #v\n",
    "\n",
    "data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "\n",
    "gitHASH = ''\n",
    "\n",
    "date = date.today()\n",
    "d = date.today()\n",
    "Pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1481ccd-4d87-4c05-84d5-77e29ee981b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function wandb.wandb_agent.agent(sweep_id, function=None, entity=None, project=None, count=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wandb.login()\n",
    "#wandb login --relogin\n",
    "wandb.agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ddbb49-828b-4de8-a31c-2a576cd736f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries                                                                                  * * * *   SETTINGS   * * * *\n",
    "\n",
    "\n",
    "#model_name = model_card['model']\n",
    "model_card_vgg_452 = {'name': 'vgg452',\n",
    "                      'model': 'vgg16',\n",
    "                      'f_lin_lay':[200704],\n",
    "                      'dropout':0.2,\n",
    "                      'pad': 5,\n",
    "                      'Epochs': 60,\n",
    "                      'loss_fn': \"MSE\",\n",
    "                      'lr': 0.0001,\n",
    "                      'seed' : 8,\n",
    "                      'resolution': [452, 144]\n",
    "                     }\n",
    "\n",
    "model_card_vgg_226 = {'name': 'vgg226',\n",
    "                      'model': 'vgg16',\n",
    "                      'f_lin_lay':[200704],\n",
    "                      'dropout':0.2,\n",
    "                      'pad': 5,\n",
    "                      'Epochs': 60,\n",
    "                      'loss_fn': \"MSE\",\n",
    "                      'lr': 0.0001,\n",
    "                      'seed' : 2,\n",
    "                      'resolution': [226, 72]\n",
    "                     }\n",
    "\n",
    "\n",
    "model_card_vgg_113 = {'name': 'vgg113',\n",
    "                      'model': 'vgg16',\n",
    "                      'f_lin_lay':[200704],\n",
    "                      'dropout':0.2,\n",
    "                      'pad': 2,\n",
    "                      'Epochs': 60,\n",
    "                      'loss_fn': \"MSE\",\n",
    "                      'lr': 0.0001,\n",
    "                      'seed' : 2,\n",
    "                      'resolution': [113, 36]\n",
    "                     }\n",
    "\n",
    "model_card_vgg_57 = {'name': 'vgg57',\n",
    "                      'model': 'vgg16',\n",
    "                      'f_lin_lay':[200704],\n",
    "                      'dropout':0.2,\n",
    "                      'pad': 1,\n",
    "                      'Epochs': 60,\n",
    "                      'loss_fn': \"MSE\",\n",
    "                      'lr': 0.0001,\n",
    "                      'seed' : 8,\n",
    "                      'resolution': [57, 18]\n",
    "                     }\n",
    "\n",
    "model_card_vgg_29 = {'name': 'vgg29',\n",
    "                      'model': 'vgg16',\n",
    "                      'f_lin_lay':[200704],\n",
    "                      'dropout':0.2,\n",
    "                      'pad': 0,\n",
    "                      'Epochs': 60,\n",
    "                      'loss_fn': \"MSE\",\n",
    "                      'lr': 0.0001,\n",
    "                      'seed' : 8,\n",
    "                      'resolution': [29, 9]\n",
    "                     }\n",
    "\n",
    "model_card_2c2l_15 = {'name': '2c2l15',\n",
    "                      'model': '2c2l',\n",
    "                      'f_lin_lay':[640],\n",
    "                      'dropout':0.1,\n",
    "                      'pad': 0,\n",
    "                      'Epochs': 60,\n",
    "                      'loss_fn': \"MSE\",\n",
    "                      'lr': 0.001,\n",
    "                      'seed' : 2,\n",
    "                      'resolution': [15, 5]\n",
    "                     }\n",
    "\n",
    "model_card_3c2l_8 = {'name': '3c2l8',\n",
    "                      'model': '3c2l',\n",
    "                      'f_lin_lay':[256],\n",
    "                      'dropout':0.2,###\n",
    "                      'pad': 0,\n",
    "                      'Epochs': 60,\n",
    "                      'loss_fn': \"MSE\",\n",
    "                      'lr': 0.001,\n",
    "                      'seed' : 2,\n",
    "                      'resolution': [8, 3]\n",
    "                     }\n",
    "\n",
    "#resolution_card_452144 = {'resolution':[452,144], 'padding':5, 'index':0}\n",
    "#resolution_card_22672 = {'resolution':[226,72], 'padding':5, 'index':1}\n",
    "#resolution_card_11336 = {'resolution':[113,36], 'padding':2, 'index':2}\n",
    "#resolution_card_5715 = {'resolution':[57,18], 'padding':1, 'index':3}\n",
    "#resolution_card_299 = {'resolution':[29,9], 'padding':0, 'index':4} # \n",
    "#resolution_card_155 = {'resolution':[15,5], 'padding':0, 'index':5}\n",
    "#resolution_card_83 = {'resolution':[8,3], 'padding':0, 'index':6}\n",
    "\n",
    "\n",
    "config = dict({'batch_size': 64, 'epochs': 60})\n",
    "\n",
    "best_models_list = [model_card_vgg_452, model_card_vgg_226, model_card_vgg_113, model_card_vgg_57, model_card_vgg_29, model_card_2c2l_15, model_card_3c2l_8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87383b",
   "metadata": {},
   "source": [
    "452 144 5/452 *100 = 1%\n",
    "226 72 5/226 *100 = 2%\n",
    "113 36 5/113 *100 = 4% -- 2/113 *100= 1.7% ~ 2%\n",
    "57 18 (56.5,) 5/57 *100 = 8% -- 2/57 *100 = 3.5% ~ 4%. 1/57 = 1.75%\n",
    "29 9 (28.5,) 5/29 *100 = 17% -- 2/29 *100 = 6.89 ~ 7% 1/28 = 3.57 ~ 4%\n",
    "15 5 (14.5, 4.5)\n",
    "8 3 (7.5,2.5)\n",
    "4, 2 (, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87dc8393-e7da-43eb-b0e7-b11c4a46c8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def save2csv_nest_dict(nested_dict, file_name, save_location:str):\n",
    "    # flattern nested dictionary\n",
    "    flatterend_dict = {}\n",
    "    for k,v in nested_dict.items():\n",
    "        if isinstance(v, dict):\n",
    "            for nested_key, nested_val in v.items():\n",
    "                flatterend_dict[f\"{k}_{nested_key}\"] = nested_val\n",
    "        else:\n",
    "            flatterend_dict[k] =v\n",
    "    \n",
    "    columns = list(flatterend_dict.keys())\n",
    "    \n",
    "    with open(save_location+str(file_name)+'.csv', \"a+\", newline=\"\") as f:\n",
    "        # using dictwriter\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        # using writeheader function\n",
    "        if f.tell() == 0:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(flatterend_dict)\n",
    "        f.close()\n",
    "\n",
    "# check dictionary values for json and csv\n",
    "\n",
    "def check_obj4np(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: check_obj4np(value) for key, value in obj.items()}\n",
    "    if isinstance(obj,list):\n",
    "        return [check_obj4np(item) for item in obj]\n",
    "    if isinstance(obj,np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# save to json\n",
    "def save2josn_nested_dict(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    with open(save_location+str(file_name)+'.json', 'a+') as f:\n",
    "        f.write(json_obj)\n",
    "        f.close()\n",
    "\n",
    "    \n",
    "#save_location+str(file_name)+'.csv'\n",
    "def save2csv(nested_dict, file_name, save_location:str):\n",
    "    \n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    \n",
    "    columns = list(nested_dict.keys())\n",
    "    path = os.path.join(save_location, file_name +\".csv\")\n",
    "    try:\n",
    "        with open(path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            # using dictwriter\n",
    "            # using writeheader function\n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(nested_dict)\n",
    "            f.close()\n",
    "    except IOError as e:\n",
    "        print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "    except ValueError:\n",
    "              print(\"could not convert to string\")\n",
    "    except:\n",
    "              print(\"unexpected error: \", sys.exc_info()[0])\n",
    "        \n",
    "\n",
    "def save2json(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    #print(nested_dict)\n",
    "    #print(nested_dict.items())\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    #print(json_obj)\n",
    "    path = os.path.join(save_location, file_name+\".json\")\n",
    "    #print(path)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(json_obj)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def read_in_json(file_path, file_name):\n",
    "    path = os.path.join(file_path, 'file_name')\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            #obj = f.read()\n",
    "            dj = json.load(f, object_pairs_hook= collections.OrderedDict) #obj, \n",
    "            #print(dj)\n",
    "    except Exception as e:\n",
    "        print(\"Error decoding Json\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "class Flattern(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flattern, self).__init__()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.flatten()\n",
    "        return x\n",
    "\n",
    "\n",
    "def choose_model(model_name, lin_lay, dropout):\n",
    "\n",
    "    if model_name == '4c3l':\n",
    "        return smallnet1(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '3c2l':\n",
    "        return smallnet2(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks = (3,5), dropout=dropout)\n",
    "    elif model_name == '2c2l':\n",
    "        return smallnet3(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '7c3l':\n",
    "        return sevennet(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == 'vgg16':\n",
    "        #self.flatten = nn.Flatten()\n",
    "        model_vgg16 = vgg16()\n",
    "        vgg_feats = model_vgg16.features\n",
    "        vgg_classifier = model_vgg16.classifier\n",
    "        vgg_classifier.pop(6)\n",
    "\n",
    "        vgg = nn.Sequential(\n",
    "            vgg_feats,\n",
    "            nn.Flatten(),\n",
    "            vgg_classifier,\n",
    "            nn.Linear(4096,11), # cheanging the output layer\n",
    "            nn.Softmax(dim=0),  \n",
    "            )\n",
    "        \n",
    "        \n",
    "        return vgg\n",
    "    else:\n",
    "        print('Model Name Not Recognised')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_model_sizes_bits(model):\n",
    "    bits = 32\n",
    "    mods = list(model.modules())\n",
    "    sizes = []\n",
    "    total_bits = 0\n",
    "    \n",
    "    for i in range(1,len(mods)):\n",
    "        m = mods[i]\n",
    "        p = list(m.parameters())\n",
    "        for j in range(len(p)):\n",
    "            sizes.append(np.array(p[j].size()))\n",
    "    \n",
    "    for i in range(len(sizes)):\n",
    "        s = sizes[i]\n",
    "        bitz = np.prod(np.array(s))*bits\n",
    "        total_bits += bitz\n",
    "    total_bytes = total_bits/8\n",
    "    total_megabytes = total_bytes/1e+6\n",
    "    total_gigabytes = total_megabytes/1000\n",
    "    print(total_bits, 'bits    ', total_bytes, \"bytes    \", total_megabytes, \"MegaBytes    \", total_gigabytes,\"GigaBytes\") # 148480\n",
    "\n",
    "\n",
    "def ptrblk_fin_mod_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    size_all_gb = size_all_mb/953.674\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))\n",
    "    print('model size: {:.3f}GB'.format(size_all_gb))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927cd54-ae90-4237-962c-d84dc63a195f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4efdd3ed-9887-44e4-af1e-a167c8da90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_batch(model, train, val, loop_run_name, save_dict, lr, loss_fn, epochs, batch_size, optimizer, scheduler_value, device): #train_dl, val_dl, \n",
    "    #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3) \n",
    "    model.train()\n",
    "    \n",
    "\n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "    sample = False\n",
    "    \n",
    "    \n",
    "    total_epochs = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        #if epoch == 1:\n",
    "        #    sample = True\n",
    "        random_value = random.randrange(0,batch_size)\n",
    "        #else:\n",
    "        #    random_value = None\n",
    "        sample = False\n",
    "        #print(random_value)\n",
    "\n",
    "        \n",
    "        print('Training...')\n",
    "        #!nvidia-smi\n",
    "        #print(len(train)) #Using a target size \n",
    "\n",
    "        \n",
    "        t_loss, train_prediction, train_targets, t_correct, model, optimizer = loop_batch(model, train, loss_fn, batch_size,sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =optimizer, scheduler= scheduler_value, train =True) #, scheduler =scheduler\n",
    "        print('training..  2')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        t_loss_list.append(t_loss)\n",
    "        [t_predict_list.append(pred.argmax()) for pred in train_prediction]\n",
    "        wandb.log({'t_loss':t_loss})\n",
    "    \n",
    "        train_acc = (t_correct/(len(train)*batch_size)*100) ###\n",
    "        print('train accuracy: ', train_acc )\n",
    "        t_accuracy_list.append(train_acc)\n",
    "        wandb.log({'train_acc':train_acc})\n",
    "        \n",
    "        \n",
    "            \n",
    "        print('validating...')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        v_loss, val_prediction, val_targets, val_correct= loop_batch(model, val, loss_fn, batch_size,sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =None, scheduler= None, train =False)\n",
    "\n",
    "        v_loss_list.append(v_loss)\n",
    "        [v_predict_list.append(pred.argmax()) for pred in val_prediction]\n",
    "        wandb.log({'v_loss':v_loss})\n",
    "        \n",
    "        val_acc = (val_correct/(len(val)*batch_size)*100)\n",
    "        v_accuracy_list.append(val_acc)\n",
    "        print('validation accuracy: ', val_acc )\n",
    "        wandb.log({'val_acc':val_acc})\n",
    "    \n",
    "        total_epochs += 1\n",
    "        \n",
    "    save_dict['Current_Epoch'] = epochs\n",
    "    save_dict['training_samples'] = len(train)\n",
    "    save_dict['validation_samples'] = len(val)\n",
    "    \n",
    "    save_dict['t_accuracy_list'] = t_accuracy_list \n",
    "    save_dict['v_accuracy_list'] = v_accuracy_list  #\n",
    "            \n",
    "    #model = best_model\n",
    "    save_dict['t_loss_list'] = t_loss_list\n",
    "    save_dict['v_loss_list'] = v_loss_list\n",
    "    \n",
    "    save_dict['t_labels'] = train_targets\n",
    "    save_dict['v_labels'] = val_targets\n",
    "    \n",
    "    save_dict['t_predict_list'] = t_predict_list \n",
    "    save_dict['v_predict_list'] = v_predict_list  #\n",
    "    \n",
    "    return model, save_dict\n",
    "\n",
    "from functions import ImageProcessor\n",
    "\n",
    "def loop_batch(model, data, loss_fn, batch_size, sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =None, scheduler= None, train =True):\t# Train and Val loops. Default is train\n",
    "    model = model\n",
    "    total_samples = len(data)\n",
    "    #scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=scheduler_value) \n",
    "    if train:\n",
    "        model.train()\n",
    "        where ='tra'\n",
    "        #lr_ls = []\n",
    "    else:\n",
    "        model.eval()   #  (torch.Size([16, 11])) that is different to the input size (torch.Size([11]))\n",
    "        where = 'val'\n",
    "\n",
    "    predict_list = []\n",
    "    total_count = 0\n",
    "    num_correct = 0\n",
    "    current_loss = 0\n",
    "    labels =[]\n",
    "\n",
    "    \n",
    "    for i, batch in enumerate(data,0):\n",
    "\n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        \n",
    "        prediction = model.forward(x_batch)\n",
    "\n",
    "\n",
    "        loss = loss_fn(prediction, y_batch)\n",
    "        \n",
    "        #print('loop batch 4')\n",
    "        #!nvidia-smi\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        for i in range(len(y_batch)-1):\n",
    "            if y_batch[i].argmax() == prediction[i].argmax():\n",
    "                num_correct +=1\n",
    "            [predict_list.append(pred.argmax()) for pred in prediction]#.argmax())\n",
    "            [labels.append(y.argmax()) for y in y_batch]\n",
    "\n",
    "        total_count+= batch_size\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "    if scheduler and scheduler >0:\n",
    "        scheduler.step()\n",
    "\n",
    "    if train:\n",
    "        return current_loss, predict_list, y_batch, num_correct, model, optimizer #, lr_ls\n",
    "    else:\n",
    "        return current_loss, predict_list, y_batch, num_correct\n",
    "\n",
    "\n",
    "def test_loop(model, model_name, X, Y, res, pad, save_dict, loss_fn, device, av_lum, num_classes=11):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    current_loss = 0\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    colour ='colour'\n",
    "    size =  res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print('Testing...') \n",
    "        for idx, img in enumerate(X):\n",
    "\n",
    "            #image pre processing\n",
    "            prepro = ImageProcessor(device)\n",
    "            if model_name == 'vgg16':\n",
    "                tense = prepro.colour_size_tense(img, colour, size, av_lum, pad, vg=True) #[29, 9], 15, 5, [8,3]\n",
    "            elif (model_name == '7c3l' and size == [29, 9]) or (model_name == '7c3l' and size == [15, 5]) or (model_name == '7c3l' and size ==[8, 3]):\n",
    "                tense = prepro.colour_size_tense(img, colour, size, av_lum, pad, vg=True)\n",
    "            else:\n",
    "                tense = prepro.colour_size_tense(img, colour, size,av_lum,  pad)\n",
    "\n",
    "\n",
    "            tense = tense.unsqueeze(dim=0)\n",
    "\n",
    "            prediction = model.forward(tense)\n",
    "            label = label_oh_tf(Y[idx], num_classes).to(device)\n",
    "\n",
    "            label = label.unsqueeze(dim=0)\n",
    "\n",
    "            loss = loss_fn(prediction, label)\n",
    "\n",
    "            if prediction.argmax()==label.argmax():\n",
    "                num_correct +=1\n",
    "            total_count +=1\n",
    "            correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "\n",
    "            predict_list.append(prediction.argmax())\n",
    "\n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        current_loss += loss.item()\n",
    "        \n",
    "    return accuracy, predict_list, Y, current_loss\n",
    "\n",
    "## model, data, loss_fn, device, optimizer =None, scheduler= None, train =True\n",
    "def test_loop_batch(model,data, loss_fn, batch_size, device):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    label_list = []\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data,0):\n",
    "            #tense = tense.to(device)\n",
    "            tense, label = batch\n",
    "            label = label.to(device)\n",
    "            \n",
    "            prediction = model.forward(tense.to(device))\n",
    "            #print('p', prediction.shape, 'l ', label.shape)\n",
    "            #label = label_oh_tf(Y[idx], device, num_classes)\n",
    "            for i in range(len(label)-1):\n",
    "                #print(len(label), label[0].argmax(), len(label)-1)\n",
    "                if label[i].argmax() == prediction[i].argmax():\n",
    "                    num_correct +=1\n",
    "            [predict_list.append(pred.argmax()) for pred in prediction]\n",
    "            [label_list.append(lab.argmax()) for lab in label]\n",
    "\n",
    "            total_count += batch_size\n",
    "\n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "\n",
    "        print(accuracy)\n",
    "        return accuracy, predict_list, label_list\n",
    "\n",
    "\n",
    "\n",
    "def get_data(random_seed):\n",
    "    file_path =  data_path\n",
    "    img_len = len(os.listdir(file_path))\n",
    "    \n",
    "    x, y = import_imagedata(file_path)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "    \n",
    "def get_lin_lay(model_card, resolution):\n",
    "    if resolution == [452, 144]:\n",
    "        lin_lay = model_card['f_lin_lay'][0]\n",
    "    elif resolution == [226, 72]:\n",
    "        lin_lay = model_card['f_lin_lay'][1]\n",
    "    elif resolution == [113, 36]:\n",
    "        lin_lay = model_card['f_lin_lay'][2]\n",
    "    elif resolution == [57, 18]:\n",
    "        lin_lay = model_card['f_lin_lay'][3]\n",
    "    elif resolution == [29, 9]:\n",
    "        lin_lay = model_card['f_lin_lay'][4]\n",
    "    elif resolution == [15, 5]:\n",
    "        lin_lay = model_card['f_lin_lay'][5]\n",
    "    elif resolution == [8, 3]:\n",
    "        lin_lay = model_card['f_lin_lay'][6]\n",
    "    else:\n",
    "        print(\"PARAMETER NOT FOUND: \\n f_lin_lay FROM MODEL CARD\")\n",
    "    return lin_lay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf5ca7f-b59a-427b-8da3-2848fa6d3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def _go(config=None):\n",
    "\n",
    "    if len(gitHASH) <1:\n",
    "        print(\"YOU FORGET THE GIT HASH\")\n",
    "        return\n",
    "    else:\n",
    "        pass\n",
    "    for model_spec in best_models_list:\n",
    "        with wandb.init(config=config, project=f\"best model run {model_spec['model_name']} {model_spec['resolution']}\", notes=\"Running best perfoming models for save.\",):\n",
    "            config = wandb.config\n",
    "            start = time.process_time()\n",
    "            model_name = model_spec['model_name']\n",
    "            loss = model_spec['loss_fn']\n",
    "            dropout = model_spec['dropout']\n",
    "            resolution = model_spec['resolution']\n",
    "            pad = model_spec['pad']\n",
    "            lin_lay = model_spec['f_lin_lay']\n",
    "            seed = model_spec['seed']\n",
    "                                      \n",
    "            torch.cuda.empty_cache()\n",
    "            #print('2')\n",
    "            #!nvidia-smi\n",
    "\n",
    "            config['batch_size']\n",
    "\n",
    "            print('Model: ', str(model_name))\n",
    "            print('resolution: ', str(resolution))\n",
    "            print('learning rate: ', str(lr))\n",
    "            print('weight decay: ', str(wd_card))\n",
    "            print('scheduler: ', str(scheduler_value))\n",
    "            print('seed: ', str(seed))\n",
    "            print('loss function: ', str(loss))\n",
    "            print('Batch size: ', config['batch_size'])\n",
    "            print('Training epochs: ', config['epochs'])\n",
    "            run_start_time = time.process_time()\n",
    "            print('start time: ',run_start_time)\n",
    "\n",
    "            print(time.process_time() - start)\n",
    "\n",
    "            epochs = config['epochs'] #40\n",
    "\n",
    "            IP = ImageProcessor(device)\n",
    "\n",
    "            wandb.log({'gitHash':gitHASH})\n",
    "            wandb.log({'Epochs': epochs})\n",
    "            config.update({'ModelSpec':model_spec})\n",
    "\n",
    "            save_dict = {'Run' : f\"{model_name}_{resolution}_{date}\",\n",
    "                         'Current_Epoch': 0,\n",
    "                         'save_location' : _save_location}\n",
    "\n",
    "            model = choose_model(model_name, lin_lay, dropout).to(device) ##\n",
    "\n",
    "            print(\"After model init, Before data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "            x_train, y_train, x_val, y_val, x_test, y_test = get_data(seed)\n",
    "            av_lum = IP.new_luminance(x_train)\n",
    "            #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "            \n",
    "            train_ds = IDSWDataSetLoader2(x_train, y_train, resolution,pad,av_lum,model_name, device)# av_lum, res,pad,\n",
    "            train = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "\n",
    "            \n",
    "            test_ds = IDSWDataSetLoader2(x_test, y_test, resolution,pad,av_lum,model_name, device)\n",
    "            test = DataLoader(test_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "            #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "            val_ds = IDSWDataSetLoader2(x_val, y_val, resolution,pad,av_lum,model_name, device)\n",
    "            val = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "            \n",
    "            print(\"After data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "\n",
    "            loss_fn = set_lossfn(loss)\n",
    "            \n",
    "            # set optimizer\n",
    "            optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "            wandb.watch(model, loss_fn, log='all', log_freq=2, idx = model_index)\n",
    "\n",
    "            loop_run_name = f\"{save_dict['Run']}_{resolution}_{lr}_{scheduler_value}_{seed}_{loss}\"\n",
    "\n",
    "            model, save_dict=  train_val_batch(model, train,val, loop_run_name,save_dict, lr, loss_fn,epochs, config['batch_size'], optimizer, scheduler_value, device)\n",
    "\n",
    "            test_acc,test_predict_list, y_test = test_loop_batch(model,test, loss_fn, config['batch_size'], device) #model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\n",
    "            \n",
    "            #print(test_predict_list)\n",
    "            print(' \\n train Acc: ', save_dict['t_accuracy_list'][-1])\n",
    "            print(' \\n val Acc: ', save_dict['v_accuracy_list'][-1])\n",
    "            print(' \\n test Acc: ', test_acc)\n",
    "            \n",
    "            save_dict.update({'test_acc': test_acc})\n",
    "            save_dict.update({'test_predict': test_predict_list})\n",
    "            save_dict.update({'test_labels': list(y_test)})\n",
    "            #save_dict.update({'test_loss':test_loss})\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            learning_curve(save_dict['t_loss_list'], save_dict['v_loss_list'], save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "            accuracy_curve(save_dict['t_accuracy_list'], save_dict['v_accuracy_list'],save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "            test_predict_list=[pred.cpu() for pred in test_predict_list]\n",
    "            plot_confusion(predictions= test_predict_list, actual= y_test, title = \"Test Confusion matrix\", run_name = loop_run_name,save_location =save_dict['save_location'])\n",
    "            \n",
    "            wandb.log({'test_acc': test_acc})\n",
    "            wandb.log({'test_predict': test_predict_list})\n",
    "            wandb.log({'test_labels': list(y_test)})\n",
    "            #saving\n",
    "            diction = {}\n",
    "            d = str(date.today())\n",
    "\n",
    "            diction.update({'Date':d})\n",
    "            diction.update({'gitHASH':str(gitHASH)})\n",
    "            diction.update({'model_name': str(model_name)})\n",
    "            diction.update({'loss_fn': str(loss)})\n",
    "            diction.update({'lr': str(lr)})\n",
    "            diction.update({'wd': str(wd_card)})\n",
    "            diction.update({'scheduler value': str(scheduler_value)})\n",
    "            diction.update({'seed': str(seed)})\n",
    "            diction.update({'resolution': str(resolution)})\n",
    "            diction.update({'pad': int(pad)})\n",
    "            diction.update({'lin_lay': int(lin_lay)})\n",
    "            diction.update({'run time': (time.process_time() - run_start_time)})\n",
    "            diction.update(save_dict)\n",
    "            \n",
    "            save_location = save_dict['save_location']\n",
    "            title = save_dict['Run']\n",
    "            save2json(diction, loop_run_name, save_location)\n",
    "            save2csv(diction, title, save_location)\n",
    "\n",
    "            diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "\n",
    "            with open(f\"{save_location}{loop_run_name}.pkl\", 'wb+') as f:\n",
    "                pickle.dump(diction, f)\n",
    "            \n",
    "            clear_output()\n",
    "            \n",
    "            print(f' \\n END {model_name} {resolution} Run Time: ',time.process_time() - run_start_time)\n",
    "            #!nvidia-smi\n",
    "            torch.cuda.empty_cache()\n",
    "        print('Final Run time: ',time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d7d27-ef9d-43d9-98a8-1f11ff50090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " END vgg16 [8, 3] Run Time:  5186.559548013\n",
      "Model:  vgg16  idx: 0 / 1\n",
      "resolution:  [8, 3]  idx: 0 / 1\n",
      "learning rate:  0.01  idx: 1 / 5\n",
      "weight decay:  0  idx: 0 / 1\n",
      "scheduler:  0  idx: 0 / 1\n",
      "seed:  8  idx: 0 / 3\n",
      "loss function:  MSE  idx: 0 / 2\n",
      "Batch size:  64\n",
      "Training epochs:  60\n",
      "start time:  29717.333482843\n",
      "29704.765514623\n",
      "After model init, Before data loading - Current allocated memory (GB): 0.0\n",
      "After data loading - Current allocated memory (GB): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                   | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.413461538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                                          | 1/60 [00:10<10:47, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.413461538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▉                                                         | 2/60 [00:21<10:38, 11.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.238636363636363\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.254807692307693\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▉                                                        | 3/60 [00:33<10:27, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.615384615384617\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███▉                                                       | 4/60 [00:43<10:15, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.735576923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████▉                                                      | 5/60 [00:54<10:05, 11.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  7.8125\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████▉                                                     | 6/60 [01:05<09:52, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████▉                                                    | 7/60 [01:16<09:42, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.194711538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████▊                                                   | 8/60 [01:27<09:30, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.555288461538462\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████▊                                                  | 9/60 [01:38<09:19, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.664772727272728\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.413461538461538\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████▋                                                | 10/60 [01:49<09:08, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.238636363636363\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.954326923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████▋                                               | 11/60 [02:00<08:57, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.653846153846153\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████▌                                              | 12/60 [02:11<08:47, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.07451923076923\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████▌                                             | 13/60 [02:22<08:35, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████▌                                            | 14/60 [02:33<08:25, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.522727272727272\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  8.59375\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████▌                                           | 15/60 [02:44<08:14, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.806818181818182\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.435096153846153\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████▍                                          | 16/60 [02:55<08:02, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  8.380681818181818\n",
      "Training...\n",
      "training..  2\n",
      "train accuracy:  9.735576923076923\n",
      "validating...\n"
     ]
    }
   ],
   "source": [
    "_go(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0ade6-cd6d-46db-ac95-6b368cbea443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
