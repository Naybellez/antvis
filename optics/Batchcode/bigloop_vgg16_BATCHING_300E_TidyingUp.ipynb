{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4fd19-5a09-4232-bdc4-42bbef0b6802",
   "metadata": {},
   "source": [
    "last updated 13/12/24 - Trying Adam, vgg16, CE on Cifar-10 database\n",
    "\n",
    "- output layer of network needs to output to 10 channels  not the current 11.\n",
    "- download and seporate cifar 10 into train, val batch\n",
    "- wont need dataloader - too specific to idsw dataset\n",
    "\n",
    "To investigate what is wrong with vgg16 learn - i.e. what i've changed.\n",
    "I am running the 4c model in this file adapted from vgg16.\n",
    "\n",
    "\n",
    "_save_location, loop_run_name, wandb.init config & notes > for cifar10 sims, included var ds_kw in, or replacing Var_WB_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6dbd95-2129-42b5-b70b-ee9f057b24c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch.Utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import collections\n",
    "from IPython.display import clear_output\n",
    "#import time\n",
    "import random\n",
    "import cv2\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "\n",
    "# data\n",
    "from functions import ImageProcessor#, IDSWDataSetLoader2, get_data\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "#\n",
    "from fns4wandb import set_lossfn\n",
    "from plotting import learning_curve, accuracy_curve, plot_confusion\n",
    "\n",
    "from modelManagment import get_lin_lay #, choose_model2, choose_model1\n",
    "from loop_fns import train_val_batch, test_loop_batch\n",
    "from fileManagment import save2csv, save2json\n",
    "\n",
    "from debuggingFuncs import check_model_sizes_bits\n",
    "#from torchvision.models import vgg16\n",
    "\n",
    "\n",
    "#import torch.Utils.data.DataLoader as DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c1e605-9a3b-48dc-a38e-8a955bd3c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "optimmy = 'adam' #'SGD'\n",
    "# note. optimizer is a single line in go- changed manually\n",
    "model_type = 'vgg16'\n",
    "Var_WB_sched = \"NoSched\"\n",
    "ds_kw =\"cifar10\"\n",
    "\n",
    "_save_location = f'/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/schedulerRuns/{model_type}/{optimmy}/{ds_kw}/' \n",
    "checkpoint_saveloc = f\"/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/schedulerRuns/{model_type}/{optimmy}/modelCheckPoints/\"\n",
    "\n",
    "#data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "\n",
    "gitHASH = 'ef6b54a4f1436e60d2151034e513eb18b1dcde07'\n",
    "\n",
    "\n",
    "start_epoch = 0\n",
    "epoch_val =  300 #150 #300# 150\n",
    "\n",
    "\n",
    "\n",
    "loadPreTrainedModel = False\n",
    "\n",
    "Pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sim_type = \"run\" #(Test or run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1481ccd-4d87-4c05-84d5-77e29ee981b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function wandb.wandb_agent.agent(sweep_id, function=None, entity=None, project=None, count=None)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wandb.login()\n",
    "#wandb login --relogin\n",
    "wandb.agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3dc2e8b-52df-4a26-9ea9-f703f85f42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory._record_memory_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ddbb49-828b-4de8-a31c-2a576cd736f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries                                                                                  * * * *   SETTINGS   * * * *\n",
    "\n",
    "date = date.today()\n",
    "#model_name = model_card['model']\n",
    "model_card_vgg = {'name': 'vgg', 'model': 'vgg16',\n",
    "                  'f_lin_lay':[200704,#200704,     #129024,#4096,  # (32x200704 and 3584x4096)\n",
    "                             200704,      #(16x64512 and 129024x4096)    (16x200704 and 64512x4096)\n",
    "                             200704,#14336#(16x200704 and 14336x4096)\n",
    "                             200704,\n",
    "                             200704, ##(32x200704 and 3584x4096)\n",
    "                             200704,\n",
    "                             200704,\n",
    "                            ],\n",
    "                 'idx': 0,\n",
    "                 'dropout':0.2}\n",
    "\n",
    "\n",
    "\n",
    "resolution_card_452144 = {'resolution':[452,144], 'padding':5, 'index':0}\n",
    "resolution_card_22672 = {'resolution':[226,72], 'padding':5, 'index':1}\n",
    "resolution_card_11336 = {'resolution':[113,36], 'padding':2, 'index':2}\n",
    "resolution_card_5715 = {'resolution':[57,18], 'padding':1, 'index':3}\n",
    "\n",
    "resolution_card_299 = {'resolution':[29,9], 'padding':0, 'index':4} # \n",
    "resolution_card_155 = {'resolution':[15,5], 'padding':0, 'index':5}\n",
    "resolution_card_83 = {'resolution':[8,3], 'padding':0, 'index':6}\n",
    "\n",
    "\n",
    "\n",
    "resolution_cards = [resolution_card_452144, resolution_card_11336, resolution_card_5715, resolution_card_155]#]#resolution_card_452144, resolution_card_22672, resolution_card_11336, \n",
    "#resolution_card_452144, resolution_card_22672, resolution_card_11336, resolution_card_5715,resolution_card_299, resolution_card_155,\n",
    "#resolution_cards = [resolution_card_11336] #resolution_card_452144, resolution_card_22672, resolution_card_11336, resolution_card_5715,resolution_card_299, resolution_card_155, resolution_card_83\n",
    "\n",
    "#learning_rate_cards = [5e-5, 6e-5, 8e-5]\n",
    "#learning_rate_cards = [8.21592E-05, 6.62E-05, 6.01E-05, 5.97E-05]\n",
    "learning_rate_cards=  [1e-3] #[0.1, 0.01, 1e-3,1e-4, 1e-5]#, 6e-5, 7e-5, 8e-5]\n",
    "#wd_cards = [4e-5, 5e-5, 3.00E-05, 2.00E-05]\n",
    "wd_cards =[0]\n",
    "#scheduler_cards = [0]#, 0.1, 0.2]\n",
    "\n",
    "seeds = [8, 2,4,42]# 8\n",
    "\n",
    "#model_cards =[model_card_vgg, model_card_7c3l, model_card_4c3l, model_card_3c2l, model_card_2c2l]\n",
    "model_cards =[model_card_vgg]\n",
    "\n",
    "loss_fn_cards = ['CrossEntropy']# ,'MSE'] #\n",
    "                        \n",
    "config = dict({'parameters': 'parameters for big loop run'})\n",
    "config.update({'model_cards':model_cards})\n",
    "config.update({'resolution_cards':resolution_cards})\n",
    "config.update({'learning_rate_cards':learning_rate_cards})\n",
    "config.update({'wd_cards':wd_cards})\n",
    "config.update({'scheduler':Var_WB_sched})\n",
    "config.update({'seeds':seeds})\n",
    "config.update({'loss_fn_cards': loss_fn_cards})\n",
    "\n",
    "\n",
    "config.update({'batch_size': 32}) #64\n",
    "config.update({'epochs': epoch_val})\n",
    "config.update({'start_epoch': start_epoch})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87383b",
   "metadata": {},
   "source": [
    "# functions that are moved\n",
    "save2csv_nest_dict\n",
    "check_obj4np\n",
    "save2josn_nested_dict\n",
    "save2csv\n",
    "save2json\n",
    "read_in_json\n",
    "check_model_sizes_bits\n",
    "ptrblk_fin_mod_size\n",
    "train_val_batch\n",
    "test_loop_batch\n",
    "get_data\n",
    "get_lin_lay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77090bf1-52a9-41f6-9f69-5a72fe4286a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def _go(config=None):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if len(gitHASH) <1:\n",
    "        print(\"YOU FORGET THE GIT HASH\")\n",
    "        return\n",
    "    else:\n",
    "        #print('Git Hash registered')\n",
    "        pass\n",
    "        \n",
    "    with wandb.init(config=config, project=f\"{model_type} {epoch_val}E. {ds_kw}. {optimmy}_{sim_type}\", notes=f\"{model_type} {epoch_val}E {ds_kw} {optimmy}_{sim_type}\",):\n",
    "        config = wandb.config\n",
    "        #start = time.process_time()\n",
    "        model_card = model_card_vgg\n",
    "        #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                \n",
    "        model_name = model_card['model']\n",
    "        model_index = model_card['idx']\n",
    "        dropout = model_card['dropout'] \n",
    "        for res_idx, resolution_card in enumerate(config['resolution_cards']):\n",
    "            #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "            resolution = resolution_card['resolution']\n",
    "            pad = resolution_card['padding']\n",
    "            lin_lay = get_lin_lay(model_card, resolution)\n",
    "            print('lin lay', lin_lay)\n",
    "            scheduler_value = 0\n",
    "        \n",
    "            lr = 1e-3#for lr_idx, lr in enumerate(config['learning_rate_cards']):\n",
    "                \n",
    "                   \n",
    "            for seed_idx, seed in enumerate(config['seeds']):\n",
    "                seed = seed\n",
    "                loss = 'CrossEntropy'\n",
    "                config['batch_size']\n",
    "\n",
    "                print('Model: ', str(model_name), f\" idx: {0} / {len(config.model_cards)}\")\n",
    "                print('resolution: ', str(resolution), f\" idx: {res_idx} / {len(config['resolution_cards'])}\")\n",
    "                print('learning rate: ', str(lr), f\" idx: {0} / {len(config['learning_rate_cards'])}\")\n",
    "                #print('weight decay: ', str(wd_card), f\" idx: {wd_idx} / {len(config['wd_cards'])}\")\n",
    "                print('scheduler: ', str(Var_WB_sched))# f\" idx: {sched_idx} / {len(config['scheduler_cards'])}\")\n",
    "                print('seed: ', str(seed), f\" idx: {seed_idx} / {len(config['seeds'])}\")\n",
    "                print('loss function: ', str(loss))#, f\" idx: {0} / {len(config['loss_fn_cards'])}\")\n",
    "                print('Batch size: ', config['batch_size'])\n",
    "                print('Training epochs: ', config['epochs'])\n",
    "\n",
    "                epochs = config['epochs'] #40\n",
    "\n",
    "                IP = ImageProcessor(device)\n",
    "\n",
    "                wandb.log({'gitHash':gitHASH})\n",
    "                wandb.log({'Epochs': epochs})\n",
    "                \n",
    "                #print('3')\n",
    "                #!nvidia-smi\n",
    "                \n",
    "                # set save dictionary\n",
    "                save_dict = {'Run' : f\"{model_name}_{resolution}_{date}_{optimmy}_{config['epochs']}E_{Var_WB_sched}_{sim_type}\",\n",
    "                             'Current_Epoch': config['start_epoch'], # this is where i add the start epoch\n",
    "                             'start_epoch':config['start_epoch'],\n",
    "                             'save_location' : _save_location,\n",
    "                             'checkpoint_save_loc': checkpoint_saveloc,\n",
    "                             'res': resolution,\n",
    "                             'sched': Var_WB_sched,\n",
    "                             'model': model_name,\n",
    "                             'optimiser':optimmy,\n",
    "                             'scheduler': Var_WB_sched,\n",
    "                             'seed':seed}\n",
    "                \n",
    "                print(\"model name\", model_name, \" flinlay: \", lin_lay, \" dropout:\", dropout)\n",
    "                model = choose_model1(model_name, lin_lay, dropout).to(device)#.to(device)\n",
    "                check_model_sizes_bits(model)\n",
    "                \n",
    "                if loadPreTrainedModel:\n",
    "                    dir_pkl = f\"/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/schedulerRuns/{model_type}/{optimmy}/NoSched/\"\n",
    "                    pkl_name = f\"{model_type}_{resolution}_2024-11-26_{optimmy}_150E_{Var_WB_sched}_{resolution}_0.001_{seed}_CrossEntropy_{optimmy}.pkl\"#f\"{model_type}_{optimmy}_{Var_WB_sched}_150E_{resolution}_seed{seed}\"#_{resolution}_0.001_0_{seed}_CrossEntropy\n",
    "                    with open(dir_pkl+pkl_name, 'rb') as f:\n",
    "                        model_pkl = torch.load(f)\n",
    "                    model.load_state_dict(model_pkl['model.state_dict'])\n",
    "\n",
    "                #print(\"After model init, Before data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated(device=device) / 1024 ** 3)\n",
    "                \n",
    "                # DATASET\n",
    "                #x_train, y_train, x_val, y_val, x_test, y_test = get_data(random_seed=seed, file_path=data_path)\n",
    "                #av_lum = IP.new_luminance(x_train)\n",
    "                #train_ds = IDSWDataSetLoader2(x_train, y_train, resolution,pad,av_lum,model_name, device)# av_lum, res,pad,\n",
    "                #train = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "                #test_ds = IDSWDataSetLoader2(x_test, y_test, resolution,pad,av_lum,model_name, device)\n",
    "                #test = DataLoader(test_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "                #val_ds = IDSWDataSetLoader2(x_val, y_val, resolution,pad,av_lum,model_name, device)\n",
    "                #val = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "                (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "                assert x_train.shape == (50000, 32, 32, 3)\n",
    "                assert x_test.shape == (10000, 32, 32, 3)\n",
    "                assert y_train.shape == (50000, 1)\n",
    "                assert y_test.shape == (10000, 1)#\n",
    "                x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, shuffle=True)\n",
    "                print(x_train[0].shape)\n",
    "                plt.imshow(x_train[4])\n",
    "                plt.show()\n",
    "                \n",
    "                #print(\"After data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated(device=device) / 1024 ** 3)\n",
    "                loss_fn = set_lossfn(loss)\n",
    "                \n",
    "                # set optimizer\n",
    "                optimizer = torch.optim.Adam(model.parameters(),lr=lr)#torch.optim.SGD(model.parameters(), lr=lr)# #torch.optim.SGD(model.parameters(), lr=lr) # \n",
    "\n",
    "                print(\"MODEL PARAMS : \",model.parameters())\n",
    "                for p in model.parameters():\n",
    "                    print(p)\n",
    "                \n",
    "                #print(\"After loading Optimizer - Current allocated memory (GB):\", torch.cuda.memory_allocated(device=device) / 1024 ** 3)\n",
    "                #wandb.watch(model, loss_fn, log='all', log_freq=10, idx = model_index)\n",
    "                #print(\"Pre Training - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "                loop_run_name = f\"{save_dict['Run']}_{resolution}_{lr}_{seed}_{loss}_{optimmy}_{ds_kw}\"\n",
    "\n",
    "                model, save_dict=  train_val_batch(model, train,val, loop_run_name,save_dict, lr, loss_fn,epochs, config['batch_size'], optimizer, scheduler_value, device)\n",
    "                #print(\"Post Training - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                \n",
    "                test_acc,test_predict_list, y_test = test_loop_batch(model,test, loss_fn, config['batch_size'], device) #model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\n",
    "                \n",
    "                #print(test_predict_list)\n",
    "                print(' \\n train Acc: ', save_dict['t_accuracy_list'][-1])\n",
    "                print(' \\n val Acc: ', save_dict['v_accuracy_list'][-1])\n",
    "                print(' \\n test Acc: ', test_acc)\n",
    "                \n",
    "                save_dict.update({'test_acc': test_acc})\n",
    "                save_dict.update({'test_predict': test_predict_list})\n",
    "                save_dict.update({'test_labels': list(y_test)})\n",
    "\n",
    "                learning_curve(save_dict['t_loss_list'], save_dict['v_loss_list'], save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                accuracy_curve(save_dict['t_accuracy_list'], save_dict['v_accuracy_list'],save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                test_predict_list=[pred for pred in test_predict_list]\n",
    "                plot_confusion(predictions= test_predict_list, actual= y_test, title = \"Test Confusion matrix\", run_name = loop_run_name,save_location =save_dict['save_location'])\n",
    "                \n",
    "                wandb.log({'test_acc': test_acc})\n",
    "                wandb.log({'test_predict': test_predict_list})\n",
    "                wandb.log({'test_labels': list(y_test)})\n",
    "                #saving\n",
    "                diction = {}\n",
    "                d = date.today()\n",
    "                d=str(d)\n",
    "                diction.update({'Date':d})\n",
    "                diction.update({'gitHASH':str(gitHASH)})\n",
    "                diction.update({'model_name': str(model_name)})\n",
    "                diction.update({'loss_fn': str(loss)})\n",
    "                diction.update({'lr': str(lr)})\n",
    "                #diction.update({'wd': str(wd_card)})\n",
    "                #diction.update({'scheduler value': str(scheduler_value)})\n",
    "                diction.update({'seed': str(seed)})\n",
    "                diction.update({'resolution': str(resolution)})\n",
    "                diction.update({'pad': int(pad)})\n",
    "                diction.update({'lin_lay': int(lin_lay)})\n",
    "                #diction.update({'run time': (time.process_time() - run_start_time)})\n",
    "                diction.update(save_dict)\n",
    "                \n",
    "                save_location = save_dict['save_location']\n",
    "                title = save_dict['Run']\n",
    "                save2json(diction, loop_run_name, save_location)\n",
    "                save2csv(diction, title, save_location)\n",
    "\n",
    "                diction['model.state_dict'] = model.state_dict().to('cpu') #to('cpu').\n",
    "\n",
    "                with open(f\"{save_location}{loop_run_name}.pkl\", 'wb+') as f:\n",
    "                    #p\n",
    "                    torch.save(diction, f)\n",
    "                \n",
    "                #clear_output()\n",
    "\n",
    "                \n",
    "                #print(f' \\n END {model_name} {resolution} Run Time: ',time.process_time() - run_start_time)\n",
    "                #!nvidia-smi\n",
    "                torch.cuda.empty_cache()\n",
    "            #print('Final Run time: ',time.process_time() - start)\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b58d7d27-ef9d-43d9-98a8-1f11ff50090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaughticalnonsence\u001b[0m (\u001b[33mantvis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/its/home/nn268/antvis/antvis/optics/Batchcode/wandb/run-20241212_162747-k44n76ez</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antvis/vgg16%2030E.%20NoSched.%20adam_run/runs/k44n76ez' target=\"_blank\">hearty-feather-10</a></strong> to <a href='https://wandb.ai/antvis/vgg16%2030E.%20NoSched.%20adam_run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antvis/vgg16%2030E.%20NoSched.%20adam_run' target=\"_blank\">https://wandb.ai/antvis/vgg16%2030E.%20NoSched.%20adam_run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antvis/vgg16%2030E.%20NoSched.%20adam_run/runs/k44n76ez' target=\"_blank\">https://wandb.ai/antvis/vgg16%2030E.%20NoSched.%20adam_run/runs/k44n76ez</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin lay 200704\n",
      "Model:  vgg16  idx: 0 / 1\n",
      "resolution:  [452, 144]  idx: 0 / 4\n",
      "learning rate:  0.001  idx: 0 / 1\n",
      "scheduler:  NoSched\n",
      "seed:  8  idx: 0 / 4\n",
      "loss function:  CrossEntropy\n",
      "Batch size:  32\n",
      "Training epochs:  30\n",
      "model name vgg16  flinlay:  200704  dropout: 0.2\n",
      "53801718464 bits     6725214808.0 bytes     6725.214808 MegaBytes     6.725214808 GigaBytes\n",
      "/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/\n",
      "MODEL PARAMS :  <generator object Module.parameters at 0x7f65d811a5e0>\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0526, -0.1665,  0.1183],\n",
      "          [ 0.0827, -0.0476, -0.0937],\n",
      "          [ 0.0280,  0.1418,  0.0701]],\n",
      "\n",
      "         [[ 0.0475, -0.0413, -0.0657],\n",
      "          [-0.1825, -0.0238,  0.0819],\n",
      "          [-0.0428, -0.1491, -0.1186]],\n",
      "\n",
      "         [[-0.0370,  0.1512, -0.0298],\n",
      "          [ 0.1845, -0.0135,  0.0408],\n",
      "          [ 0.1600, -0.0611,  0.0262]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0202,  0.1499, -0.0105],\n",
      "          [ 0.1422, -0.1136, -0.0666],\n",
      "          [ 0.0002, -0.0137,  0.1528]],\n",
      "\n",
      "         [[-0.0493,  0.1506, -0.0102],\n",
      "          [-0.0661, -0.1479,  0.0358],\n",
      "          [-0.1546,  0.1415, -0.1747]],\n",
      "\n",
      "         [[ 0.1309, -0.1288,  0.0889],\n",
      "          [ 0.0219, -0.1138, -0.0952],\n",
      "          [-0.0734,  0.1549, -0.0395]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0503,  0.0279, -0.1372],\n",
      "          [ 0.0620,  0.1207, -0.1565],\n",
      "          [ 0.0471,  0.0764,  0.0027]],\n",
      "\n",
      "         [[-0.1892, -0.0241, -0.0262],\n",
      "          [-0.0616,  0.1408, -0.1314],\n",
      "          [ 0.1553,  0.1452,  0.1681]],\n",
      "\n",
      "         [[-0.1165, -0.1913, -0.1642],\n",
      "          [ 0.0394, -0.0180, -0.0934],\n",
      "          [-0.0302, -0.0022,  0.0182]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0569,  0.0967,  0.1000],\n",
      "          [ 0.0557, -0.0201, -0.1438],\n",
      "          [ 0.1271, -0.0579, -0.1711]],\n",
      "\n",
      "         [[-0.1711,  0.1655, -0.0583],\n",
      "          [-0.1651, -0.0281, -0.0273],\n",
      "          [ 0.0040, -0.0697, -0.0454]],\n",
      "\n",
      "         [[-0.0790, -0.0533, -0.1575],\n",
      "          [-0.0416, -0.1131, -0.1681],\n",
      "          [ 0.0145, -0.0816, -0.1189]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0853,  0.0033, -0.0507],\n",
      "          [ 0.0146,  0.0123,  0.1435],\n",
      "          [ 0.0141, -0.0726,  0.0374]],\n",
      "\n",
      "         [[-0.1899,  0.1874,  0.1768],\n",
      "          [ 0.0495,  0.0706,  0.0655],\n",
      "          [-0.1406,  0.0122,  0.1456]],\n",
      "\n",
      "         [[ 0.0642,  0.1639,  0.0037],\n",
      "          [-0.1897,  0.0973,  0.0614],\n",
      "          [ 0.1868,  0.0120, -0.0079]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1297,  0.0971,  0.0014],\n",
      "          [ 0.0196, -0.0585, -0.1241],\n",
      "          [-0.0534,  0.0977, -0.1321]],\n",
      "\n",
      "         [[-0.1511, -0.0870, -0.1044],\n",
      "          [-0.1112,  0.1352,  0.0580],\n",
      "          [-0.1909, -0.0667,  0.0867]],\n",
      "\n",
      "         [[ 0.0302,  0.1549, -0.1600],\n",
      "          [ 0.0887,  0.1040,  0.0898],\n",
      "          [ 0.0362,  0.1384,  0.1398]]]], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0511,  0.1606, -0.0694,  0.0353, -0.1368,  0.1863, -0.1272, -0.1284,\n",
      "         0.1733,  0.0976,  0.1139,  0.0185, -0.0409, -0.1354, -0.0606,  0.0251,\n",
      "        -0.0723, -0.0552,  0.1452, -0.1564,  0.1578, -0.0705,  0.1429,  0.0526,\n",
      "         0.0624, -0.1807, -0.1053,  0.0070, -0.0153,  0.0366,  0.0555,  0.1613,\n",
      "         0.1113, -0.1324, -0.1421, -0.1390, -0.1272, -0.1516, -0.1387, -0.0748,\n",
      "        -0.1685,  0.0874, -0.0624,  0.1524, -0.0395,  0.0661, -0.1872,  0.1127,\n",
      "         0.1744,  0.1721, -0.1013,  0.0208, -0.1614, -0.1633,  0.0104, -0.0977,\n",
      "         0.0970, -0.0049, -0.0873,  0.0658,  0.1327, -0.1681,  0.1510,  0.0722],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-3.5216e-02, -2.6267e-02, -3.4383e-02],\n",
      "          [ 3.0164e-03,  3.2923e-02,  9.6942e-03],\n",
      "          [-6.9934e-03, -3.7478e-02,  1.3970e-02]],\n",
      "\n",
      "         [[-3.3879e-02, -1.3124e-02, -1.1692e-02],\n",
      "          [ 1.8013e-02,  1.1088e-02,  9.4478e-03],\n",
      "          [-2.8934e-02,  3.3080e-02, -6.2783e-03]],\n",
      "\n",
      "         [[-2.1457e-02,  1.9683e-02,  2.1634e-03],\n",
      "          [-2.6464e-02, -2.8317e-03,  2.0760e-02],\n",
      "          [-2.7496e-02, -2.2187e-02, -1.1208e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3586e-02,  3.8497e-02,  3.8793e-02],\n",
      "          [ 1.1508e-02, -7.5401e-03,  2.4962e-02],\n",
      "          [-2.9404e-02,  2.1922e-02, -1.1138e-02]],\n",
      "\n",
      "         [[-1.7291e-02, -4.0149e-02,  3.7039e-02],\n",
      "          [ 3.8897e-02,  2.9104e-02,  3.3676e-02],\n",
      "          [-3.2223e-02, -3.5880e-04,  2.0918e-02]],\n",
      "\n",
      "         [[ 1.8590e-03, -7.2302e-03, -1.5450e-02],\n",
      "          [ 3.6389e-02, -3.5781e-02,  4.1636e-02],\n",
      "          [ 3.8174e-02, -3.7161e-02,  2.4155e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1064e-02,  3.9717e-02,  2.9318e-02],\n",
      "          [ 2.9455e-02,  2.1590e-02,  6.1268e-03],\n",
      "          [ 3.8201e-02, -2.6053e-02,  1.7477e-02]],\n",
      "\n",
      "         [[-2.9435e-02, -2.0429e-02,  1.0619e-02],\n",
      "          [-4.0088e-03, -3.4053e-03,  3.5966e-02],\n",
      "          [-1.8725e-02, -9.0336e-03,  3.8957e-02]],\n",
      "\n",
      "         [[-2.4139e-02,  3.2044e-02,  2.0067e-02],\n",
      "          [ 2.5301e-02,  1.7270e-02,  3.6557e-02],\n",
      "          [-3.2373e-02,  2.4341e-03, -4.1596e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.4332e-02,  2.3024e-02, -9.7958e-03],\n",
      "          [ 1.6964e-02, -4.0815e-02,  2.3075e-02],\n",
      "          [ 2.5359e-02,  3.3955e-02, -2.7380e-02]],\n",
      "\n",
      "         [[ 3.6713e-02, -3.4008e-02,  3.1579e-02],\n",
      "          [ 2.3331e-03, -2.2192e-02, -2.4241e-03],\n",
      "          [ 5.8717e-03,  1.7405e-02,  8.6442e-03]],\n",
      "\n",
      "         [[-9.1934e-03,  1.2676e-02, -1.7911e-02],\n",
      "          [ 1.4457e-04,  3.9185e-02, -1.0193e-02],\n",
      "          [-1.8781e-02,  6.9029e-03,  3.8404e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4548e-02,  4.1523e-02,  1.4112e-02],\n",
      "          [ 2.0117e-02, -1.7703e-02, -1.4036e-02],\n",
      "          [-2.9544e-02, -3.2272e-02,  2.3650e-02]],\n",
      "\n",
      "         [[-2.0059e-02, -1.8567e-02,  3.0003e-02],\n",
      "          [-1.2425e-02, -3.7848e-02,  2.8943e-02],\n",
      "          [ 2.6997e-03, -2.2284e-02, -8.2970e-03]],\n",
      "\n",
      "         [[ 1.1354e-02, -4.0230e-03, -3.3137e-02],\n",
      "          [-2.2679e-02, -6.9922e-03, -3.6452e-03],\n",
      "          [ 3.9140e-02, -2.9608e-02,  4.2512e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1406e-02, -1.1451e-02, -4.0756e-02],\n",
      "          [-2.8407e-02, -8.2767e-03, -2.1813e-02],\n",
      "          [-3.7927e-02,  2.5234e-03,  3.4968e-02]],\n",
      "\n",
      "         [[ 3.1597e-02, -3.8627e-02,  1.8176e-02],\n",
      "          [ 3.8212e-02, -1.5854e-02,  1.3001e-02],\n",
      "          [ 4.0047e-02,  3.7759e-02, -3.9167e-02]],\n",
      "\n",
      "         [[-1.5813e-02, -3.1711e-02, -9.8273e-04],\n",
      "          [ 2.6308e-02, -3.5883e-03,  1.1229e-02],\n",
      "          [-1.0559e-02, -3.5655e-02, -3.7708e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.2029e-02, -8.3258e-05,  2.0238e-02],\n",
      "          [ 1.6718e-02,  3.9335e-02, -4.0925e-02],\n",
      "          [-2.3997e-02,  1.3444e-02,  3.7569e-03]],\n",
      "\n",
      "         [[ 4.0295e-02, -4.1537e-02,  2.0423e-02],\n",
      "          [-3.8182e-05,  2.3682e-02, -1.5940e-02],\n",
      "          [-5.1696e-03,  2.0046e-02,  2.1304e-02]],\n",
      "\n",
      "         [[ 7.5322e-04, -2.3234e-02,  5.4922e-03],\n",
      "          [-9.5076e-03, -7.7417e-03, -2.8146e-02],\n",
      "          [ 2.1845e-02,  3.7908e-02, -1.2824e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7258e-02, -4.1131e-02,  1.5258e-02],\n",
      "          [-3.6060e-02,  3.8500e-02, -2.8091e-02],\n",
      "          [-2.5898e-02,  2.8575e-02, -1.6476e-02]],\n",
      "\n",
      "         [[ 3.5452e-02, -2.9774e-02,  2.4470e-02],\n",
      "          [ 1.5110e-03, -1.3325e-02,  2.7058e-02],\n",
      "          [ 1.8599e-02, -3.0903e-02, -8.1611e-03]],\n",
      "\n",
      "         [[-3.6875e-02, -5.1152e-03,  8.0559e-04],\n",
      "          [-1.0452e-04, -3.0208e-02,  2.0192e-02],\n",
      "          [-5.2873e-03, -2.6902e-02, -3.3101e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.7364e-02,  2.4915e-02,  1.2078e-02],\n",
      "          [ 4.0107e-02,  1.1009e-02,  4.0005e-02],\n",
      "          [ 7.2119e-03,  1.1454e-02,  5.9008e-03]],\n",
      "\n",
      "         [[ 3.1665e-02,  1.2398e-03, -2.4886e-02],\n",
      "          [ 9.1201e-04, -4.1229e-03,  4.0788e-02],\n",
      "          [-2.9113e-02,  3.5656e-02, -2.8818e-02]],\n",
      "\n",
      "         [[-9.2276e-03,  2.7132e-02, -7.4502e-03],\n",
      "          [-3.3269e-02, -1.0608e-02, -2.4191e-02],\n",
      "          [-2.9299e-02, -1.2470e-02,  3.9215e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0218e-02, -1.9994e-02,  8.9213e-03],\n",
      "          [ 1.4415e-02, -7.7890e-03,  2.6120e-02],\n",
      "          [-9.2319e-03,  4.2087e-03,  6.3268e-03]],\n",
      "\n",
      "         [[-6.1334e-03,  2.6639e-02, -2.4491e-02],\n",
      "          [ 1.7427e-02,  1.7182e-02,  3.3844e-02],\n",
      "          [-5.4027e-03,  9.3546e-03, -3.8538e-02]],\n",
      "\n",
      "         [[-1.6549e-03, -8.1358e-03,  4.1461e-02],\n",
      "          [ 4.1161e-02,  6.4289e-03,  1.1283e-02],\n",
      "          [-6.1371e-03,  9.8722e-03, -2.1619e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4618e-02,  1.2092e-02,  3.3650e-02],\n",
      "          [ 1.0888e-02,  3.4388e-02,  4.1426e-02],\n",
      "          [-1.2051e-02, -2.4524e-02, -3.7292e-02]],\n",
      "\n",
      "         [[-2.0792e-02, -3.1753e-02,  3.4450e-02],\n",
      "          [ 4.0992e-02, -3.3921e-02, -3.2426e-02],\n",
      "          [-2.4677e-02,  3.4194e-02,  3.8449e-03]],\n",
      "\n",
      "         [[-2.7608e-02,  3.0568e-02, -1.5643e-02],\n",
      "          [ 4.0925e-02,  1.8131e-02, -3.7778e-02],\n",
      "          [ 3.5321e-03,  1.8358e-02,  1.9224e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5109e-02, -2.5048e-03,  2.0219e-02],\n",
      "          [-3.0194e-02, -1.7714e-03,  3.1031e-02],\n",
      "          [ 1.2348e-02,  1.0838e-04,  2.4287e-03]],\n",
      "\n",
      "         [[-2.8255e-02, -3.4442e-02,  2.2204e-02],\n",
      "          [ 3.5166e-02,  4.1066e-02, -1.3262e-02],\n",
      "          [ 2.0195e-02, -5.2152e-03, -3.7684e-02]],\n",
      "\n",
      "         [[-1.2237e-02, -1.8055e-02,  2.0131e-02],\n",
      "          [-1.6518e-02, -7.6458e-03,  1.5451e-03],\n",
      "          [-4.0620e-03,  1.8651e-02,  3.5106e-02]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0369,  0.0310, -0.0218, -0.0173,  0.0139, -0.0231,  0.0053, -0.0120,\n",
      "        -0.0201, -0.0133,  0.0289, -0.0158,  0.0395, -0.0395, -0.0243, -0.0098,\n",
      "        -0.0012, -0.0380,  0.0178,  0.0383, -0.0003, -0.0231, -0.0146,  0.0058,\n",
      "         0.0369,  0.0008,  0.0067, -0.0245,  0.0099,  0.0373, -0.0019, -0.0287,\n",
      "         0.0283, -0.0182, -0.0089,  0.0400, -0.0296,  0.0131, -0.0031, -0.0295,\n",
      "        -0.0162,  0.0008, -0.0230, -0.0338,  0.0348, -0.0347, -0.0145,  0.0146,\n",
      "         0.0081, -0.0333, -0.0193, -0.0304, -0.0353, -0.0020,  0.0275, -0.0395,\n",
      "        -0.0410,  0.0146, -0.0272, -0.0306, -0.0144, -0.0325,  0.0216,  0.0175],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 2.1427e-02,  2.3089e-02, -3.2135e-02],\n",
      "          [ 2.6486e-02, -2.9034e-02,  3.6149e-02],\n",
      "          [-5.1563e-03, -5.7870e-03,  3.5421e-02]],\n",
      "\n",
      "         [[-3.0281e-03, -4.0952e-02, -3.1602e-03],\n",
      "          [-1.5118e-02, -2.4938e-02,  2.2464e-03],\n",
      "          [ 3.3320e-02, -1.5900e-02, -2.2482e-02]],\n",
      "\n",
      "         [[ 3.3745e-02, -3.7646e-02,  1.7954e-02],\n",
      "          [ 7.8236e-03,  1.9543e-02,  1.7885e-02],\n",
      "          [-1.6030e-02,  3.6606e-02, -1.3826e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7191e-02,  1.1873e-02,  1.7042e-03],\n",
      "          [-3.6434e-02, -4.0081e-03,  1.3247e-02],\n",
      "          [-2.5977e-02, -1.6601e-02, -2.7617e-02]],\n",
      "\n",
      "         [[-2.1919e-02,  2.9100e-02,  3.0686e-02],\n",
      "          [-2.6774e-02,  1.2060e-02, -3.8633e-02],\n",
      "          [ 2.6978e-02,  1.1009e-03,  6.7277e-03]],\n",
      "\n",
      "         [[-2.3802e-02,  2.0845e-02, -7.2144e-03],\n",
      "          [ 4.0182e-03,  2.8730e-02,  3.6980e-02],\n",
      "          [ 3.5340e-02, -3.2247e-02, -2.2906e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2833e-02,  2.6793e-02,  9.1140e-03],\n",
      "          [-3.5547e-02, -2.6095e-02, -4.7404e-03],\n",
      "          [-3.6896e-02,  1.8228e-02,  1.4547e-02]],\n",
      "\n",
      "         [[ 3.6193e-03,  1.6621e-03, -3.0211e-02],\n",
      "          [ 1.0296e-02,  8.2722e-03,  1.7430e-02],\n",
      "          [ 2.2445e-02,  2.2702e-02,  3.2629e-02]],\n",
      "\n",
      "         [[-6.1288e-04,  2.1799e-02, -3.5744e-02],\n",
      "          [-2.6680e-02, -3.4570e-02,  3.2596e-02],\n",
      "          [ 1.3370e-02,  1.3962e-02,  1.0349e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0689e-02,  1.7923e-02,  7.7475e-03],\n",
      "          [ 3.5444e-02,  5.9524e-03, -2.0518e-02],\n",
      "          [ 3.4974e-02,  3.9704e-02,  1.3510e-02]],\n",
      "\n",
      "         [[-5.9495e-03, -1.0626e-02, -1.1560e-02],\n",
      "          [-3.6756e-02, -2.4246e-02, -4.0548e-02],\n",
      "          [ 1.1065e-02,  3.0025e-02,  4.1194e-02]],\n",
      "\n",
      "         [[-1.7234e-02,  1.5358e-02, -3.3953e-02],\n",
      "          [ 4.4332e-03, -2.5427e-02, -2.8557e-02],\n",
      "          [-3.6370e-03, -1.4790e-02, -3.0680e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8193e-02, -3.4544e-02, -2.2001e-02],\n",
      "          [ 3.4300e-02,  3.4754e-02,  3.3450e-02],\n",
      "          [-1.0493e-02,  1.2460e-02, -2.8839e-03]],\n",
      "\n",
      "         [[-1.6423e-02,  3.3078e-02, -7.8721e-03],\n",
      "          [-4.9284e-03,  1.9706e-02, -9.9763e-03],\n",
      "          [-3.6108e-02, -1.5136e-02, -9.3637e-03]],\n",
      "\n",
      "         [[ 1.1005e-02,  2.3440e-02,  2.7360e-02],\n",
      "          [-2.1893e-03, -1.6019e-03, -1.2804e-03],\n",
      "          [-2.6574e-02,  3.0654e-02,  1.9425e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1819e-02, -6.4431e-03,  3.9003e-02],\n",
      "          [-5.2769e-03, -9.2458e-03, -2.7910e-02],\n",
      "          [ 2.6224e-02,  4.9253e-03, -3.9115e-02]],\n",
      "\n",
      "         [[-2.3106e-02,  2.4236e-02, -2.0301e-02],\n",
      "          [ 6.9550e-03, -2.1128e-02,  2.4677e-02],\n",
      "          [-3.3941e-02, -5.6930e-04, -4.1588e-02]],\n",
      "\n",
      "         [[-1.1452e-02, -2.2126e-02, -2.9619e-02],\n",
      "          [ 3.2819e-03,  2.0723e-02, -2.7931e-03],\n",
      "          [-4.1271e-02, -6.3460e-03, -1.0839e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.4804e-02, -4.0829e-02,  7.3603e-03],\n",
      "          [-5.3668e-03, -2.7529e-02, -1.3359e-02],\n",
      "          [-1.6770e-02, -2.8264e-02,  2.9718e-02]],\n",
      "\n",
      "         [[ 1.2328e-02,  1.5552e-02,  1.9025e-02],\n",
      "          [ 9.8824e-03, -1.3157e-02,  5.2145e-03],\n",
      "          [-4.0856e-02,  3.5015e-03,  2.3647e-02]],\n",
      "\n",
      "         [[-3.1505e-02, -2.6414e-02, -1.4508e-02],\n",
      "          [ 3.9930e-02,  1.2504e-04,  1.1916e-02],\n",
      "          [ 1.9335e-02, -2.9840e-02, -3.0833e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1147e-02, -9.3589e-03, -4.7848e-03],\n",
      "          [ 4.6722e-03, -2.1775e-03, -3.0722e-02],\n",
      "          [ 1.7508e-02,  8.6458e-03,  1.8110e-02]],\n",
      "\n",
      "         [[-9.3782e-03,  7.6932e-03, -1.8274e-03],\n",
      "          [ 1.7164e-02, -2.1350e-02, -9.9255e-03],\n",
      "          [-3.5016e-02, -1.9177e-02, -3.6940e-02]],\n",
      "\n",
      "         [[-7.8473e-03,  2.3740e-02,  1.5473e-02],\n",
      "          [ 3.0180e-02,  3.7589e-04,  1.5199e-02],\n",
      "          [-2.4161e-02, -3.7714e-02,  1.9530e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4246e-02,  2.7179e-02,  1.8495e-02],\n",
      "          [-2.6455e-02,  3.7599e-02,  1.7230e-02],\n",
      "          [ 3.5781e-02, -3.5819e-02, -3.7079e-02]],\n",
      "\n",
      "         [[-1.5066e-02,  3.3314e-02,  2.4394e-03],\n",
      "          [-2.1448e-02, -9.7843e-03, -8.2235e-03],\n",
      "          [-3.7512e-03,  1.7850e-02,  8.2989e-03]],\n",
      "\n",
      "         [[ 1.6472e-03,  3.1957e-02,  2.2499e-02],\n",
      "          [ 1.1125e-02,  9.2137e-03, -3.4467e-02],\n",
      "          [-4.2855e-04,  2.2653e-02, -3.8170e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2956e-04,  2.4989e-03, -2.9042e-02],\n",
      "          [ 1.9203e-02, -3.0292e-02, -2.7423e-02],\n",
      "          [ 1.9697e-02, -2.5783e-02,  2.1858e-02]],\n",
      "\n",
      "         [[ 2.3224e-02,  1.7894e-02,  1.0027e-02],\n",
      "          [ 2.4973e-02,  2.3599e-02, -2.3886e-02],\n",
      "          [ 1.5942e-02,  8.1478e-03,  1.6223e-02]],\n",
      "\n",
      "         [[ 4.7207e-03, -5.0165e-03,  1.9869e-03],\n",
      "          [ 1.9901e-03, -2.1188e-04, -3.6668e-02],\n",
      "          [-8.9362e-03, -2.0340e-02,  3.4706e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7896e-02, -2.0597e-03,  6.1052e-03],\n",
      "          [-3.3873e-02,  2.4571e-02, -2.5404e-02],\n",
      "          [-1.7854e-02, -3.2839e-02, -9.9126e-03]],\n",
      "\n",
      "         [[-2.4077e-02,  1.0508e-03, -1.0747e-02],\n",
      "          [-1.9483e-02,  4.0326e-03, -1.5034e-02],\n",
      "          [-2.6846e-02, -4.0508e-02,  1.7527e-02]],\n",
      "\n",
      "         [[-1.0295e-03,  1.7738e-02,  3.1387e-02],\n",
      "          [-1.9535e-02,  4.9040e-05, -1.4162e-02],\n",
      "          [-1.9167e-02, -1.5303e-03, -3.3924e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3496e-02,  2.2950e-02,  1.7866e-02],\n",
      "          [-6.9251e-03,  2.9810e-02, -3.4659e-02],\n",
      "          [-3.2718e-02,  3.9914e-02,  3.0006e-02]],\n",
      "\n",
      "         [[-1.3199e-02, -3.6835e-02, -3.0825e-02],\n",
      "          [ 2.3586e-02, -9.6307e-03,  3.7551e-02],\n",
      "          [-3.7278e-02,  4.0348e-02, -2.1062e-02]],\n",
      "\n",
      "         [[-1.6216e-02,  1.6201e-02, -2.5730e-02],\n",
      "          [-3.3110e-02,  3.1872e-02, -1.6943e-02],\n",
      "          [ 2.7695e-02, -2.4143e-02, -3.5116e-03]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0270, -0.0296,  0.0209, -0.0071,  0.0028, -0.0126, -0.0011,  0.0232,\n",
      "        -0.0033,  0.0316, -0.0036,  0.0121,  0.0211, -0.0314,  0.0185, -0.0066,\n",
      "         0.0284, -0.0346, -0.0401,  0.0256, -0.0168,  0.0269,  0.0070, -0.0037,\n",
      "        -0.0288, -0.0288, -0.0395,  0.0251,  0.0208, -0.0241,  0.0206,  0.0411,\n",
      "         0.0243,  0.0214,  0.0051, -0.0373,  0.0324, -0.0127,  0.0400,  0.0304,\n",
      "        -0.0079,  0.0196,  0.0279, -0.0370,  0.0242, -0.0157,  0.0106, -0.0112,\n",
      "         0.0393,  0.0405, -0.0279, -0.0340, -0.0077, -0.0352, -0.0088, -0.0271,\n",
      "        -0.0269, -0.0036,  0.0016, -0.0288, -0.0386, -0.0212,  0.0057, -0.0079,\n",
      "         0.0037, -0.0246, -0.0058,  0.0038, -0.0165,  0.0036,  0.0309, -0.0331,\n",
      "         0.0137,  0.0299, -0.0073,  0.0338,  0.0308, -0.0278,  0.0098, -0.0299,\n",
      "         0.0233,  0.0032,  0.0085,  0.0337, -0.0193,  0.0160,  0.0063,  0.0253,\n",
      "        -0.0126, -0.0388, -0.0079,  0.0150, -0.0151,  0.0148, -0.0087,  0.0296,\n",
      "         0.0273,  0.0121, -0.0248,  0.0166, -0.0178,  0.0300,  0.0146, -0.0021,\n",
      "         0.0267,  0.0081,  0.0082,  0.0137, -0.0098,  0.0400,  0.0192, -0.0373,\n",
      "         0.0371,  0.0026,  0.0207, -0.0157, -0.0218, -0.0132,  0.0039,  0.0397,\n",
      "         0.0130,  0.0331,  0.0134, -0.0192, -0.0366, -0.0240,  0.0074, -0.0023],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 1.3124e-02, -1.1335e-02,  1.8329e-02],\n",
      "          [ 9.2991e-03, -2.4647e-02, -1.8826e-02],\n",
      "          [-2.4071e-02, -2.8836e-03, -1.5313e-03]],\n",
      "\n",
      "         [[ 1.8969e-02,  1.4748e-02,  2.8517e-02],\n",
      "          [-2.2036e-02, -2.7048e-02, -1.4453e-02],\n",
      "          [ 1.6942e-02, -1.1426e-02,  1.1098e-03]],\n",
      "\n",
      "         [[-1.0251e-03, -1.9965e-02, -2.0291e-02],\n",
      "          [-9.3264e-03, -1.2221e-02,  2.0704e-02],\n",
      "          [ 2.3068e-02,  1.4546e-02,  1.6872e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2945e-02, -4.1800e-03, -3.5617e-03],\n",
      "          [-2.8919e-02, -1.2822e-02,  2.9025e-02],\n",
      "          [-2.9222e-02, -2.4308e-02,  2.9038e-02]],\n",
      "\n",
      "         [[-1.3190e-02, -6.2573e-03, -2.3242e-04],\n",
      "          [ 2.3583e-02,  1.9346e-02,  2.1607e-02],\n",
      "          [ 1.5575e-02, -6.7059e-03,  1.3739e-02]],\n",
      "\n",
      "         [[ 1.3901e-03,  2.0958e-02, -7.4619e-03],\n",
      "          [-2.0942e-02, -1.6979e-02, -1.3447e-03],\n",
      "          [-2.0506e-02,  1.7944e-03, -2.4577e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6637e-02, -2.4449e-02,  2.4785e-04],\n",
      "          [ 1.3233e-02, -9.6826e-03, -2.6924e-02],\n",
      "          [ 2.6723e-02,  2.9443e-02, -4.6274e-03]],\n",
      "\n",
      "         [[-5.2372e-03,  1.2354e-02,  1.8935e-04],\n",
      "          [ 2.5306e-02,  1.1392e-02,  2.4747e-02],\n",
      "          [ 1.0736e-02, -2.8008e-02, -2.0816e-02]],\n",
      "\n",
      "         [[-7.6577e-03, -2.2918e-02,  7.2947e-03],\n",
      "          [-2.8917e-02, -2.2050e-02,  1.0434e-02],\n",
      "          [ 1.1229e-02,  2.3916e-02,  3.3960e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2508e-02, -1.6606e-02,  1.3131e-02],\n",
      "          [ 1.3499e-02,  2.3345e-02, -1.3926e-02],\n",
      "          [ 1.8103e-02,  2.9381e-02,  8.1776e-03]],\n",
      "\n",
      "         [[ 1.8467e-03, -2.6696e-02, -1.5712e-02],\n",
      "          [-2.5312e-02,  1.3104e-02, -4.4887e-03],\n",
      "          [ 6.9496e-03, -8.0330e-03, -1.6809e-02]],\n",
      "\n",
      "         [[-7.4330e-03, -7.6402e-03, -1.8387e-02],\n",
      "          [-1.6039e-02, -2.0446e-02, -1.7785e-02],\n",
      "          [-2.1847e-02, -2.1399e-03, -2.6395e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6528e-02, -1.1397e-02, -1.9037e-02],\n",
      "          [-1.2241e-02, -2.3753e-02,  2.0692e-02],\n",
      "          [ 2.0833e-02,  2.7040e-03,  7.4189e-03]],\n",
      "\n",
      "         [[ 9.4086e-03,  2.3565e-02, -2.0546e-02],\n",
      "          [ 1.3962e-02,  9.3165e-03,  7.2500e-03],\n",
      "          [-1.6060e-03,  4.6124e-03, -1.2978e-02]],\n",
      "\n",
      "         [[ 2.2605e-02, -5.8257e-03,  2.5852e-02],\n",
      "          [-1.0606e-02, -2.5466e-02,  1.0174e-03],\n",
      "          [ 1.8411e-02, -2.5921e-02, -3.9753e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9020e-02, -7.1042e-03,  2.5567e-03],\n",
      "          [-1.0231e-02, -5.7715e-03, -1.2741e-02],\n",
      "          [-6.4013e-03,  6.3139e-05,  6.9875e-03]],\n",
      "\n",
      "         [[-7.4054e-04,  1.8221e-02,  1.3365e-02],\n",
      "          [-4.9474e-03, -2.5878e-02, -2.4237e-02],\n",
      "          [ 2.7625e-02,  2.8566e-02, -2.4987e-02]],\n",
      "\n",
      "         [[ 2.5527e-02, -2.6021e-02,  2.5868e-02],\n",
      "          [ 1.5977e-02,  2.2674e-02, -7.2433e-03],\n",
      "          [-1.8889e-02, -4.8447e-03,  1.0225e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.9250e-02,  3.6274e-03,  1.4934e-03],\n",
      "          [ 9.0135e-03,  2.0723e-02, -1.3592e-02],\n",
      "          [-1.2331e-02,  1.5132e-02,  7.0181e-03]],\n",
      "\n",
      "         [[-2.4640e-02, -2.3570e-02, -1.4414e-02],\n",
      "          [ 5.4032e-03, -3.7157e-03, -6.1429e-03],\n",
      "          [-9.8951e-03, -1.0600e-02, -1.5792e-02]],\n",
      "\n",
      "         [[-2.0129e-02,  2.2356e-02, -1.4878e-02],\n",
      "          [ 8.8129e-03,  1.8429e-02, -1.0956e-02],\n",
      "          [-8.6782e-03,  1.4041e-02,  1.1568e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8142e-02, -1.6003e-02, -7.5348e-03],\n",
      "          [ 1.7575e-03,  7.7047e-03,  2.8457e-02],\n",
      "          [-2.9331e-02,  2.0665e-02, -1.3509e-02]],\n",
      "\n",
      "         [[-1.2899e-02,  2.6698e-02,  1.1674e-02],\n",
      "          [ 1.2976e-02,  1.4473e-02,  9.0999e-04],\n",
      "          [ 1.3110e-02, -2.3050e-02, -2.9341e-02]],\n",
      "\n",
      "         [[ 2.2496e-02, -2.3926e-02, -2.3403e-03],\n",
      "          [-3.0783e-03, -2.0883e-02,  1.3336e-02],\n",
      "          [ 1.8954e-02, -1.6039e-02,  1.4496e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0403e-02, -2.6380e-02, -2.1845e-02],\n",
      "          [ 8.4047e-03,  2.5733e-03,  1.1429e-02],\n",
      "          [-1.7541e-02, -9.5564e-03,  1.2207e-02]],\n",
      "\n",
      "         [[ 2.6004e-02, -1.1037e-02,  1.2969e-02],\n",
      "          [ 1.4009e-02,  1.4778e-02,  1.1951e-02],\n",
      "          [-7.7245e-04,  1.1915e-02,  2.9190e-02]],\n",
      "\n",
      "         [[-2.7760e-02,  2.3490e-02,  9.2841e-03],\n",
      "          [-2.5521e-02, -1.7659e-04,  2.5512e-04],\n",
      "          [ 1.8272e-02,  2.2106e-02, -1.3575e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6466e-03,  2.4282e-02,  9.0167e-03],\n",
      "          [ 5.5382e-03, -2.0470e-02,  2.7353e-02],\n",
      "          [-2.0979e-02,  5.5416e-03,  2.6332e-02]],\n",
      "\n",
      "         [[ 1.4569e-02,  2.2950e-03, -2.2486e-02],\n",
      "          [-1.0123e-02,  2.7488e-02,  2.5928e-02],\n",
      "          [-3.3137e-03,  1.5874e-03,  2.0429e-02]],\n",
      "\n",
      "         [[-2.0133e-02,  1.3530e-02, -1.7111e-02],\n",
      "          [-2.4912e-02,  1.9721e-02, -5.6421e-03],\n",
      "          [ 9.1394e-03,  2.4674e-02,  2.4686e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9085e-02, -1.7763e-03,  9.8826e-04],\n",
      "          [-8.9824e-03,  1.3140e-02,  1.7460e-02],\n",
      "          [-2.6717e-02,  1.9328e-02,  8.3798e-03]],\n",
      "\n",
      "         [[-2.3742e-02,  2.2046e-02, -2.7797e-02],\n",
      "          [-2.3182e-02, -7.8399e-03,  1.8092e-03],\n",
      "          [-6.9006e-03, -2.3456e-02, -2.2850e-02]],\n",
      "\n",
      "         [[ 2.2396e-03,  1.1863e-02,  4.5845e-03],\n",
      "          [-2.4328e-02,  4.6170e-03,  1.3013e-03],\n",
      "          [-7.5969e-03, -2.7943e-02,  1.0105e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4371e-02, -1.5693e-02, -6.9425e-03],\n",
      "          [-5.8038e-03,  1.1941e-02,  2.2077e-02],\n",
      "          [-1.5002e-02,  4.3390e-03,  1.1124e-02]],\n",
      "\n",
      "         [[-2.5892e-02, -1.6689e-02, -1.4501e-02],\n",
      "          [ 1.9227e-02, -8.8272e-03,  2.3501e-03],\n",
      "          [ 2.1723e-02, -2.0058e-02,  1.4707e-02]],\n",
      "\n",
      "         [[-2.2694e-02, -2.6777e-02, -5.0051e-03],\n",
      "          [ 2.9406e-02, -1.6395e-02,  1.0495e-02],\n",
      "          [ 1.7678e-02, -1.4858e-02, -1.9789e-02]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0189, -0.0241, -0.0052, -0.0091,  0.0112, -0.0143, -0.0100, -0.0131,\n",
      "        -0.0085, -0.0246, -0.0221, -0.0099,  0.0056, -0.0228,  0.0029, -0.0101,\n",
      "         0.0130,  0.0012, -0.0207,  0.0106, -0.0217,  0.0066, -0.0047,  0.0251,\n",
      "         0.0260, -0.0256, -0.0118,  0.0106,  0.0249,  0.0264,  0.0257, -0.0007,\n",
      "         0.0291, -0.0023,  0.0189,  0.0182, -0.0002, -0.0227,  0.0036,  0.0098,\n",
      "         0.0090,  0.0289,  0.0004,  0.0236, -0.0007,  0.0146, -0.0082, -0.0112,\n",
      "         0.0142, -0.0243, -0.0209, -0.0048,  0.0092, -0.0051,  0.0069, -0.0160,\n",
      "         0.0036, -0.0209,  0.0202,  0.0099, -0.0057, -0.0283, -0.0190,  0.0120,\n",
      "         0.0008,  0.0105,  0.0215, -0.0083, -0.0147,  0.0264, -0.0175, -0.0261,\n",
      "         0.0002, -0.0072, -0.0206, -0.0065,  0.0266,  0.0149,  0.0093,  0.0293,\n",
      "        -0.0196,  0.0180,  0.0091,  0.0193, -0.0158, -0.0252, -0.0095, -0.0140,\n",
      "         0.0029,  0.0068,  0.0241,  0.0109,  0.0197,  0.0051, -0.0203, -0.0076,\n",
      "        -0.0052, -0.0113, -0.0141,  0.0046,  0.0243,  0.0019,  0.0065,  0.0033,\n",
      "        -0.0178, -0.0068,  0.0061,  0.0113, -0.0179, -0.0161, -0.0199,  0.0190,\n",
      "        -0.0225, -0.0043,  0.0141,  0.0237, -0.0087,  0.0014, -0.0118, -0.0266,\n",
      "        -0.0024, -0.0176,  0.0154,  0.0275, -0.0171,  0.0107, -0.0048,  0.0153],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0177,  0.0239, -0.0146],\n",
      "          [ 0.0174,  0.0027,  0.0087],\n",
      "          [-0.0014, -0.0239, -0.0097]],\n",
      "\n",
      "         [[-0.0011,  0.0193, -0.0076],\n",
      "          [ 0.0052,  0.0292, -0.0235],\n",
      "          [-0.0089,  0.0279, -0.0123]],\n",
      "\n",
      "         [[-0.0045, -0.0280, -0.0146],\n",
      "          [-0.0131, -0.0002, -0.0098],\n",
      "          [-0.0275,  0.0103,  0.0281]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0180, -0.0030, -0.0263],\n",
      "          [-0.0236, -0.0030,  0.0201],\n",
      "          [-0.0090, -0.0164,  0.0085]],\n",
      "\n",
      "         [[-0.0162,  0.0019,  0.0207],\n",
      "          [-0.0219, -0.0278, -0.0176],\n",
      "          [-0.0271, -0.0056, -0.0113]],\n",
      "\n",
      "         [[-0.0121,  0.0236,  0.0241],\n",
      "          [ 0.0024, -0.0042,  0.0170],\n",
      "          [ 0.0086,  0.0070, -0.0195]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0286, -0.0262,  0.0091],\n",
      "          [-0.0027, -0.0281,  0.0017],\n",
      "          [ 0.0279,  0.0268,  0.0141]],\n",
      "\n",
      "         [[ 0.0012, -0.0143,  0.0245],\n",
      "          [ 0.0061, -0.0193,  0.0082],\n",
      "          [-0.0016,  0.0153,  0.0020]],\n",
      "\n",
      "         [[ 0.0161,  0.0023, -0.0171],\n",
      "          [-0.0170,  0.0292, -0.0198],\n",
      "          [ 0.0156,  0.0226,  0.0190]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0168,  0.0081, -0.0204],\n",
      "          [-0.0281,  0.0052,  0.0003],\n",
      "          [ 0.0200,  0.0012,  0.0025]],\n",
      "\n",
      "         [[ 0.0085,  0.0034,  0.0202],\n",
      "          [-0.0081,  0.0006,  0.0281],\n",
      "          [-0.0053, -0.0134, -0.0171]],\n",
      "\n",
      "         [[ 0.0020,  0.0185,  0.0143],\n",
      "          [ 0.0032,  0.0155, -0.0040],\n",
      "          [ 0.0002,  0.0251, -0.0225]]],\n",
      "\n",
      "\n",
      "        [[[-0.0117,  0.0207,  0.0246],\n",
      "          [ 0.0071, -0.0129, -0.0080],\n",
      "          [-0.0209,  0.0154, -0.0270]],\n",
      "\n",
      "         [[-0.0128,  0.0251,  0.0237],\n",
      "          [-0.0275, -0.0033, -0.0079],\n",
      "          [-0.0278, -0.0278,  0.0032]],\n",
      "\n",
      "         [[ 0.0068, -0.0036,  0.0163],\n",
      "          [ 0.0086,  0.0099, -0.0010],\n",
      "          [-0.0090, -0.0056,  0.0211]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0196, -0.0256,  0.0073],\n",
      "          [ 0.0015,  0.0097, -0.0138],\n",
      "          [-0.0145,  0.0007,  0.0200]],\n",
      "\n",
      "         [[-0.0102, -0.0003, -0.0274],\n",
      "          [-0.0217, -0.0167, -0.0129],\n",
      "          [-0.0090,  0.0108,  0.0229]],\n",
      "\n",
      "         [[ 0.0136, -0.0161,  0.0042],\n",
      "          [-0.0237,  0.0255,  0.0226],\n",
      "          [ 0.0099,  0.0055, -0.0210]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0288,  0.0178, -0.0241],\n",
      "          [-0.0237, -0.0039,  0.0140],\n",
      "          [ 0.0249,  0.0281, -0.0242]],\n",
      "\n",
      "         [[ 0.0152,  0.0250,  0.0184],\n",
      "          [ 0.0261, -0.0121,  0.0207],\n",
      "          [ 0.0080,  0.0257,  0.0162]],\n",
      "\n",
      "         [[-0.0274,  0.0124, -0.0121],\n",
      "          [-0.0276,  0.0170, -0.0195],\n",
      "          [ 0.0292,  0.0106,  0.0185]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0088, -0.0260,  0.0264],\n",
      "          [ 0.0063, -0.0025, -0.0005],\n",
      "          [-0.0058, -0.0282, -0.0073]],\n",
      "\n",
      "         [[-0.0155,  0.0204, -0.0249],\n",
      "          [-0.0241,  0.0238,  0.0281],\n",
      "          [-0.0194, -0.0058,  0.0163]],\n",
      "\n",
      "         [[ 0.0176, -0.0104,  0.0083],\n",
      "          [ 0.0252,  0.0076, -0.0025],\n",
      "          [-0.0043,  0.0016,  0.0189]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0069, -0.0102, -0.0019],\n",
      "          [-0.0227, -0.0262,  0.0128],\n",
      "          [ 0.0236,  0.0226, -0.0170]],\n",
      "\n",
      "         [[-0.0071, -0.0076, -0.0074],\n",
      "          [-0.0049, -0.0199, -0.0205],\n",
      "          [-0.0081,  0.0216,  0.0260]],\n",
      "\n",
      "         [[ 0.0177, -0.0242,  0.0116],\n",
      "          [ 0.0068, -0.0120, -0.0002],\n",
      "          [ 0.0043, -0.0015,  0.0154]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0152, -0.0156,  0.0113],\n",
      "          [ 0.0176, -0.0247,  0.0124],\n",
      "          [ 0.0265,  0.0006, -0.0041]],\n",
      "\n",
      "         [[ 0.0136, -0.0026, -0.0109],\n",
      "          [ 0.0235,  0.0267,  0.0145],\n",
      "          [ 0.0073,  0.0160,  0.0054]],\n",
      "\n",
      "         [[-0.0292, -0.0064, -0.0125],\n",
      "          [ 0.0145, -0.0220,  0.0036],\n",
      "          [ 0.0067, -0.0062,  0.0026]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0148,  0.0115, -0.0227],\n",
      "          [-0.0011,  0.0018, -0.0038],\n",
      "          [ 0.0257, -0.0011, -0.0087]],\n",
      "\n",
      "         [[ 0.0250, -0.0040, -0.0105],\n",
      "          [-0.0070, -0.0062,  0.0121],\n",
      "          [-0.0011,  0.0218,  0.0130]],\n",
      "\n",
      "         [[ 0.0140, -0.0197, -0.0231],\n",
      "          [-0.0265,  0.0127,  0.0181],\n",
      "          [-0.0179,  0.0142, -0.0128]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0252,  0.0294, -0.0235],\n",
      "          [-0.0272, -0.0041,  0.0292],\n",
      "          [ 0.0226, -0.0101, -0.0079]],\n",
      "\n",
      "         [[ 0.0060,  0.0286, -0.0190],\n",
      "          [ 0.0143,  0.0122,  0.0232],\n",
      "          [-0.0138,  0.0294,  0.0156]],\n",
      "\n",
      "         [[ 0.0144,  0.0197, -0.0089],\n",
      "          [ 0.0233, -0.0152, -0.0280],\n",
      "          [-0.0071, -0.0204, -0.0114]]]], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.3364e-03, -5.0252e-03, -2.0664e-02,  2.2887e-02,  2.7893e-02,\n",
      "         6.6002e-03,  2.8591e-02,  1.2752e-03,  2.1596e-02, -1.6130e-02,\n",
      "         1.5688e-02, -8.7698e-03, -2.0999e-04,  2.2276e-02,  1.9282e-02,\n",
      "         2.0676e-02,  9.3962e-03, -2.0524e-02, -2.6102e-02,  2.8337e-03,\n",
      "         2.4071e-02, -1.0380e-02,  1.3291e-02,  2.3516e-02, -2.1430e-02,\n",
      "         5.5471e-04,  4.2525e-03, -1.1601e-02, -2.1126e-02,  1.3317e-02,\n",
      "         2.1768e-02,  4.2963e-04, -4.6413e-03, -1.6193e-02, -2.5558e-02,\n",
      "         1.0466e-02,  6.2626e-03, -2.5200e-02,  3.5594e-03, -1.5030e-02,\n",
      "         2.4266e-02, -1.2520e-02,  2.1822e-02, -1.7064e-02,  1.6876e-03,\n",
      "         4.6063e-03,  2.3742e-02,  6.0680e-03,  2.6929e-02, -2.9867e-04,\n",
      "         9.7868e-03,  1.8094e-02,  2.7392e-02,  1.8061e-02,  1.1567e-02,\n",
      "         2.4043e-02, -2.4013e-02,  2.4917e-02,  2.6562e-02,  1.0300e-03,\n",
      "        -3.9222e-03, -1.9987e-03,  2.1904e-02, -1.6936e-02,  2.3690e-02,\n",
      "         1.9569e-02,  1.8060e-02, -1.5227e-02,  2.6917e-02,  2.2874e-02,\n",
      "         7.8038e-03, -9.5198e-03,  2.6053e-03,  2.2076e-02,  1.2773e-02,\n",
      "         1.3572e-03,  1.8836e-02, -4.7627e-03,  1.5384e-02,  3.0231e-03,\n",
      "         1.6476e-02,  9.9170e-03,  2.5158e-02,  2.6526e-02, -1.4645e-02,\n",
      "        -1.1934e-02,  4.2516e-03,  9.7990e-03,  1.7932e-03, -1.7801e-02,\n",
      "        -1.0026e-02,  2.7574e-02,  1.7268e-02, -1.6754e-02,  2.0882e-02,\n",
      "         2.4637e-02,  2.1062e-02, -4.7988e-03,  2.5707e-02,  1.6825e-02,\n",
      "         1.1370e-02,  1.1999e-02,  2.2080e-02, -1.1160e-02, -2.1043e-02,\n",
      "         2.1088e-02,  1.8803e-02,  6.9477e-03,  1.9380e-02, -2.8136e-02,\n",
      "         2.9925e-03,  1.7044e-02,  2.6149e-02,  1.4311e-03,  6.9520e-03,\n",
      "         5.4649e-03,  4.3084e-04, -2.7699e-02, -2.5415e-02, -9.9312e-03,\n",
      "        -5.6330e-03,  8.1000e-03, -3.2681e-03, -1.5388e-03,  6.3225e-03,\n",
      "        -2.8466e-02,  1.8607e-03,  8.5745e-03, -1.3284e-02, -1.6530e-02,\n",
      "        -1.2275e-03, -4.8543e-05,  2.6701e-02, -2.8076e-02, -1.1055e-02,\n",
      "        -2.9330e-02, -1.9769e-02,  8.4046e-03, -1.6737e-03, -2.4831e-03,\n",
      "        -1.2858e-02, -6.2204e-03,  2.2675e-03,  9.8178e-03,  1.8978e-02,\n",
      "        -5.8092e-03,  2.7784e-02, -5.1388e-03, -2.4652e-02,  1.9468e-02,\n",
      "        -2.2711e-04, -1.6076e-02,  1.1555e-02,  2.7121e-02, -2.7951e-02,\n",
      "         2.2527e-02,  2.3571e-02,  1.1180e-02, -2.0230e-02, -2.6891e-02,\n",
      "        -3.6860e-03,  3.7445e-03,  1.3979e-03,  2.7102e-02,  4.4612e-03,\n",
      "        -1.3629e-02, -1.4861e-02, -2.9278e-02,  2.3106e-02,  7.4764e-03,\n",
      "         2.5117e-02, -2.0682e-03, -2.8200e-02,  1.1660e-02, -1.0547e-02,\n",
      "         8.7723e-03,  3.0666e-03, -7.4543e-03,  2.7446e-02, -2.6065e-02,\n",
      "         2.2722e-02,  4.9932e-03,  6.3376e-03,  1.2304e-02,  1.7878e-02,\n",
      "        -2.7798e-02,  4.3249e-03,  2.7217e-02,  1.0918e-02,  2.7035e-02,\n",
      "        -1.3735e-02, -1.0234e-02, -2.6604e-03, -2.6378e-02, -2.7935e-02,\n",
      "        -4.0133e-03,  2.7625e-02,  8.0645e-03, -7.0381e-03,  2.6807e-02,\n",
      "        -3.8962e-03, -8.3453e-03, -2.3536e-02,  2.6521e-02,  2.2838e-02,\n",
      "         2.1821e-02,  1.1506e-02, -1.5237e-02, -2.0652e-02,  2.2746e-02,\n",
      "         1.8272e-02,  1.1211e-02, -2.5030e-02,  3.5618e-03, -2.7840e-02,\n",
      "         2.1288e-03,  4.9796e-03,  5.6158e-03,  1.1587e-02,  1.5071e-02,\n",
      "        -4.7346e-03, -1.6279e-02,  1.1106e-02,  1.9715e-02,  2.1387e-02,\n",
      "        -1.0727e-02, -2.8359e-02,  1.4558e-02, -2.8593e-02,  1.1418e-02,\n",
      "         2.0675e-02,  1.1160e-03, -9.0046e-03, -1.8697e-02,  1.4686e-02,\n",
      "        -2.7548e-02, -2.8723e-02, -7.3359e-03, -2.6164e-02, -1.5371e-02,\n",
      "         7.3225e-03, -1.9044e-02, -2.4671e-02,  2.0665e-02,  2.4964e-02,\n",
      "        -2.2047e-02,  2.7922e-02, -1.5418e-02,  2.5178e-02,  1.1139e-02,\n",
      "         2.5965e-02,  4.9583e-03, -1.9239e-02, -6.1245e-03,  1.9925e-02,\n",
      "        -1.8475e-02], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 1.6851e-02, -7.0543e-03, -6.7753e-03],\n",
      "          [ 4.4715e-03,  1.2489e-02,  2.6468e-04],\n",
      "          [-1.1188e-02,  8.4529e-03,  5.4117e-03]],\n",
      "\n",
      "         [[-7.3686e-04,  1.2540e-02, -1.3026e-02],\n",
      "          [ 1.3994e-02,  1.7578e-02,  1.4021e-02],\n",
      "          [-1.1583e-02, -1.0857e-02, -6.4289e-03]],\n",
      "\n",
      "         [[ 1.4843e-02,  1.7118e-02, -8.6425e-03],\n",
      "          [ 1.4521e-02, -1.1235e-02, -1.1925e-02],\n",
      "          [-1.7760e-02, -9.5476e-03,  1.2278e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7142e-02,  2.6071e-03, -9.4855e-04],\n",
      "          [-1.3221e-02,  7.1233e-03, -1.9054e-02],\n",
      "          [ 4.6273e-03,  1.6141e-02,  1.1671e-02]],\n",
      "\n",
      "         [[-1.1406e-02, -1.8681e-02,  6.4717e-03],\n",
      "          [ 3.9896e-03,  8.8223e-03, -1.3052e-03],\n",
      "          [-1.5309e-02,  1.3025e-02, -1.8030e-02]],\n",
      "\n",
      "         [[-2.5519e-04, -2.0684e-03, -1.1170e-02],\n",
      "          [-6.6951e-05,  8.9272e-03,  1.1027e-02],\n",
      "          [-7.1143e-03, -1.8473e-03,  6.7712e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6330e-03,  6.9929e-03,  8.8292e-04],\n",
      "          [ 1.3067e-02, -1.3239e-02, -9.1062e-03],\n",
      "          [-8.0820e-03,  1.1205e-02,  2.3183e-03]],\n",
      "\n",
      "         [[ 9.6095e-03,  8.9479e-03, -2.8120e-03],\n",
      "          [ 1.7627e-02,  1.6926e-02, -1.7688e-02],\n",
      "          [-2.3521e-03, -1.4996e-02,  1.8923e-02]],\n",
      "\n",
      "         [[ 1.2586e-02, -1.3725e-02, -2.4952e-03],\n",
      "          [-1.2101e-03,  1.9140e-02,  2.6900e-03],\n",
      "          [-7.9856e-03,  2.2939e-04, -1.5701e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2629e-03, -7.7641e-04,  5.2816e-03],\n",
      "          [ 8.2924e-03, -3.2628e-03, -7.6055e-03],\n",
      "          [-2.3018e-03,  3.5240e-03,  1.8867e-02]],\n",
      "\n",
      "         [[-7.5829e-03, -1.6266e-02, -1.9041e-02],\n",
      "          [-2.0809e-02, -2.8306e-03,  4.4893e-03],\n",
      "          [-1.2012e-02,  2.6025e-03, -1.1576e-02]],\n",
      "\n",
      "         [[-5.4747e-03,  5.2843e-03,  1.6423e-02],\n",
      "          [-1.6989e-02, -1.2476e-02, -9.2073e-03],\n",
      "          [-5.3959e-03, -1.9076e-02, -1.2737e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4597e-02, -2.5450e-03,  1.0463e-02],\n",
      "          [-8.4402e-03,  1.7961e-02,  1.7877e-02],\n",
      "          [ 1.0315e-02,  1.9871e-02,  9.0685e-03]],\n",
      "\n",
      "         [[-1.4426e-02, -5.3824e-03, -1.3383e-02],\n",
      "          [-2.2259e-03,  1.3032e-02, -1.2440e-02],\n",
      "          [ 7.5093e-04,  1.5760e-02,  1.8231e-02]],\n",
      "\n",
      "         [[-2.0064e-02, -2.2496e-03,  9.3042e-03],\n",
      "          [ 1.9314e-02,  1.0397e-02,  2.0654e-03],\n",
      "          [-1.6702e-02, -1.7099e-02,  5.7511e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0512e-02, -1.5558e-02, -1.8176e-02],\n",
      "          [-1.7961e-02,  1.4277e-02, -1.5590e-02],\n",
      "          [-1.3773e-02,  5.2870e-03,  2.0741e-02]],\n",
      "\n",
      "         [[-1.5888e-02, -1.1284e-02,  4.1338e-03],\n",
      "          [ 5.6401e-03,  3.1251e-03,  3.9812e-03],\n",
      "          [ 1.9231e-02, -9.8528e-03, -1.4161e-02]],\n",
      "\n",
      "         [[-1.8348e-02,  1.2181e-02,  1.7247e-02],\n",
      "          [-5.9589e-03,  7.8059e-03, -1.0452e-02],\n",
      "          [ 5.4410e-04, -3.5762e-03, -8.5051e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.5532e-02,  1.2767e-02,  1.6419e-02],\n",
      "          [ 1.6784e-02, -2.6988e-03,  6.3212e-03],\n",
      "          [-1.8956e-02, -5.6166e-03,  1.2920e-02]],\n",
      "\n",
      "         [[ 1.4260e-02, -6.0760e-03,  1.1445e-03],\n",
      "          [-1.2463e-02, -9.3812e-03,  1.8948e-02],\n",
      "          [-1.8722e-02,  1.5304e-02, -1.7195e-02]],\n",
      "\n",
      "         [[-2.0800e-02,  1.4292e-03,  1.1147e-02],\n",
      "          [ 5.5819e-03, -1.8136e-02,  1.5158e-02],\n",
      "          [-7.9440e-03,  1.9121e-02, -1.6952e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0834e-02,  9.5973e-03,  4.4173e-03],\n",
      "          [-1.7066e-02, -2.0184e-02,  4.5408e-03],\n",
      "          [ 1.5217e-02,  1.2478e-03,  1.0538e-02]],\n",
      "\n",
      "         [[-5.4630e-03,  1.1370e-02,  7.2996e-03],\n",
      "          [-1.0688e-02,  1.1976e-02, -1.3868e-02],\n",
      "          [ 1.3124e-02,  8.8693e-03, -1.5764e-02]],\n",
      "\n",
      "         [[-1.2348e-04, -6.6576e-03,  1.3081e-02],\n",
      "          [-3.5075e-03,  1.3945e-02,  1.2760e-02],\n",
      "          [-1.3216e-02,  1.2208e-02,  4.4825e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4526e-02,  1.8835e-02, -7.0631e-03],\n",
      "          [ 1.5772e-02,  4.9617e-03,  1.0850e-02],\n",
      "          [ 1.9405e-02,  1.2143e-02, -8.6841e-03]],\n",
      "\n",
      "         [[ 2.2525e-03, -1.9759e-02, -6.3311e-03],\n",
      "          [-1.8542e-02,  1.2378e-02, -1.8398e-02],\n",
      "          [-1.4947e-02, -1.5970e-02, -8.2444e-03]],\n",
      "\n",
      "         [[-4.0602e-03, -3.4297e-03,  1.7189e-03],\n",
      "          [-1.2739e-02,  1.5353e-02, -1.0439e-03],\n",
      "          [-1.6058e-02, -1.3296e-02, -1.6703e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9344e-03, -1.7147e-02,  1.2169e-02],\n",
      "          [-4.5122e-03,  1.9091e-02, -1.7873e-02],\n",
      "          [ 1.1927e-02, -3.2637e-03, -2.2003e-03]],\n",
      "\n",
      "         [[-1.6078e-02, -8.0848e-03,  5.3284e-03],\n",
      "          [-1.8904e-02,  9.4985e-05,  1.0810e-02],\n",
      "          [-7.8791e-03,  5.2806e-03, -1.6562e-02]],\n",
      "\n",
      "         [[ 1.1146e-02, -2.5076e-03, -5.6570e-03],\n",
      "          [ 1.6191e-02, -2.0109e-02, -9.4952e-03],\n",
      "          [ 4.4946e-03,  2.0305e-02, -1.4289e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7527e-03,  1.7625e-02, -9.1920e-03],\n",
      "          [-1.7457e-02, -8.3388e-03,  7.2225e-03],\n",
      "          [-3.8273e-03, -1.2323e-02,  1.7438e-02]],\n",
      "\n",
      "         [[ 1.0473e-02, -2.7244e-03,  1.9527e-02],\n",
      "          [ 4.5433e-03,  9.5274e-03,  1.7957e-02],\n",
      "          [-1.5783e-02, -7.1853e-03, -1.9673e-03]],\n",
      "\n",
      "         [[ 1.1614e-02,  1.0133e-02, -1.7356e-03],\n",
      "          [ 1.1413e-02,  1.5844e-02, -1.1129e-02],\n",
      "          [ 1.3425e-02, -1.6677e-02, -1.1127e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1545e-02, -8.9006e-03,  1.6141e-02],\n",
      "          [ 1.4489e-02, -1.9733e-02,  1.2560e-03],\n",
      "          [-1.8656e-04,  1.9225e-02,  4.1108e-03]],\n",
      "\n",
      "         [[ 6.3512e-03,  3.6245e-03,  1.7929e-03],\n",
      "          [-1.1001e-02,  7.6035e-03, -1.8856e-02],\n",
      "          [-1.3128e-02,  1.0966e-02,  1.2662e-02]],\n",
      "\n",
      "         [[ 5.7598e-04, -1.2849e-02, -1.2903e-03],\n",
      "          [-9.6698e-03,  9.5991e-03, -5.8563e-03],\n",
      "          [-6.4794e-03,  1.9793e-02,  2.0762e-02]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.6139e-02, -4.3777e-04, -1.0442e-02, -2.0108e-02, -1.9289e-02,\n",
      "         1.3102e-02,  1.0960e-02, -6.4643e-03,  1.0073e-03, -1.1201e-03,\n",
      "        -7.9661e-03,  1.8548e-02, -1.7459e-02,  1.8563e-02, -1.2364e-03,\n",
      "         1.2805e-02,  1.3538e-02,  6.2403e-04,  1.7731e-02, -3.8498e-03,\n",
      "        -4.9197e-03, -8.6228e-03,  1.4691e-02,  1.2607e-02,  1.6802e-02,\n",
      "        -1.6848e-02,  1.5461e-02,  1.4058e-02, -1.3458e-02, -4.9861e-03,\n",
      "        -1.1004e-02,  2.1703e-03,  9.9969e-03, -1.7908e-02,  5.5754e-04,\n",
      "        -2.2380e-03,  4.8803e-03,  1.9084e-02,  5.9702e-03, -1.4638e-02,\n",
      "         1.9634e-02,  1.6067e-02, -2.6054e-03,  1.2252e-02,  1.0299e-02,\n",
      "         1.5727e-02, -1.9490e-02,  1.9713e-02, -1.6173e-02, -8.7104e-03,\n",
      "         7.5165e-03,  1.8789e-02,  7.8465e-03,  3.5205e-03,  4.7890e-03,\n",
      "         3.0590e-03, -6.4736e-04, -1.0548e-02, -1.8133e-02,  1.6661e-02,\n",
      "         6.5734e-03, -1.5643e-03,  1.8304e-02, -1.2932e-02,  1.7475e-02,\n",
      "         1.0392e-02,  1.1834e-02, -9.7637e-03, -4.7707e-03, -3.0491e-03,\n",
      "         1.3511e-02,  1.5956e-02,  1.0908e-02,  1.0242e-02,  1.2933e-03,\n",
      "        -9.9347e-03, -5.2494e-03, -2.0521e-02, -1.0001e-02, -1.6998e-02,\n",
      "        -7.0952e-03,  1.5226e-02, -1.6825e-02,  1.2871e-02, -2.0730e-02,\n",
      "         1.8159e-02,  1.3220e-02, -1.9180e-02, -3.9303e-03,  1.6296e-02,\n",
      "         1.0227e-02, -9.0274e-03,  1.2760e-02, -1.9903e-02,  4.2131e-03,\n",
      "        -1.2297e-02,  1.6487e-02, -3.9039e-03, -7.8798e-03, -6.3969e-03,\n",
      "        -1.7571e-02, -6.3825e-03,  1.1510e-02,  1.6175e-02, -1.6349e-02,\n",
      "        -1.6015e-02,  1.0589e-02,  1.1349e-02,  1.2317e-02, -1.2063e-02,\n",
      "         1.3433e-02,  2.0085e-02,  1.6456e-02, -1.8187e-02, -1.7073e-02,\n",
      "        -1.9556e-02,  1.9401e-02,  5.5116e-03,  2.0442e-02, -1.8583e-02,\n",
      "        -7.4356e-03, -1.1406e-02,  5.8873e-03,  4.1299e-03,  2.2387e-03,\n",
      "        -4.2952e-04, -2.5245e-03, -1.9336e-02,  7.8947e-03,  7.9723e-04,\n",
      "        -1.8128e-02, -5.6329e-03, -2.0803e-03,  7.0623e-03, -1.7508e-02,\n",
      "        -2.1928e-03,  1.1232e-02, -1.5648e-02,  6.3491e-03,  1.8191e-02,\n",
      "         2.0799e-02, -2.4108e-04,  1.8443e-02, -1.6974e-02,  1.8513e-02,\n",
      "         1.9405e-02, -6.5246e-03,  1.3195e-02,  1.7223e-02,  2.4412e-03,\n",
      "        -1.2310e-02,  1.1657e-02,  3.2746e-03,  1.6119e-02,  1.4985e-02,\n",
      "         5.1623e-03,  1.3529e-02, -7.2130e-03,  2.0242e-02, -1.7548e-02,\n",
      "        -6.9267e-03,  2.8701e-03,  7.9123e-03,  9.3079e-03,  9.1226e-03,\n",
      "         4.2330e-03, -3.9812e-03, -3.9922e-03, -8.2843e-05, -1.6816e-02,\n",
      "         2.7205e-03, -9.1398e-04, -1.5068e-02, -9.6449e-03, -1.4272e-02,\n",
      "        -1.7372e-02,  4.7473e-03, -1.9384e-02,  3.9438e-06, -1.2717e-02,\n",
      "         2.8587e-03, -1.8249e-02,  9.5715e-03,  7.9604e-03, -1.5164e-02,\n",
      "        -6.4136e-04, -1.8177e-02, -1.7587e-02,  7.3606e-03,  6.5340e-03,\n",
      "        -8.3407e-03,  5.9421e-03,  1.8131e-02,  1.8151e-02, -1.2967e-02,\n",
      "         1.4654e-02,  1.9504e-02,  4.3425e-03,  1.6046e-02, -3.5334e-03,\n",
      "         1.8759e-02, -9.1299e-03, -1.0621e-02, -1.6389e-02, -1.8437e-02,\n",
      "        -1.5864e-02, -1.1620e-02, -4.2284e-03,  5.1994e-03, -9.3914e-03,\n",
      "         4.4804e-03,  6.3611e-03, -1.1288e-02,  1.9487e-02, -2.0067e-03,\n",
      "        -1.8287e-03, -7.0242e-03,  3.8869e-03,  1.2505e-02,  5.2649e-03,\n",
      "        -1.2668e-02,  1.2500e-02, -3.8689e-04, -1.0982e-02,  1.1377e-02,\n",
      "         2.0171e-02,  1.3800e-02, -8.8566e-03, -1.4491e-02, -1.8134e-02,\n",
      "        -5.0360e-03,  2.9615e-03,  3.0773e-03,  2.1165e-03,  1.9113e-02,\n",
      "        -5.4587e-03, -1.2579e-02,  1.8542e-02,  1.2047e-02,  1.6980e-02,\n",
      "         2.0429e-03, -3.6140e-03, -6.1692e-03, -1.3743e-02, -7.3748e-03,\n",
      "         1.5174e-02,  1.0101e-02, -2.0045e-02,  3.7843e-03, -1.4189e-02,\n",
      "        -1.8444e-02, -2.9736e-03,  9.8735e-03, -1.2000e-03,  1.9746e-02,\n",
      "         7.1015e-04], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0067, -0.0005,  0.0137],\n",
      "          [ 0.0127,  0.0064, -0.0007],\n",
      "          [ 0.0024,  0.0127, -0.0087]],\n",
      "\n",
      "         [[-0.0117, -0.0056, -0.0070],\n",
      "          [-0.0036, -0.0080, -0.0117],\n",
      "          [ 0.0128,  0.0030,  0.0185]],\n",
      "\n",
      "         [[-0.0009, -0.0016,  0.0122],\n",
      "          [ 0.0114, -0.0128,  0.0085],\n",
      "          [ 0.0142, -0.0016,  0.0121]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0011,  0.0068,  0.0052],\n",
      "          [ 0.0061,  0.0114, -0.0047],\n",
      "          [-0.0157,  0.0072, -0.0126]],\n",
      "\n",
      "         [[-0.0140, -0.0086, -0.0050],\n",
      "          [-0.0143,  0.0108, -0.0103],\n",
      "          [-0.0031,  0.0028, -0.0089]],\n",
      "\n",
      "         [[ 0.0046, -0.0074, -0.0124],\n",
      "          [-0.0068,  0.0074,  0.0206],\n",
      "          [ 0.0057, -0.0180, -0.0006]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0081, -0.0085,  0.0076],\n",
      "          [ 0.0095,  0.0042, -0.0030],\n",
      "          [-0.0192,  0.0032, -0.0050]],\n",
      "\n",
      "         [[-0.0202,  0.0107,  0.0012],\n",
      "          [ 0.0059, -0.0092,  0.0154],\n",
      "          [ 0.0172, -0.0038, -0.0118]],\n",
      "\n",
      "         [[ 0.0054, -0.0073, -0.0028],\n",
      "          [ 0.0191,  0.0138,  0.0153],\n",
      "          [ 0.0092,  0.0043, -0.0158]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0190,  0.0052, -0.0055],\n",
      "          [ 0.0030,  0.0127, -0.0088],\n",
      "          [-0.0075, -0.0031,  0.0002]],\n",
      "\n",
      "         [[ 0.0180,  0.0035,  0.0170],\n",
      "          [ 0.0064,  0.0002, -0.0035],\n",
      "          [-0.0114,  0.0094, -0.0160]],\n",
      "\n",
      "         [[ 0.0034,  0.0035, -0.0187],\n",
      "          [-0.0179,  0.0088,  0.0089],\n",
      "          [-0.0198,  0.0160,  0.0022]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0084, -0.0037, -0.0099],\n",
      "          [-0.0063, -0.0182,  0.0121],\n",
      "          [ 0.0025, -0.0008, -0.0044]],\n",
      "\n",
      "         [[ 0.0204, -0.0074,  0.0082],\n",
      "          [-0.0102,  0.0206, -0.0160],\n",
      "          [ 0.0094, -0.0161,  0.0163]],\n",
      "\n",
      "         [[ 0.0198, -0.0164, -0.0207],\n",
      "          [ 0.0080,  0.0089, -0.0126],\n",
      "          [ 0.0187,  0.0065,  0.0003]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0087, -0.0096, -0.0150],\n",
      "          [-0.0035, -0.0143,  0.0198],\n",
      "          [-0.0117, -0.0091, -0.0100]],\n",
      "\n",
      "         [[ 0.0093,  0.0075, -0.0008],\n",
      "          [-0.0073,  0.0149, -0.0028],\n",
      "          [ 0.0194, -0.0107, -0.0030]],\n",
      "\n",
      "         [[ 0.0176,  0.0050,  0.0199],\n",
      "          [-0.0055, -0.0123, -0.0198],\n",
      "          [-0.0066, -0.0004,  0.0150]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0092, -0.0052,  0.0170],\n",
      "          [-0.0193, -0.0186,  0.0193],\n",
      "          [ 0.0150,  0.0027,  0.0198]],\n",
      "\n",
      "         [[ 0.0149, -0.0143, -0.0008],\n",
      "          [ 0.0134, -0.0038,  0.0120],\n",
      "          [ 0.0073, -0.0095,  0.0203]],\n",
      "\n",
      "         [[-0.0095,  0.0051,  0.0119],\n",
      "          [ 0.0196,  0.0100,  0.0083],\n",
      "          [-0.0136, -0.0030,  0.0043]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0075,  0.0206, -0.0074],\n",
      "          [-0.0055,  0.0074, -0.0025],\n",
      "          [ 0.0155,  0.0200,  0.0107]],\n",
      "\n",
      "         [[ 0.0163, -0.0006, -0.0031],\n",
      "          [ 0.0164, -0.0164, -0.0120],\n",
      "          [ 0.0083, -0.0074, -0.0099]],\n",
      "\n",
      "         [[ 0.0201, -0.0018, -0.0100],\n",
      "          [-0.0095, -0.0162, -0.0004],\n",
      "          [-0.0205, -0.0192, -0.0041]]],\n",
      "\n",
      "\n",
      "        [[[-0.0069,  0.0003,  0.0003],\n",
      "          [ 0.0008, -0.0095, -0.0108],\n",
      "          [ 0.0081, -0.0159,  0.0075]],\n",
      "\n",
      "         [[-0.0152, -0.0091,  0.0065],\n",
      "          [-0.0121, -0.0095,  0.0187],\n",
      "          [-0.0027,  0.0071, -0.0002]],\n",
      "\n",
      "         [[ 0.0173,  0.0066,  0.0057],\n",
      "          [ 0.0174,  0.0018, -0.0089],\n",
      "          [-0.0078, -0.0200,  0.0030]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0016, -0.0110, -0.0025],\n",
      "          [-0.0012,  0.0016,  0.0069],\n",
      "          [ 0.0069,  0.0155,  0.0020]],\n",
      "\n",
      "         [[ 0.0185, -0.0139,  0.0103],\n",
      "          [-0.0117,  0.0165,  0.0060],\n",
      "          [ 0.0169, -0.0158,  0.0138]],\n",
      "\n",
      "         [[ 0.0192, -0.0179, -0.0008],\n",
      "          [ 0.0082, -0.0013, -0.0119],\n",
      "          [ 0.0008,  0.0199, -0.0104]]],\n",
      "\n",
      "\n",
      "        [[[-0.0171, -0.0204, -0.0063],\n",
      "          [ 0.0095, -0.0159,  0.0099],\n",
      "          [ 0.0101,  0.0013,  0.0027]],\n",
      "\n",
      "         [[-0.0166, -0.0053,  0.0065],\n",
      "          [-0.0149, -0.0075,  0.0025],\n",
      "          [-0.0039,  0.0084,  0.0115]],\n",
      "\n",
      "         [[ 0.0080,  0.0188, -0.0111],\n",
      "          [-0.0098, -0.0101, -0.0032],\n",
      "          [-0.0149,  0.0050, -0.0065]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0130, -0.0042,  0.0167],\n",
      "          [-0.0023,  0.0014,  0.0115],\n",
      "          [-0.0008,  0.0181,  0.0079]],\n",
      "\n",
      "         [[ 0.0060,  0.0163,  0.0061],\n",
      "          [ 0.0125, -0.0065,  0.0051],\n",
      "          [-0.0177, -0.0032,  0.0060]],\n",
      "\n",
      "         [[ 0.0199,  0.0057, -0.0056],\n",
      "          [-0.0079, -0.0048, -0.0005],\n",
      "          [ 0.0200, -0.0164, -0.0090]]]], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.6869e-02, -2.4647e-03, -1.4330e-02, -1.3599e-02, -1.0113e-02,\n",
      "        -3.4739e-03, -1.4149e-02,  1.3390e-02, -2.8106e-03, -1.1610e-02,\n",
      "        -7.6595e-03, -2.0628e-03,  6.9788e-03,  2.5246e-03, -1.6863e-02,\n",
      "         1.8079e-02, -1.4711e-02,  2.8315e-03,  1.4617e-02,  1.3588e-02,\n",
      "        -2.5135e-03,  1.3785e-02,  1.1699e-02,  8.2488e-03,  8.2006e-03,\n",
      "        -5.3958e-04,  6.3491e-03, -1.4263e-02,  1.3008e-03,  9.8335e-04,\n",
      "         1.1858e-02, -3.9209e-03, -1.4448e-02, -1.8059e-02, -3.1658e-03,\n",
      "        -1.5327e-02,  4.1339e-03,  1.6239e-02,  1.4542e-03,  3.4896e-03,\n",
      "         1.7108e-02, -7.4252e-03, -1.5932e-02,  1.7137e-02,  9.3456e-03,\n",
      "         1.6765e-02, -1.1114e-02,  2.0189e-02,  4.8353e-03, -1.4740e-02,\n",
      "        -8.3269e-03, -2.0086e-02,  7.1165e-03,  1.0465e-02,  1.6538e-02,\n",
      "         1.2723e-02,  8.0367e-03,  1.9443e-02, -7.0093e-03,  3.5863e-03,\n",
      "        -9.0710e-03, -6.5713e-04, -2.2863e-03, -8.9358e-04,  1.6528e-02,\n",
      "         1.9022e-02, -2.6337e-03,  6.2018e-03,  1.0820e-03, -1.0191e-03,\n",
      "        -1.1682e-02, -7.1510e-03,  2.0872e-04, -1.3191e-02, -1.9937e-02,\n",
      "        -1.0923e-02,  1.9243e-02, -5.7889e-05,  1.7471e-02,  1.9003e-02,\n",
      "        -1.6823e-02,  1.1632e-02, -8.7762e-03, -1.7452e-02, -8.9555e-03,\n",
      "         1.3817e-02,  1.2530e-02, -7.8175e-03,  3.4793e-03, -4.6395e-03,\n",
      "         1.5560e-02, -1.0783e-02, -1.8478e-02,  1.5556e-02,  2.1334e-03,\n",
      "         2.5124e-03,  4.7157e-03, -2.5968e-03, -1.1922e-03,  5.7659e-03,\n",
      "        -1.3156e-02, -1.3160e-02,  5.3198e-03,  1.7552e-02,  7.3147e-03,\n",
      "        -2.3842e-03, -1.5511e-02,  4.8130e-03, -5.3488e-03, -1.6777e-02,\n",
      "         1.5285e-02,  1.1566e-02, -9.8635e-03, -1.3315e-02, -4.5232e-03,\n",
      "        -7.7820e-03,  1.1666e-02, -4.2859e-03,  1.4783e-03,  4.5076e-03,\n",
      "         9.0896e-03,  1.9000e-02, -1.1076e-02,  8.8568e-03,  1.4274e-02,\n",
      "        -1.4947e-02,  1.7868e-02, -1.8522e-02, -7.2928e-03,  2.8203e-03,\n",
      "         1.7457e-02,  1.8280e-02,  3.8467e-03,  2.0182e-02,  2.1280e-03,\n",
      "        -1.5597e-02,  1.3893e-02, -3.8588e-03,  1.8265e-02, -1.4895e-02,\n",
      "         1.1826e-02, -9.7273e-03,  1.0195e-02,  1.5720e-02,  9.4195e-04,\n",
      "        -2.0437e-03, -4.0013e-03, -1.3084e-02, -1.6429e-02,  1.8018e-02,\n",
      "        -1.3727e-03,  4.1572e-03, -4.8168e-03, -2.0533e-02,  5.6956e-04,\n",
      "        -2.0208e-02,  5.6131e-03, -1.2168e-02,  1.6425e-02, -1.5175e-02,\n",
      "         1.7653e-02, -3.6753e-03,  1.7315e-02, -1.6245e-02,  3.1793e-03,\n",
      "         1.5039e-02,  1.3522e-02,  1.1615e-02, -8.6936e-03,  1.7787e-02,\n",
      "         1.2119e-02, -3.3157e-03, -1.4479e-02, -2.8226e-03, -1.5761e-03,\n",
      "         1.5962e-02, -1.0365e-02, -9.8548e-03,  2.0959e-03,  5.4791e-03,\n",
      "        -1.0061e-02,  5.6055e-03, -1.4669e-02,  1.3741e-02,  1.1514e-02,\n",
      "         2.3098e-03, -6.9989e-03,  1.6076e-02, -5.1747e-03, -2.8811e-03,\n",
      "        -9.3642e-03,  4.0844e-04, -1.1817e-02, -1.0377e-02,  1.2898e-02,\n",
      "        -3.9764e-03, -1.4448e-02,  2.7304e-03,  1.3696e-02, -1.4372e-02,\n",
      "        -6.9814e-04, -2.0585e-02, -1.2857e-02, -7.0156e-03,  1.8535e-03,\n",
      "         1.8076e-02,  3.2145e-03, -6.8265e-03, -7.7672e-03, -1.4071e-03,\n",
      "        -9.4040e-03, -1.9558e-02,  1.1732e-02,  1.0257e-03, -1.3763e-02,\n",
      "         6.1949e-03,  1.4552e-02, -6.0081e-03,  1.3426e-02,  5.3750e-03,\n",
      "        -1.3329e-02, -1.6189e-02, -8.7731e-03, -9.0900e-03, -1.9031e-02,\n",
      "        -1.0474e-02,  1.6386e-02,  9.9714e-03,  1.1905e-02,  1.6807e-02,\n",
      "        -1.5685e-03, -7.1876e-03,  1.1102e-02, -1.0468e-02,  1.9117e-02,\n",
      "        -1.4963e-02, -1.8968e-02, -5.8047e-03,  1.4638e-02, -1.4299e-02,\n",
      "         8.4215e-03,  3.9718e-03, -1.9607e-02,  1.3092e-02,  1.9923e-02,\n",
      "        -1.6887e-02, -7.8511e-03, -1.7214e-02,  1.1769e-02,  7.4134e-03,\n",
      "         6.7332e-03, -3.3932e-03, -3.0046e-03, -6.0217e-03,  1.9506e-02,\n",
      "         1.4861e-04], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 6.2126e-04, -8.8443e-04,  1.5072e-03,  ...,  2.1092e-03,\n",
      "          2.0855e-03,  9.4064e-04],\n",
      "        [ 2.1148e-03,  1.2121e-03, -1.5217e-03,  ...,  1.0878e-03,\n",
      "         -1.9428e-04, -1.3152e-04],\n",
      "        [ 1.5903e-03,  1.2364e-03, -4.0569e-04,  ...,  8.5622e-05,\n",
      "         -5.4794e-04,  1.2077e-03],\n",
      "        ...,\n",
      "        [-1.0193e-03,  2.0084e-03,  4.8505e-04,  ...,  1.1625e-03,\n",
      "         -4.1357e-04,  1.9432e-03],\n",
      "        [ 3.1472e-04, -7.0098e-04, -2.0812e-03,  ...,  1.5943e-03,\n",
      "          1.4137e-03, -8.1020e-04],\n",
      "        [ 2.5163e-04,  5.6132e-04,  1.4068e-03,  ..., -2.9151e-04,\n",
      "          5.8268e-04,  1.2021e-03]], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-9.2202e-04, -3.4993e-04, -1.7976e-03,  ...,  1.6556e-03,\n",
      "         7.9414e-04, -4.9687e-05], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0120,  0.0150,  0.0074,  ...,  0.0030, -0.0003,  0.0002],\n",
      "        [-0.0074,  0.0110,  0.0133,  ...,  0.0027,  0.0028, -0.0027],\n",
      "        [ 0.0020, -0.0063, -0.0108,  ...,  0.0090, -0.0121,  0.0026],\n",
      "        ...,\n",
      "        [ 0.0070,  0.0016,  0.0024,  ..., -0.0083, -0.0007, -0.0094],\n",
      "        [ 0.0041,  0.0106,  0.0132,  ...,  0.0058, -0.0064,  0.0018],\n",
      "        [ 0.0117, -0.0127, -0.0103,  ...,  0.0080, -0.0002, -0.0009]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0088,  0.0088, -0.0144,  ..., -0.0078, -0.0088, -0.0123],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0065, -0.0137,  0.0075,  ...,  0.0139, -0.0105, -0.0002],\n",
      "        [ 0.0060,  0.0015,  0.0038,  ..., -0.0057,  0.0145, -0.0106],\n",
      "        [-0.0040, -0.0081, -0.0096,  ...,  0.0010,  0.0102, -0.0100],\n",
      "        ...,\n",
      "        [ 0.0075, -0.0026,  0.0063,  ..., -0.0117, -0.0072,  0.0015],\n",
      "        [ 0.0011,  0.0132, -0.0066,  ..., -0.0142,  0.0141, -0.0023],\n",
      "        [-0.0155,  0.0052, -0.0104,  ..., -0.0006, -0.0031, -0.0138]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0046, -0.0092, -0.0141,  0.0041,  0.0022, -0.0017, -0.0109,  0.0104,\n",
      "         0.0055,  0.0055, -0.0148], device='cuda:1', requires_grad=True)\n",
      "Before Epochs of training - Current allocated memory (GB): 3.1316871643066406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Optimizer present:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:03<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68613/2512109927.py\", line 109, in _go\n",
      "    model, save_dict=  train_val_batch(model, train,val, loop_run_name,save_dict, lr, loss_fn,epochs, config['batch_size'], optimizer, scheduler_value, device)\n",
      "  File \"/its/home/nn268/antvis/antvis/optics/Batchcode/.././loop_fns.py\", line 312, in train_val_batch\n",
      "    t_loss, train_prediction, t_label_list, t_correct, model, optimizer = loop_batch(model, train, loss_fn, batch_size,sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =optimizer, scheduler= scheduler_value, train =True) #, scheduler =scheduler\n",
      "  File \"/its/home/nn268/antvis/antvis/optics/Batchcode/.././loop_fns.py\", line 235, in loop_batch\n",
      "    if y_batch[i].argmax() == prediction[i].argmax():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 6.0%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epochs</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epochs</td><td>30</td></tr><tr><td>gitHash</td><td>ef6b54a4f1436e60d215...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-feather-10</strong> at: <a href='https://wandb.ai/antvis/vgg16%2030E.%20NoSched.%20adam_run/runs/k44n76ez' target=\"_blank\">https://wandb.ai/antvis/vgg16%2030E.%20NoSched.%20adam_run/runs/k44n76ez</a><br/> View job at <a href='https://wandb.ai/antvis/vgg16%2030E.%20NoSched.%20adam_run/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjUwMjk2ODA0NQ==/version_details/v2' target=\"_blank\">https://wandb.ai/antvis/vgg16%2030E.%20NoSched.%20adam_run/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjUwMjk2ODA0NQ==/version_details/v2</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241212_162747-k44n76ez/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m_go\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 109\u001b[0m, in \u001b[0;36m_go\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#print(\"After loading Optimizer - Current allocated memory (GB):\", torch.cuda.memory_allocated(device=device) / 1024 ** 3)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m#wandb.watch(model, loss_fn, log='all', log_freq=10, idx = model_index)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m#print(\"Pre Training - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m loop_run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimmy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 109\u001b[0m model, save_dict\u001b[38;5;241m=\u001b[39m  \u001b[43mtrain_val_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_run_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m#print(\"Post Training - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m test_acc,test_predict_list, y_test \u001b[38;5;241m=\u001b[39m test_loop_batch(model,test, loss_fn, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], device) \u001b[38;5;66;03m#model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\u001b[39;00m\n",
      "File \u001b[0;32m~/antvis/antvis/optics/Batchcode/.././loop_fns.py:312\u001b[0m, in \u001b[0;36mtrain_val_batch\u001b[0;34m(model, train, val, loop_run_name, save_dict, lr, loss_fn, epochs, batch_size, optimizer, scheduler_value, device)\u001b[0m\n\u001b[1;32m    309\u001b[0m random_value \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandrange(\u001b[38;5;241m0\u001b[39m,batch_size)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 312\u001b[0m t_loss, train_prediction, t_label_list, t_correct, model, optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mloop_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrandom_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloop_run_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, scheduler =scheduler\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining..  2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m#!nvidia-smi\u001b[39;00m\n",
      "File \u001b[0;32m~/antvis/antvis/optics/Batchcode/.././loop_fns.py:235\u001b[0m, in \u001b[0;36mloop_batch\u001b[0;34m(model, data, loss_fn, batch_size, sample, random_value, epoch, loop_run_name, save_dict, device, optimizer, scheduler, train)\u001b[0m\n\u001b[1;32m    232\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_batch)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_batch[i]\u001b[38;5;241m.\u001b[39margmax() \u001b[38;5;241m==\u001b[39m prediction[i]\u001b[38;5;241m.\u001b[39margmax():\n\u001b[1;32m    236\u001b[0m         num_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    239\u001b[0m [predict_list\u001b[38;5;241m.\u001b[39mappend(pred\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()) \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m prediction]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_go(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d964b31e-4bae-4f65-bc46-ee1334a8f239",
   "metadata": {},
   "source": [
    "# 12.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.04 GiB is free\n",
    "23.65-8.04\n",
    "/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/schedulerRuns/4c3l/SGD/modelCheckPoints\n",
    "/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/schedulerRuns/4c/SGD/modelCheckPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59daceaa-fa47-4c76-90d6-f23550f85694",
   "metadata": {},
   "source": [
    "\n",
    "pred torch.Size([11])\n",
    "\n",
    "lab  torch.Size([5, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0ade6-cd6d-46db-ac95-6b368cbea443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only things that have been added are more dictionary items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e6c0bb-8e01-4c7a-ac94-0f899faaff7a",
   "metadata": {},
   "source": [
    "cuda memory error\n",
    "\n",
    "currently trying to reduce number of vars and delete any large ones after use (del loss after loss has been added to current loss or loss list)\n",
    "\n",
    "14.39  261124 - reducing batch size to 32\n",
    "\n",
    "worked up to 160E.\n",
    "will train to 150, then when all done, read in the model files and continue to 300.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154693be-5f86-4945-95b3-dde95a4bc63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device=device, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023a4c1-bd26-406b-b140-5e9a4dd0add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf798dcf-4b05-4efd-820a-5d96411718ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/schedulerRuns/vgg16/adam/NoSched//"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
