{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4fd19-5a09-4232-bdc4-42bbef0b6802",
   "metadata": {},
   "source": [
    "last updated 03/12/24\n",
    "\n",
    "This notebook is to check on why current vgg16 runs aren't learning.\n",
    "this file is importing functions. file was originally a 4c file that did learn as expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6dbd95-2129-42b5-b70b-ee9f057b24c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg16\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch.Utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import collections\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "#import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "\n",
    "from functions import ImageProcessor,  IDSWDataSetLoader2\n",
    "from fns4wandb import set_lossfn\n",
    "from plotting import learning_curve, accuracy_curve, plot_confusion\n",
    "from modelManagment import get_lin_lay, choose_model2\n",
    "import copy\n",
    "\n",
    "#import torch.Utils.data.DataLoader as DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c1e605-9a3b-48dc-a38e-8a955bd3c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "model_type = '4c3l'\n",
    "optimmy = 'Adam'\n",
    "Var_WB_sched = \"NoSched\"\n",
    "\n",
    "\n",
    "_save_location = f'/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/{model_type}/60E/' \n",
    "checkpoint_saveloc = f\"/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/schedulerRuns/{model_type}/{optimmy}/modelCheckPoints/\"\n",
    "# '/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/4c/60E//Learning Curve 4c3l_[113, 36]_2025-01-15_Adam_60E_NoSched_run_[113, 36]_0.0001_0_8_MSE.png'\n",
    "data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "\n",
    "gitHASH = 'ac9b2d2910b48bbc4d8cb511b231b637b7edff2a'\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "start_epoch = 0\n",
    "epoch_val = 60  # 150\n",
    "\n",
    "loadPreTrainedModel = False\n",
    "\n",
    "sim_type = \"run\" #(Test or run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1481ccd-4d87-4c05-84d5-77e29ee981b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.login()\n",
    "d = date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87383b",
   "metadata": {},
   "source": [
    "452 144 5/452 *100 = 1%\n",
    "226 72 5/226 *100 = 2%\n",
    "113 36 5/113 *100 = 4% -- 2/113 *100= 1.7% ~ 2%\n",
    "57 18 (56.5,) 5/57 *100 = 8% -- 2/57 *100 = 3.5% ~ 4%. 1/57 = 1.75%\n",
    "29 9 (28.5,) 5/29 *100 = 17% -- 2/29 *100 = 6.89 ~ 7% 1/28 = 3.57 ~ 4%\n",
    "15 5 (14.5, 4.5)\n",
    "8 3 (7.5,2.5)\n",
    "4, 2 (, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ddbb49-828b-4de8-a31c-2a576cd736f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries                                                                                  * * * *   SETTINGS   * * * *\n",
    "\n",
    "date = date.today()\n",
    "\n",
    "model_card_vgg = {'name': 'vgg', 'model': 'vgg16',\n",
    "                  'f_lin_lay':[200704,#200704,     #129024,#4096,  # (1x229376 and 25088x4096)  1x229376 and 25088x4096) 1x229376 and 25088x4096)\n",
    "                             200704,      #(16x64512 and 129024x4096)    (16x200704 and 64512x4096)\n",
    "                             14336,\n",
    "                             3584,\n",
    "                             768,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                            ],\n",
    "                 'idx': 0,\n",
    "                 'dropout':0.2}\n",
    "\n",
    "\n",
    "model_card_7c3l = {'name': '7c3l', 'model': '7c3l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[248832,    # 452 144 # p5\n",
    "                            59904,      # 226 72 # p5\n",
    "                            11264,      # 113 36 # p2\n",
    "                            1536,       # 57 18 # p1\n",
    "                            172032,           # 29 9\n",
    "                            172032,          # 15 5\n",
    "                            172032,         # 8 3\n",
    "                              ], \n",
    "                   'idx': 1,\n",
    "                  'dropout':0.2}\n",
    "\n",
    "\n",
    "\n",
    "model_card_4c3l = {'name': '4c3l', 'model': '4c3l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[539904,# 1055232,#539904,    # 452 144 # p5  (64x539904 and 1055232x100)\n",
    "                             141056, #141056,    # 226 72 # p5   64x141056 and 267264x100)\n",
    "                             35840,     # 113 36 # p2   (64x35840 and 304640x100)\n",
    "                             9984,      # 57 18 # p1 \n",
    "                             2304,      # 29 9\n",
    "                             512,       # 15 5\n",
    "                             256],      # 8 3\n",
    "                  'idx': 2,\n",
    "                  'dropout':0.2}      \n",
    "\n",
    "model_card_3c2l = {'name': '3c2l', 'model': '3c2l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[1069888,    # 452 144 # p5\n",
    "                             274688,     #226 72 # p5\n",
    "                             68096,      # 113 36 # p2\n",
    "                             17280,      # 57 18 # p1\n",
    "                             3840,       # 29 9\n",
    "                             960,        # 15 5\n",
    "                             256],\n",
    "                  'idx': 3,\n",
    "                  'dropout':0.2}       # 8 3\n",
    "\n",
    "model_card_2c2l = {'name': '2c2l', 'model': '2c2l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[1055232 , #1032192,# 16883712,#33767424,    # 452 144 # p5 # (1x33767424 and 1055232x100) (1x5276160 and 15828480x100) 1x33767424 and 5276160x100)\n",
    "                             267264,     #226 72 # p5                   (1x1032192 and 64512x100)\n",
    "                             64512,#   1032192,#64512,      # 113 36 # p2    ### (16x1055232 and 1032192x100) ###  16x1055232 and 1032192x100)\n",
    "                             15552,      # 57 18 # p1\n",
    "                             3072,       # 29 9\n",
    "                             640,        # 15 5\n",
    "                             128],\n",
    "                  'idx': 4,\n",
    "                  'dropout':0.1}       # 8 3\n",
    "\n",
    "resolution_card_452144 = {'resolution':[452,144], 'padding':5, 'index':0}\n",
    "resolution_card_22672 = {'resolution':[226,72], 'padding':5, 'index':1}\n",
    "resolution_card_11336 = {'resolution':[113,36], 'padding':2, 'index':2}\n",
    "resolution_card_5715 = {'resolution':[57,18], 'padding':1, 'index':3}\n",
    "\n",
    "resolution_card_299 = {'resolution':[29,9], 'padding':0, 'index':4} # \n",
    "resolution_card_155 = {'resolution':[15,5], 'padding':0, 'index':5}\n",
    "resolution_card_83 = {'resolution':[8,3], 'padding':0, 'index':6}\n",
    "\n",
    "\n",
    "\n",
    "resolution_cards = [resolution_card_452144,resolution_card_22672, resolution_card_299,resolution_card_155,resolution_card_83]#[resolution_card_11336, resolution_card_5715,\n",
    "#resolution_card_299, resolution_card_155, resolution_card_83]#]#resolution_card_452144, \n",
    "#resolution_cards = [resolution_card_11336]\n",
    "\n",
    "#learning_rate_cards = [5e-5, 6e-5, 8e-5]\n",
    "#learning_rate_cards = [8.21592E-05, 6.62E-05, 6.01E-05, 5.97E-05]\n",
    "learning_rate_cards=  [1e-4] #[0.1,0.01, 1e-3,1e-4, 1e-5]#, 6e-5, 7e-5, 8e-5]\n",
    "#wd_cards = [4e-5, 5e-5, 3.00E-05, 2.00E-05]\n",
    "wd_cards =[0]\n",
    "scheduler_cards = [0]#, 0.1, 0.2]\n",
    "\n",
    "seeds = [8,2,4, 42]#,2,3] # 4, 5,6\n",
    "\n",
    "#model_cards =[model_card_vgg, model_card_7c3l, model_card_4c3l, model_card_3c2l, model_card_2c2l]\n",
    "model_cards =[model_card_4c3l]\n",
    "\n",
    "loss_fn_cards = ['MSE'] #,'CrossEntropy' 'MSE'\n",
    "                        \n",
    "config = dict({'parameters': 'parameters for big loop run'})\n",
    "config.update({'model_cards':model_cards})\n",
    "config.update({'resolution_cards':resolution_cards})\n",
    "config.update({'learning_rate_cards':learning_rate_cards})\n",
    "config.update({'wd_cards':wd_cards})\n",
    "config.update({'scheduler_cards':scheduler_cards})\n",
    "config.update({'seeds':seeds})\n",
    "config.update({'loss_fn_cards': loss_fn_cards})\n",
    "\n",
    "\n",
    "config.update({'batch_size': 64})\n",
    "config.update({'start_epoch': start_epoch})\n",
    "config.update({'epochs': epoch_val}) #60\n",
    "\n",
    "#print(model_card_vgg)\n",
    "#print('')\n",
    "#Pp.pprint(Config) # dictionary of dictionaries of lists and lists of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf5ca7f-b59a-427b-8da3-2848fa6d3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelManagment import get_lin_lay, choose_model\n",
    "from functions import get_data\n",
    "from loop_fns import train_val_batch, test_loop_batch\n",
    "from fileManagment import save2csv, save2json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _go(config=None):\n",
    "\n",
    "\n",
    "    if len(gitHASH) <1:\n",
    "        print(\"YOU FORGET THE GIT HASH\")\n",
    "        return\n",
    "    else:\n",
    "        print('Git Hash registered')\n",
    "        pass\n",
    "        \n",
    "    #with wandb.init(config=config, project=f\"{model_type}. {epoch_val}E. {Var_WB_sched}. {optimmy}_{sim_type}\", notes=f\"{model_type}. {epoch_val}E. {Var_WB_sched}. {optimmy}_{sim_type}\",):\n",
    "    #config = wandb.config\n",
    "    start = time.process_time()\n",
    "        \n",
    "    for model_idx, model_card in enumerate(config['model_cards']):\n",
    "        #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                \n",
    "        model_name = model_card['model']\n",
    "        model_index = model_card['idx']\n",
    "        dropout = model_card['dropout'] \n",
    "        for res_idx, resolution_card in enumerate(config['resolution_cards']):\n",
    "            #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "        \n",
    "            resolution = resolution_card['resolution']\n",
    "            pad = resolution_card['padding']\n",
    "            lin_lay = get_lin_lay(model_card, resolution)\n",
    "            print('lin lay', lin_lay)\n",
    "        \n",
    "            for lr_idx, lr in enumerate(config['learning_rate_cards']):\n",
    "                for wd_idx, wd_card in enumerate(wd_cards):\n",
    "                    for sched_idx, scheduler_value in enumerate(config['scheduler_cards']):\n",
    "                        \n",
    "                        for seed_idx, seed in enumerate(config['seeds']):\n",
    "                            seed = seed\n",
    "                            for lossfn_idx, loss in enumerate(config['loss_fn_cards']):\n",
    "                                \n",
    "                                torch.cuda.empty_cache()\n",
    "                                #print('2')\n",
    "                                #!nvidia-smi\n",
    "\n",
    "                                config['batch_size']\n",
    "\n",
    "                                print('Model: ', str(model_name), f\" idx: {model_idx} / {len(config['model_cards'])}\")\n",
    "                                print('resolution: ', str(resolution), f\" idx: {res_idx} / {len(config['resolution_cards'])}\")\n",
    "                                print('learning rate: ', str(lr), f\" idx: {lr_idx} / {len(config['learning_rate_cards'])}\")\n",
    "                                print('weight decay: ', str(wd_card), f\" idx: {wd_idx} / {len(config['wd_cards'])}\")\n",
    "                                print('scheduler: ', str(scheduler_value), f\" idx: {sched_idx} / {len(config['scheduler_cards'])}\")\n",
    "                                print('seed: ', str(seed), f\" idx: {seed_idx} / {len(config['seeds'])}\")\n",
    "                                print('loss function: ', str(loss), f\" idx: {lossfn_idx} / {len(config['loss_fn_cards'])}\")\n",
    "                                print('Batch size: ', config['batch_size'])\n",
    "                                print('Training epochs: ', config['epochs'])\n",
    "                                run_start_time = time.process_time()\n",
    "                                print('start time: ',run_start_time)\n",
    "\n",
    "                                print(time.process_time() - start)\n",
    "\n",
    "                                epochs = config['epochs'] #40\n",
    "\n",
    "                                IP = ImageProcessor(device)\n",
    "\n",
    "                                #wandb.log({'gitHash':gitHASH})\n",
    "                                #wandb.log({'Epochs': epochs})\n",
    "                                \n",
    "                                save_dict = {'Run' : f\"{model_name}_{resolution}_{date}_{optimmy}_{config['epochs']}E_{Var_WB_sched}_{sim_type}\",\n",
    "                                             'Current_Epoch': config['start_epoch'], # this is where i add the start epoch\n",
    "                                             'start_epoch':config['start_epoch'],\n",
    "                                             'save_location' : _save_location,\n",
    "                                             'checkpoint_save_loc': checkpoint_saveloc,\n",
    "                                             'res': resolution,\n",
    "                                             'scheduler': Var_WB_sched,\n",
    "                                             'model': model_name,\n",
    "                                             'optimiser': optimmy,\n",
    "                                             'seed':seed}\n",
    "                                \n",
    "                                print(\"model name\", model_name, \" flinlay: \", lin_lay, \" dropout:\", dropout)\n",
    "                                model = choose_model2(model_name, lin_lay, dropout).to(device)\n",
    "                                \n",
    "                                # This is where I want to add the new code\n",
    "                                if loadPreTrainedModel:\n",
    "                                    dir_pkl = f\"/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/schedulerRuns/4c/SGD/{Var_WB_sched}/\"\n",
    "                                    pkl_name = f\"{model_type}_{resolution}_2024-11-26_SGD_150E_{Var_WB_sched}_{resolution}_0.001_0_{seed}_CrossEntropy.pkl\"\n",
    "                                    #model_pkl = torch.load(dir_pkl+pkl_name)\n",
    "                                    with open(dir_pkl+pkl_name, 'rb') as f:\n",
    "                                        model_pkl = pickle.load(f)\n",
    "                                    #model_pkl = pickle.load(dir_pkl+pkl_name)\n",
    "                                    model.load_state_dict(model_pkl['model.state_dict'])\n",
    "\n",
    "                                \n",
    "\n",
    "                                #print(\"After model init, Before data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "                                x_train, y_train, x_val, y_val, x_test, y_test = get_data(random_seed=seed, file_path=data_path) #, file_path\n",
    "                                av_lum = IP.new_luminance(x_train)\n",
    "                                #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                                \n",
    "                                train_ds = IDSWDataSetLoader2(x_train, y_train, resolution,pad,av_lum,model_name, device)# av_lum, res,pad,\n",
    "                                train = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "\n",
    "                                \n",
    "                                test_ds = IDSWDataSetLoader2(x_test, y_test, resolution,pad,av_lum,model_name, device)\n",
    "                                test = DataLoader(test_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "                                #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                                val_ds = IDSWDataSetLoader2(x_val, y_val, resolution,pad,av_lum,model_name, device)\n",
    "                                val = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "                                \n",
    "                                print(\"After data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "\n",
    "                                #print('5')\n",
    "                                #!nvidia-smi\n",
    "\n",
    "                                loss_fn = set_lossfn(loss)\n",
    "                                \n",
    "                                # set optimizer\n",
    "                                optimizer = torch.optim.Adam(model.parameters(),lr=lr)# torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)#\n",
    "\n",
    "                                #wandb.watch(model, loss_fn, log='all', log_freq=2, idx = model_index)\n",
    "\n",
    "                                loop_run_name = f\"{save_dict['Run']}_{resolution}_{lr}_{scheduler_value}_{seed}_{loss}\"\n",
    "     \n",
    "                                model, save_dict=  train_val_batch(model, train,val, loop_run_name,save_dict, lr, loss_fn,epochs, config['batch_size'], optimizer, scheduler_value, device)\n",
    "\n",
    "                                test_acc,test_predict_list, y_test = test_loop_batch(model,test, loss_fn, config['batch_size'], device) #model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\n",
    "                                \n",
    "                                #print(test_predict_list)\n",
    "                                print(' \\n train Acc: ', save_dict['t_accuracy_list'][-1])\n",
    "                                print(' \\n val Acc: ', save_dict['v_accuracy_list'][-1])\n",
    "                                print(' \\n test Acc: ', test_acc)\n",
    "                                \n",
    "                                save_dict.update({'test_acc': test_acc})\n",
    "                                save_dict.update({'test_predict': test_predict_list})\n",
    "                                save_dict.update({'test_labels': list(y_test)})\n",
    "                                #save_dict.update({'test_loss':test_loss})\n",
    "\n",
    "                                learning_curve(save_dict['t_loss_list'], save_dict['v_loss_list'], save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                                accuracy_curve(save_dict['t_accuracy_list'], save_dict['v_accuracy_list'],save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                                test_predict_list=test_predict_list#[pred.cpu() for pred in test_predict_list]\n",
    "                                plot_confusion(predictions= test_predict_list, actual= y_test, title = \"Test Confusion matrix\", run_name = loop_run_name,save_location =save_dict['save_location'])\n",
    "                                \n",
    "                                #wandb.log({'test_acc': test_acc})\n",
    "                                #wandb.log({'test_predict': test_predict_list})\n",
    "                                #wandb.log({'test_labels': list(y_test)})\n",
    "                                #saving\n",
    "                                diction = {}\n",
    "                                d = date.today()\n",
    "                                d=str(d)\n",
    "                                diction.update({'Date':d})\n",
    "                                diction.update({'gitHASH':str(gitHASH)})\n",
    "                                diction.update({'model_name': str(model_name)})\n",
    "                                diction.update({'loss_fn': str(loss)})\n",
    "                                diction.update({'lr': str(lr)})\n",
    "                                diction.update({'wd': str(wd_card)})\n",
    "                                diction.update({'scheduler value': str(scheduler_value)})\n",
    "                                diction.update({'seed': str(seed)})\n",
    "                                diction.update({'resolution': str(resolution)})\n",
    "                                diction.update({'pad': int(pad)})\n",
    "                                diction.update({'lin_lay': int(lin_lay)})\n",
    "                                diction.update({'run time': (time.process_time() - run_start_time)})\n",
    "                                diction.update(save_dict)\n",
    "                                \n",
    "                                save_location = save_dict['save_location']\n",
    "                                title = save_dict['Run']\n",
    "                                save2json(diction, loop_run_name, save_location)\n",
    "                                save2csv(diction, title, save_location)\n",
    "    \n",
    "                                diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "    \n",
    "                                with open(f\"{save_location}{loop_run_name}.pkl\", 'wb+') as f:\n",
    "                                    #pickle.dump(diction, f)\n",
    "                                    torch.save(diction, f)\n",
    "                                \n",
    "                                clear_output()\n",
    "                                \n",
    "                                print(f' \\n END {model_name} {resolution} Run Time: ',time.process_time() - run_start_time)\n",
    "                                #!nvidia-smi\n",
    "                                torch.cuda.empty_cache()\n",
    "    print('Final Run time: ',time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b58d7d27-ef9d-43d9-98a8-1f11ff50090d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " END 4c3l [8, 3] Run Time:  69.93893916100205\n",
      "Final Run time:  30000.820467604\n"
     ]
    }
   ],
   "source": [
    "_go(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d964b31e-4bae-4f65-bc46-ee1334a8f239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.61"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.04 GiB is free\n",
    "23.65-8.04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59daceaa-fa47-4c76-90d6-f23550f85694",
   "metadata": {},
   "source": [
    "\n",
    "pred torch.Size([11])\n",
    "\n",
    "lab  torch.Size([5, 11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67bda7-4c6a-451c-9183-440a8fc39f03",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "18/11/24\n",
    "Added in the checkpoints every 25 epochs\n",
    "Checked that optimizer = SGD and not optimizer =optimizer = SGD\n",
    "set total epochs to 150.\n",
    "added in the creation and saving of LC and AC at each checkpoint.\n",
    "so checkpoints have a save of the model state dicts and lc and ac so far.\n",
    "\n",
    "HOWEVER\n",
    "there still does not look to be any learning... lc are flat and do not change over epochs.\n",
    "in the pytroch sgd page, the examples use momentum (0.9)\n",
    "considering running again with  momentum.\n",
    "\n",
    "hmm. no. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
