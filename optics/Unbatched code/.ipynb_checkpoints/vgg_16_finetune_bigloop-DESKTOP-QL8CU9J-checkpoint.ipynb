{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6dbd95-2129-42b5-b70b-ee9f057b24c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49eb7e06-506f-48e6-b28c-8caa7641b11b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-05 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#!pip install datetime\n",
    "from datetime import date\n",
    "d = date.today()\n",
    "print(str(d), type(str(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87383b",
   "metadata": {},
   "source": [
    "452 144               5/452 *100 = 1%\n",
    "226 72                5/226 *100 = 2%\n",
    "113 36                5/113 *100 = 4% -- 2/113 *100= 1.7% ~ 2%\n",
    "57  18   (56.5,)      5/57 *100  = 8% -- 2/57 *100 = 3.5% ~ 4%.   1/57 = 1.75%\n",
    "29   9   (28.5,)      5/29 *100  = 17% -- 2/29 *100 = 6.89 ~ 7%   1/28 = 3.57 ~ 4%\n",
    "15   5   (14.5, 4.5)\n",
    "8    3   (7.5,2.5)\n",
    "4,   2   (, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff54fdb-23a0-4ae3-ba35-72bbeb751035",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"config = dict(\\n    epochs= 4, #30, \\n    learning_rate =1.00E-05,\\n    architecture ='CNN',\\n    optimizer= 'adam',\\n    weight_decay= 4e-5,\\n    ks = (3,5),\\n    loss_fn = 'CrossEntropy',\\n    scheduler=0.2,\\n    f_lin_lay = 4096, #7168 #1024*7 = 7168 4096\\n    random_seed = 1,\\n)\\n\\nsave_dict = {'Run' :'IDSW_VGG16_fine_280224_TEST',\\n            'Current_Epoch': 0,\\n            'save_location' : r'C:/Users/nn268/OneDrive - University of Sussex/Sussex/phd/antvis_exp1/saves/'}\\n\\ncol_dict =dict(\\n    pad = 5,\\n    colour = 'colour',\\n    size = [226,72]\\n)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionaries\n",
    "\n",
    "\n",
    "\"\"\"config = dict(\n",
    "    epochs= 4, #30, \n",
    "    learning_rate =1.00E-05,\n",
    "    architecture ='CNN',\n",
    "    optimizer= 'adam',\n",
    "    weight_decay= 4e-5,\n",
    "    ks = (3,5),\n",
    "    loss_fn = 'CrossEntropy',\n",
    "    scheduler=0.2,\n",
    "    f_lin_lay = 4096, #7168 #1024*7 = 7168 4096\n",
    "    random_seed = 1,\n",
    ")\n",
    "\n",
    "save_dict = {'Run' :'IDSW_VGG16_fine_280224_TEST',\n",
    "            'Current_Epoch': 0,\n",
    "            'save_location' : r'C:/Users/nn268/OneDrive - University of Sussex/Sussex/phd/antvis_exp1/saves/'}\n",
    "\n",
    "col_dict =dict(\n",
    "    pad = 5,\n",
    "    colour = 'colour',\n",
    "    size = [226,72]\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87dc8393-e7da-43eb-b0e7-b11c4a46c8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef save2csv(nested_dict, file_name, save_location:str):\\n  # flattern nested dictionary\\n  #flatterend_dict = {}\\n  #for k,v in nested_dict.items():\\n  #  if isinstance(v, dict):\\n  #    for nested_key, nested_val in v.items():\\n  #      flatterend_dict[f\"{k}_{nested_key}\"] = nested_val\\n  #  else:\\n  #    flatterend_dict[k] =v\\n\\n  columns = list(nested_dict.keys())\\n\\n  with open(save_location+str(file_name)+\\'.csv\\', \"a\", newline=\"\") as f:\\n      # using dictwriter\\n      writer = csv.DictWriter(f, fieldnames=columns)\\n      # using writeheader function\\n      #if f.tell() == 0:\\n      #  writer.writeheader()\\n      writer.writerow(nested_dict)\\n      f.close()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   \n",
    "import pprint\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "from datetime import date\n",
    "import collections\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "#columns = ['model_name', 'save_location', 'save_as_csv', 'save_as_JSON', 'epochs', 'lr', 'Wd', 'kernal size', 'dropout', 'f_lin_lay', 'colour', 'resolution', 'pad']\n",
    "\n",
    "# save to csv \n",
    "\n",
    "def save2csv_nest_dict(nested_dict, file_name, save_location:str):\n",
    "  # flattern nested dictionary\n",
    "  flatterend_dict = {}\n",
    "  for k,v in nested_dict.items():\n",
    "    if isinstance(v, dict):\n",
    "      for nested_key, nested_val in v.items():\n",
    "        flatterend_dict[f\"{k}_{nested_key}\"] = nested_val\n",
    "    else:\n",
    "      flatterend_dict[k] =v\n",
    "\n",
    "  columns = list(flatterend_dict.keys())\n",
    "\n",
    "  with open(save_location+str(file_name)+'.csv', \"a+\", newline=\"\") as f:\n",
    "      # using dictwriter\n",
    "      writer = csv.DictWriter(f, fieldnames=columns)\n",
    "      # using writeheader function\n",
    "      if f.tell() == 0:\n",
    "        writer.writeheader()\n",
    "      writer.writerow(flatterend_dict)\n",
    "      f.close()\n",
    "\n",
    "# save to json\n",
    "def save2josn_nested_dict(nested_dict, file_name, save_location:str):\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    with open(save_location+str(file_name)+'.json', 'a+') as f:\n",
    "        f.write(json_obj)\n",
    "        f.close()\n",
    "\n",
    "    \n",
    "#save_location+str(file_name)+'.csv'\n",
    "def save2csv(nested_dict, file_name, save_location:str):\n",
    "    \n",
    "\n",
    "    \n",
    "    columns = list(nested_dict.keys())\n",
    "    path = os.path.join(save_location, file_name +\".csv\")\n",
    "    try:\n",
    "        with open(path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            # using dictwriter\n",
    "            # using writeheader function\n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(nested_dict)\n",
    "            f.close()\n",
    "    except IOError as e:\n",
    "        print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "    except ValueError:\n",
    "              print(\"could not convert to string\")\n",
    "    except:\n",
    "              print(\"unexpected error: \", sys.exc_info()[0])\n",
    "        \n",
    "\n",
    "def save2json(nested_dict, file_name, save_location:str):\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    print(json_obj)\n",
    "    path = os.path.join(save_location, file_name+\".json\")\n",
    "    #print(path)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(json_obj)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def read_in_json(file_path, file_name):\n",
    "    path = os.path.join(file_path, 'file_name')\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            #obj = f.read()\n",
    "            dj = json.load(f, object_pairs_hook= collections.OrderedDict) #obj, \n",
    "            print(dj)\n",
    "    except Exception as e:\n",
    "        print(\"Error decoding Json\")\n",
    "        print(e)\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "    with open(path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        # using dictwriter\n",
    "        # using writeheader function\n",
    "        if f.tell() == 0:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(nested_dict)\n",
    "        f.close()\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def save2csv(nested_dict, file_name, save_location:str):\n",
    "  # flattern nested dictionary\n",
    "  #flatterend_dict = {}\n",
    "  #for k,v in nested_dict.items():\n",
    "  #  if isinstance(v, dict):\n",
    "  #    for nested_key, nested_val in v.items():\n",
    "  #      flatterend_dict[f\"{k}_{nested_key}\"] = nested_val\n",
    "  #  else:\n",
    "  #    flatterend_dict[k] =v\n",
    "\n",
    "  columns = list(nested_dict.keys())\n",
    "\n",
    "  with open(save_location+str(file_name)+'.csv', \"a\", newline=\"\") as f:\n",
    "      # using dictwriter\n",
    "      writer = csv.DictWriter(f, fieldnames=columns)\n",
    "      # using writeheader function\n",
    "      #if f.tell() == 0:\n",
    "      #  writer.writeheader()\n",
    "      writer.writerow(nested_dict)\n",
    "      f.close()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# save to json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ddbb49-828b-4de8-a31c-2a576cd736f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries\n",
    "\n",
    "date = date.today()\n",
    "\n",
    "model_card_vgg = {'name': 'vgg'+str(date), 'model': 'vgg16',\n",
    "                  'f_lin_lay':[4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                            ]},\n",
    "\n",
    "\n",
    "model_card_7c3l = {'name': '7c3l'+str(date), 'model': '7c3l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[248832,    # 452 144    # p5\n",
    "                            59904,      # 226 72     # p5\n",
    "                            11264,      # 113  36    # p2\n",
    "                            1536,       # 57 18      # p1\n",
    "                            ]}\n",
    "\n",
    "\n",
    "\n",
    "model_card_4c3l = {'name': '4c3l'+str(date), 'model': '4c3l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[539904,    # 452 144    # p5\n",
    "                             141056,    # 226 72     # p5\n",
    "                             304640,     # 113  36    # p2\n",
    "                             9984,      # 57 18      # p1\n",
    "                             2304,      # 29  9\n",
    "                             512,       # 15 5\n",
    "                             256]}      # 8 3\n",
    "\n",
    "model_card_3c2l = {'name': '3c2l'+str(date), 'model': '3c2l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[1069888,    # 452 144    # p5\n",
    "                             274688,     #226 72      # p5\n",
    "                             68096,      # 113  36    # p2\n",
    "                             17280,      # 57 18      # p1\n",
    "                             3840,       # 29  9\n",
    "                             960,        # 15 5\n",
    "                             256]}       # 8 3\n",
    "\n",
    "model_card_2c2l = {'name': '2c2l'+str(date), 'model': '2c2l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[1055232,    # 452 144    # p5\n",
    "                             267264,     #226 72      # p5\n",
    "                             64512,      # 113  36    # p2\n",
    "                             15552,      # 57 18      # p1\n",
    "                             3072,       # 29  9\n",
    "                             640,        # 15 5\n",
    "                             128]}       # 8 3\n",
    "\n",
    "resolution_card_452144 = {'resolution':[452,144], 'padding':5, 'index':0}\n",
    "resolution_card_22672 = {'resolution':[226,72], 'padding':5, 'index':1}\n",
    "resolution_card_11336 = {'resolution':[113,36], 'padding':2, 'index':2}\n",
    "resolution_card_5715 = {'resolution':[57,18], 'padding':1, 'index':3}\n",
    "\n",
    "resolution_card_299 = {'resolution':[29,9], 'padding':0, 'index':4}\n",
    "resolution_card_155 = {'resolution':[15,5], 'padding':0, 'index':5}\n",
    "resolution_card_83 = {'resolution':[8,3], 'padding':0, 'index':6}\n",
    "\n",
    "\n",
    "resolution_cards = [resolution_card_452144, resolution_card_22672, resolution_card_11336, resolution_card_5715,\n",
    "                    resolution_card_299, resolution_card_155, resolution_card_83]\n",
    "\n",
    "learning_rate_cards = [1e-5, 1e-4, 1e-3, 1e-2, 1e-6]\n",
    "wd_cards = [4e-5, 5e-5, 1e-5, 1e-4, 5e-4, 4e-4]\n",
    "scheduler_cards = [0.2, 0.1, 0.3, 0.05, 0.001]\n",
    "\n",
    "seeds = [1,3,5,7,9,34,57,79]\n",
    "\n",
    "model_cards =[model_card_vgg, model_card_7c3l, model_card_4c3l, model_card_3c2l, model_card_2c2l]\n",
    "\n",
    "loss_fn_cards = ['MSE', 'CrossEntropy']\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495f38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, x_train, x_val, y_train, y_val, save_dict, lr, scheduler, epochs, model_name): #train_dl, val_dl, \n",
    "\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)#build_optimizer(mo\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=scheduler, last_epoch=-1) \n",
    "                                                                    #scheduler'\n",
    "    ####\n",
    "    \n",
    "    #model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    #losses= []\n",
    "    #predictions = []\n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "\n",
    "    \n",
    "    total_epochs = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        if epoch ==0:\n",
    "            best_model=model\n",
    "            best_acc=0\n",
    "\n",
    "        t_loss, train_prediction, t_correct, model, optimizer = loop(model=model, X=x_train, Y=y_train, loss_fn=loss_fn, device=device, col_dict=col_dict, num_classes=11, model_name= model_name, optimizer=optimizer, scheduler =scheduler)\n",
    "        \n",
    "        \n",
    "        save_dict['t_loss_list'] = t_loss_list\n",
    "        save_dict['t_labels'] = y_train\n",
    "        save_dict['t_predict_list'] = t_predict_list \n",
    "\n",
    "        train_acc = (t_correct / len(x_train))\n",
    "        t_accuracy_list.append(train_acc)\n",
    "        \n",
    "        save_dict['t_accuracy_list'] = t_accuracy_list \n",
    "        clear_output()\n",
    "        \n",
    "            \n",
    "        print('validating...')\n",
    "        \n",
    "        v_loss, val_prediction, val_correct= loop(model=model, X=x_val, Y=y_val, loss_fn=loss_fn, device=device, col_dict=col_dict, num_classes=11, model_name= model_name, train=False)\n",
    "\n",
    "\n",
    "        save_dict['v_loss_list'] = v_loss_list\n",
    "        save_dict['v_predict_list'] = v_predict_list  #\n",
    "        save_dict['v_labels'] = y_val\n",
    "        \n",
    "        val_acc = (t_correct / len(x_val))\n",
    "        v_accuracy_list.append(val_acc)\n",
    "        save_dict['v_accuracy_list'] = v_accuracy_list  #\n",
    "        \n",
    "\n",
    "        clear_output()\n",
    "            \n",
    "        total_epochs += epoch\n",
    "        save_dict['Current_Epoch'] += epochs\n",
    "        save_dict['training_samples'] = len(x_train)\n",
    "        save_dict['validation_samples'] = len(x_val)\n",
    "            \n",
    "    model = best_model\n",
    "\n",
    "    return model, save_dict\n",
    "\n",
    "def test_loop(model, X, Y, loss_fn, device, num_classes):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    colour = col_dict['colour']\n",
    "    size = col_dict['size']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, img in enumerate(X):\n",
    "            prepro = ImageProcessor(device)\n",
    "            tense = prepro.colour_size_tense(img, colour, size)\n",
    "            prediction = model.forward(tense)\n",
    "            label = label_oh_tf(Y[idx], device, num_classes)\n",
    "\n",
    "            if prediction.argmax()==label.argmax():\n",
    "                num_correct +=1\n",
    "            total_count +=1\n",
    "            correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "\n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    file_path =  r'//smbhome.uscs.susx.ac.uk/nn268/Documents/PHD/antvis/optics/AugmentedDS_IDSW/'\n",
    "    img_len = len(os.listdir(file_path))\n",
    "    \n",
    "    x, y = import_imagedata(file_path)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, train_size=0.8,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.1, train_size=0.8,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "\n",
    "    return x_train, y-train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "    \n",
    "    model=  train_model(model, x_train, x_val, y_train, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650c0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fns4wandb import choose_model, set_lossfn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c19d9613",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13856/1573327979.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"cuda:1\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel_card\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_cards\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlin_lay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_card\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'f_lin_lay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_card\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for model_card in model_cards:\n",
    "    lin_lay = model_card['f_lin_lay']\n",
    "    model_name = model_card['model']\n",
    "    \n",
    "    for resolution_card in resolution_cards:\n",
    "        if resolution_card['index'] > len(model_card['f_lin_lay']):\n",
    "            pass\n",
    "        \n",
    "        resolution = resolution_card['resolution']\n",
    "        pad = resolution_card['padding']\n",
    "        \n",
    "        for learning_rate in learning_rate_cards:\n",
    "            for wd_card in wd_cards:\n",
    "                for scheduler in scheduler_cards:\n",
    "                    for seed in seeds:\n",
    "                        seed = seed\n",
    "                        for loss_fn in loss_fn_cards:\n",
    "                            \n",
    "                            # set save dictionary\n",
    "                            save_dict = {'Run' : f\"{model_name}{resolution}{date}\",\n",
    "                                         'Current_Epoch': 0,\n",
    "                                         'save_location' : r'C:/Users/nn268/OneDrive - University of Sussex/Sussex/phd/antvis_exp1/saves/'}\n",
    "                            \n",
    "                            # set model\n",
    "                            model = choose_model(model_name)\n",
    "                            \n",
    "                            # get image data\n",
    "                            x_train, y_train, x_val, y_val, x_test, y_test = get_data()\n",
    "                            \n",
    "                            # set loss function\n",
    "                            loss_fn = set_lossfn(loss-fn)\n",
    "                            \n",
    "                            # train val\n",
    "                            model, save_dict=  train_model(model, x_train, x_val, y_train, y_val, save_dict, lr, scheduler, epochs, model_name)\n",
    "                            \n",
    "                            #test\n",
    "                            test_acc = test_loop(x_test, y_test, loss_fn, device, 11)\n",
    "                            save_dict.update({'test_acc': test_acc})\n",
    "                            \n",
    "                            #saving\n",
    "                            diction = {}\n",
    "                            d = date.today()\n",
    "                            d=str(d)\n",
    "                            diction.update({'Date':d})\n",
    "                            diction.update({'model_name': model_name})\n",
    "                            diction.update({'loss_fn': loss_fn})\n",
    "                            diction.update({'lr': learning_rate})\n",
    "                            diction.update({'wd': wd_card})\n",
    "                            diction.update({'scheduler': scheduler})\n",
    "                            diction.update({'seed': seed})\n",
    "                            diction.update({'loss_fn': loss_fn})\n",
    "                            diction.update({'resolution': resolution})\n",
    "                            diction.update({'pad': pad})\n",
    "                            diction.update({'lin_lay': lin_lay})\n",
    "                            diction.update(save_dict)\n",
    "                            \n",
    "                            save_location = save_dict['save_location']\n",
    "                            title = save_dict['Run']\n",
    "                            save2json(diction, title, save_location)\n",
    "                            save2csv(diction, title, save_location)\n",
    "\n",
    "                            diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "\n",
    "                            with open(f\"{save_location}{title}.pkl\", 'wb+') as f:\n",
    "                                pickle.dump(diction, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336527ec-d970-4cb8-aabb-666abbd4dcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"config = dict(\n",
    "    epochs= 80, #30, \n",
    "    learning_rate =1e-6,\n",
    "    architecture ='CNN',\n",
    "    optimizer= 'adam',\n",
    "    weight_decay= 4e-5,\n",
    "    ks = (3,5),\n",
    "    scheduler=0.2,\n",
    "    f_lin_lay = 7168 #1024*7 = 7168\n",
    ")\n",
    "col_dict= dict(\n",
    "    colour= \"colour\",\n",
    "    size= [227,72],\n",
    "    pad= 5)\n",
    "\n",
    "# this directory works : C:\\Users\\nn268\\Documents\\folderTest\n",
    "title = f'saving_TEST'\n",
    "save_dict = {'Run' : title,\n",
    "            'Current_Epoch': 0, #'//smbhome.uscs.susx.ac.uk/nn268/Documents/PHD/antvis/optics/AugmentedDS_IDSW/'\n",
    "            'save_location' :r\"C:/Users/nn268/OneDrive - University of Sussex/Sussex/phd/folder_test/\"\n",
    "            } #\\\\smbhome.uscs.susx.ac.uk\\nn268\\Desktop\\_ # r'//smbhome.uscs.susx.ac.uk/nn268/Documents/PHD/antvis/optics/pickles/'\n",
    "\n",
    "\n",
    "#print(d)\n",
    "d = date.today()\n",
    "d=str(d)\n",
    "diction = {}\n",
    "diction.update({'Date':d})\n",
    "diction.update(config)\n",
    "diction.update(save_dict)\n",
    "\n",
    "#pp.pprint(diction)\n",
    "#print(diction)\n",
    "save_location = save_dict['save_location']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefcac1f-c450-4133-9002-15932660e80d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#save2csv(diction, 'tst2csv', save_location) #save_dict['save_location']\n",
    "#save2josn(diction, 'testjson', save_location)\n",
    "\n",
    "#with open('testjson.json', 'r') as openfile:\n",
    "#    dj = json.load(openfile)\n",
    "#    \n",
    "#pp.pprint(dj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b22efc9-e798-4803-934d-374fe74d63a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#pp.pprint(dj)\n",
    "\n",
    "\"\"\"\n",
    "# set up model\n",
    "model_vgg16 = vgg16(weights=\"IMAGENET1K_V1\")\n",
    "vgg_feats = model_vgg16.features\n",
    "vgg_classifier = model_vgg16.classifier\n",
    "vgg_classifier.pop(6)\n",
    "\n",
    "vgg = nn.Sequential(\n",
    "    vgg_feats,\n",
    "    Flattern(),\n",
    "    vgg_classifier,\n",
    "    nn.Linear(4096,11),\n",
    "    nn.Softmax(dim=0),\n",
    "    )\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
