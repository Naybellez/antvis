{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5e9143-7c4d-4353-b98f-8c364f461455",
   "metadata": {},
   "source": [
    "# Continueing work on incorperating Batching - batched data - into the pipeline.\n",
    "### This notebook will also continue the work with Pandas at getting the stats for the unbatched data.\n",
    "\n",
    "Thoughts are still on\n",
    "1. changing up the model architecture as the Wrok done by Kemal (removing layers from the VGG16 model, works better. here could be some assessment on what changes I made to make my models and why these didn't work out so well)\n",
    "2. Removing and weighting the colour channels\n",
    "3. When learning, ants will see the fist section of the route the most, second second most and so on - we could introduce this method into our model learning? how does this affect the learning of the model, what changes (neeed point 1. to be done first, want to go forth with the best ground base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c15f4-4326-41b0-91c6-95b1031f3d41",
   "metadata": {},
   "source": [
    "# Tables\n",
    "2c2l model. batch size of 32 (semi random, worked for Kemal, may well be the batch size of VGG16)\n",
    "\n",
    "Memory Issues, change 32 to 15\n",
    "    still tooo bug, reduced to batch of 5\n",
    "\n",
    "|Res (x,y)|pad|f lin lay|\n",
    "|---------|--|---------|\n",
    "|452,144|5||\n",
    "|226,72|5||\n",
    "|113,36|2||\n",
    "|57,18|1||\n",
    "|29,9|0||\n",
    "|15,5|0||\n",
    "|8,3|0||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0021c5f-9953-45cc-afec-ae466e0e1c83",
   "metadata": {},
   "source": [
    "hiccup - memory problem/ 420G in optics - probably from too many saves. cleaning up excess files is taking tiiime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c560152-613f-4f16-83d3-2a77dd159826",
   "metadata": {},
   "source": [
    "### Exploring example from [machinelearningmastery](https://machinelearningmastery.com/training-a-pytorch-model-with-dataloader-and-dataset/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7205b269-a559-4873-9b5e-ee70f6c3fe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4659febc-719b-4cee-b5a2-e6d96eded4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/nn268/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/its/home/nn268/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 82.54%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Read data, convert to NumPy arrays\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "connectionist_bench_sonar_mines_vs_rocks = fetch_ucirepo(id=151) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = connectionist_bench_sonar_mines_vs_rocks.data.features\n",
    "X=X.to_numpy()\n",
    "y = connectionist_bench_sonar_mines_vs_rocks.data.targets \n",
    "y=y.to_numpy()\n",
    "#print(type(X))\n",
    "#print(type(y))\n",
    "# metadata \n",
    "\n",
    "#print(connectionist_bench_sonar_mines_vs_rocks.metadata)  \n",
    "# variable information \n",
    "#print(connectionist_bench_sonar_mines_vs_rocks.variables) \n",
    "\n",
    " \n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    " \n",
    "# convert into PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# train-test split for evaluation of the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "# set up DataLoader for training set\n",
    "loader = DataLoader(list(zip(X_train, y_train)), shuffle=True, batch_size=16)\n",
    " \n",
    "# create model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(60, 60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    " \n",
    "# Train the model\n",
    "n_epochs = 200\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        #print(y_pred.shape) # me # torch.Size([16, 1])\n",
    "        #print(y_batch.shape) # me # torch.Size([16, 1])\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "# evaluate accuracy after training\n",
    "model.eval()\n",
    "y_pred = model(X_test)\n",
    "acc = (y_pred.round() == y_test).float().mean()\n",
    "acc = float(acc)\n",
    "print(\"Model accuracy: %.2f%%\" % (acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab48878-cb29-435b-9238-fa6fe3574dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a058e13-79a4-4c91-9531-6c5742cca7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
