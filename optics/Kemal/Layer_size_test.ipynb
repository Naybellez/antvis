{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 16:48:40.145677: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-18 16:48:40.173382: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-18 16:48:40.173401: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-18 16:48:40.174066: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-18 16:48:40.178615: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-18 16:48:40.675174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import torch.optim.lr_scheduler as sch\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptrblk_fin_mod_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    size_all_gb = size_all_mb/953.674\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))\n",
    "    print('model size: {:.3f}GB'.format(size_all_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(directory_path):\n",
    "\n",
    "    data_directory_path = directory_path \n",
    "    data_file_path = []\n",
    "    labels = []\n",
    "\n",
    "    directory = os.fsencode(data_directory_path)\n",
    "        \n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename[:4]== 'IDSW':\n",
    "            data_file_path.append(data_directory_path+\"/\"+filename)\n",
    "            #print(filename[5:7])\n",
    "            labels.append(int(filename[5:7])- 1)\n",
    "\n",
    "    return data_file_path, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(image_paths, labels, seed):\n",
    "\n",
    "    x_remainder_train, test_data, y_remainder_train, test_labels = train_test_split(image_paths, labels, test_size=0.3, random_state=seed)\n",
    "    train_data, validation_data, train_labels, validation_labels = train_test_split(x_remainder_train, y_remainder_train, test_size=0.1, random_state=seed)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels, validation_data, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img, pad_size):\n",
    "\t\tleft_x = img[:,:pad_size,:] # h, w, c\n",
    "\t\tright_x = img[:,-pad_size:,:]\n",
    "\t\ty = img.shape[0]\n",
    "\t\tx = img.shape[1]+(pad_size*2)\n",
    "\t\tnew_x = np.full((y, x, 3),255) # h w c\n",
    "\t\tnew_x[:,:pad_size,:] = right_x\n",
    "\t\tnew_x[:,pad_size:-pad_size,:] = img\n",
    "\t\tnew_x[:,-pad_size:,:] = left_x\n",
    "\t\treturn new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(image_paths):\n",
    "\n",
    "    processed_images = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        resized_img = cv2.resize(img, (226, 72))\n",
    "        processed_img = padding(resized_img, 5)\n",
    "        im_chan = processed_img.shape[2]\n",
    "        imgY, imgX = processed_img.shape[0], processed_img.shape[1]\n",
    "        processed_img_tensor = torch.tensor(processed_img, device=mps_device, dtype = torch.float32)\n",
    "        normalized_tensor = torch.nn.functional.normalize(processed_img_tensor) \n",
    "        permuted_tensor = normalized_tensor.permute(2, 0, 1)\n",
    "\n",
    "        tensor = permuted_tensor.reshape(im_chan, imgY, imgX)\n",
    "        tensor.to(mps_device)\n",
    "        processed_images.append(tensor)\n",
    "\n",
    "    return processed_images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "seed = random.seed(1)\n",
    "image_paths, labels = get_data(data_path)\n",
    "train_data, train_labels, test_data, test_labels, validation_data, validation_labels = train_test_validation_split(image_paths,labels,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = image_processing(train_data)\n",
    "test_data = image_processing(test_data)\n",
    "validation_data = image_processing(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 #32\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "val = []\n",
    "\n",
    "for i, data in enumerate(train_data):\n",
    "    train.append((data, train_labels[i]))\n",
    "\n",
    "for i, data in enumerate(test_data):\n",
    "    test.append((data, test_labels[i]))\n",
    "\n",
    "for i, data in enumerate(validation_data):\n",
    "    val.append((data, validation_labels[i]))\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train, batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(val, batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(t_loss, v_loss, save_location,run_name:str):\n",
    "    lab = \"Learning Curve \"+run_name\n",
    "    font1 = {'family':'serif','color':'darkblue','size':16}\n",
    "    font2 = {'family':'serif','color':'darkblue','size':15}\n",
    "    \n",
    "    plt.plot(range(len(t_loss)), t_loss, label ='Training loss')\n",
    "    plt.plot(range(len(v_loss)), v_loss, label='Validation loss')\n",
    "    plt.title(run_name+\"\\n Learning Curve \", font1)\n",
    "    plt.xlabel('Epochs', font2)\n",
    "    plt.ylabel('Loss', font2)\n",
    "    #plt.yscale(\"log\")\n",
    "    # plt.legend()\n",
    "    # if save_location != None:\n",
    "    #     plt.savefig(save_location+'/'+lab+'.png') #run_name\n",
    "    # else:\n",
    "    #     print(\"Save Location Not Specified!\")\n",
    "    plt.show()\n",
    "\n",
    "def accuracy_curve(v_accuracy_list, t_accuracy_list, save_location,run_name:str):\n",
    "    lab = \"Accuracy Curve\"+run_name\n",
    "    font1 = {'family':'serif','color':'darkblue','size':16}\n",
    "    font2 = {'family':'serif','color':'darkblue','size':15}\n",
    "\n",
    "    plt.title(run_name+\"\\n Accuracy Curve\", font1)\n",
    "    plt.plot(range(len(t_accuracy_list)), t_accuracy_list, label ='Training accuracy')\n",
    "    plt.plot(range(len(v_accuracy_list)), v_accuracy_list, label='Validation accuracy')\n",
    "    plt.xlabel('Epochs', font2)\n",
    "    plt.ylabel('Accuracy', font2)\n",
    "    plt.legend()\n",
    "    # if save_location != None:\n",
    "    #     plt.savefig(save_location+lab+'.png', format='png')\n",
    "    # else:\n",
    "    #     print(\"Save Location Not Specified!\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_layers = [nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGTest(nn.Module):\n",
    "    def __init__(self, start_index, starting_side, conv_layers, num_classes=11):\n",
    "        super(VGGTest, self).__init__()\n",
    "        self.starting_side = starting_side\n",
    "        self.start_index = start_index\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "\n",
    "        self.conv_layers = [self.layer1,self.layer2,self.layer3,self.layer4,self.layer5,self.layer6,self.layer7,self.layer8,self.layer9,self.layer10,self.layer11,self.layer12,self.layer13]\n",
    "        \n",
    "        self.linear_layer_dimensions = [7168, 28672, 28672, 28672, 133632, 133632,271872,271872 , 271872, 271872, 135936, 543744, 271872] #271872 #271872 #66816\n",
    "        self.lin_lay_dim = 0\n",
    "        if starting_side == \"front\":\n",
    "            self.lin_lay_dim = start_index\n",
    "        else:\n",
    "            self.lin_lay_dim = 13 - start_index\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.linear_layer_dimensions[self.lin_lay_dim], 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.starting_side == \"end\":\n",
    "            for i in range(0, self.start_index):\n",
    "                layer = self.conv_layers[i]\n",
    "                if i == 0:\n",
    "                    out = layer(x)\n",
    "                else:\n",
    "                    out = layer(out)\n",
    "\n",
    "        else:\n",
    "            for i in range(self.start_index, 13):\n",
    "                layer = self.conv_layers[i]\n",
    "                if i == 0:\n",
    "                    out = layer(x)\n",
    "                else:\n",
    "                    out = layer(out)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = out.flatten(start_dim=1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, schedulr, optimizer, criterion, layer_size, starting_side, epochs):\n",
    "    epoch_number = 0\n",
    "    EPOCHS = epochs\n",
    "    best_vloss = 1_000_000.\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    #print(\" tm 1 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('EPOCH {}:'.format(epoch_number + 1))\n",
    "        training_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "        #print(\" tm 2 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "        #avg_loss = train_one_epoch(epoch_number, writer)\n",
    "        for i, data in enumerate(dataloaders['train'], 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "            #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "            #print(\" tm 3 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 2000 mini-batches\n",
    "                training_loss = running_loss / 10 # loss per batch\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}') ###***\n",
    "                running_loss = 0.0\n",
    "\n",
    "        running_vloss = 0.0\n",
    "        model.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(dataloaders['val']):\n",
    "                vinputs, vlabels = vdata\n",
    "                vlabels = vlabels.to(mps_device)\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(training_loss, avg_vloss))\n",
    "\n",
    "        losses.append(training_loss)\n",
    "        val_losses.append(avg_vloss.item())\n",
    "\n",
    "        epoch_number += 1\n",
    "        schedulr.step()\n",
    "\n",
    "    learning_curve(losses, val_losses, None, starting_side+\"\"+layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "def save2csv(nested_dict, file_name, save_location:str):\n",
    "    columns = list(nested_dict.keys())\n",
    "    path = os.path.join(save_location, file_name +\".csv\")\n",
    "    try:\n",
    "        with open(path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            # using dictwriter\n",
    "            # using writeheader function\n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(nested_dict)\n",
    "            f.close()\n",
    "    except IOError as e:\n",
    "        print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "    except ValueError:\n",
    "              print(\"could not convert to string\")\n",
    "    except:\n",
    "              print(\"unexpected error: \", sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloaders):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['test']:\n",
    "            images, labels = data\n",
    "            images = images.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "            count += len(images)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "    print(f'Accuracy of the network on the {count} test images: {100 * correct // total} %')\n",
    "    return accuracy\n",
    "\n",
    "def test_model_train(model, dataloaders):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['train']:\n",
    "            images, labels = data\n",
    "            images = images.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "            count += len(images)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "    print(f'Accuracy of the network on the {count} train images: {100 * correct // total} %')\n",
    "    return accuracy\n",
    "\n",
    "def test_model_validation(model, dataloaders):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['val']:\n",
    "            images, labels = data\n",
    "            images = images.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "            count += len(images)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "    print(f'Accuracy of the network on the {count} validation images: {100 * correct // total} %')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Current allocated memory (GB): 0.0\n",
      "1.1 Current allocated memory (GB): 0.0\n",
      "model size: 4368.400MB\n",
      "model size: 4.581GB\n",
      " 2 Current allocated memory (GB): 0.0\n",
      " 2.2 Current allocated memory (GB): 0.0\n",
      "EPOCH 1:\n",
      "[1,    10] loss: 2.419\n",
      "[1,    20] loss: 2.268\n",
      "[1,    30] loss: 2.165\n",
      "[1,    40] loss: 2.159\n",
      "[1,    50] loss: 1.985\n",
      "[1,    60] loss: 2.020\n",
      "[1,    70] loss: 2.034\n",
      "[1,    80] loss: 1.910\n",
      "[1,    90] loss: 1.886\n",
      "[1,   100] loss: 1.809\n",
      "[1,   110] loss: 1.608\n",
      "[1,   120] loss: 1.636\n",
      "[1,   130] loss: 1.589\n",
      "LOSS train 1.589251160621643 valid 1.4111179113388062\n",
      "EPOCH 2:\n",
      "[2,    10] loss: 1.426\n",
      "[2,    20] loss: 1.240\n",
      "[2,    30] loss: 1.228\n",
      "[2,    40] loss: 1.181\n",
      "[2,    50] loss: 1.132\n",
      "[2,    60] loss: 1.302\n",
      "[2,    70] loss: 1.154\n",
      "[2,    80] loss: 1.142\n",
      "[2,    90] loss: 1.123\n",
      "[2,   100] loss: 1.119\n",
      "[2,   110] loss: 0.968\n",
      "[2,   120] loss: 1.079\n",
      "[2,   130] loss: 1.022\n",
      "LOSS train 1.0222208023071289 valid 0.9824888110160828\n",
      "EPOCH 3:\n",
      "[3,    10] loss: 0.873\n",
      "[3,    20] loss: 0.706\n",
      "[3,    30] loss: 0.750\n",
      "[3,    40] loss: 0.760\n",
      "[3,    50] loss: 0.775\n",
      "[3,    60] loss: 0.624\n",
      "[3,    70] loss: 0.673\n",
      "[3,    80] loss: 0.706\n",
      "[3,    90] loss: 0.752\n",
      "[3,   100] loss: 0.529\n",
      "[3,   110] loss: 0.645\n",
      "[3,   120] loss: 0.583\n",
      "[3,   130] loss: 0.676\n",
      "LOSS train 0.6760924577713012 valid 0.8070648908615112\n",
      "EPOCH 4:\n",
      "[4,    10] loss: 0.457\n",
      "[4,    20] loss: 0.467\n",
      "[4,    30] loss: 0.407\n",
      "[4,    40] loss: 0.395\n",
      "[4,    50] loss: 0.417\n",
      "[4,    60] loss: 0.389\n",
      "[4,    70] loss: 0.379\n",
      "[4,    80] loss: 0.385\n",
      "[4,    90] loss: 0.377\n",
      "[4,   100] loss: 0.408\n",
      "[4,   110] loss: 0.401\n",
      "[4,   120] loss: 0.386\n",
      "[4,   130] loss: 0.353\n",
      "LOSS train 0.3526458814740181 valid 0.7533784508705139\n",
      "EPOCH 5:\n",
      "[5,    10] loss: 0.280\n",
      "[5,    20] loss: 0.284\n",
      "[5,    30] loss: 0.270\n",
      "[5,    40] loss: 0.211\n",
      "[5,    50] loss: 0.284\n",
      "[5,    60] loss: 0.256\n",
      "[5,    70] loss: 0.268\n",
      "[5,    80] loss: 0.216\n",
      "[5,    90] loss: 0.213\n",
      "[5,   100] loss: 0.199\n",
      "[5,   110] loss: 0.189\n",
      "[5,   120] loss: 0.213\n",
      "[5,   130] loss: 0.196\n",
      "LOSS train 0.19567357674241065 valid 0.6468125581741333\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Current allocated memory (GB): 0.0\n",
      "Accuracy of the network on the 2161 train images: 99 %\n",
      "Accuracy of the network on the 241 validation images: 81 %\n",
      "Accuracy of the network on the 1030 test images: 76 %\n",
      "model size: 4368.400MB\n",
      "model size: 4.581GB\n",
      "4 Current allocated memory (GB): 0.0\n",
      "1 Current allocated memory (GB): 0.0\n",
      "1.1 Current allocated memory (GB): 0.0\n",
      "model size: 4368.400MB\n",
      "model size: 4.581GB\n",
      " 2 Current allocated memory (GB): 0.0\n",
      " 2.2 Current allocated memory (GB): 0.0\n",
      "EPOCH 1:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x135936 and 271872x4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m schedulr \u001b[38;5;241m=\u001b[39m sch\u001b[38;5;241m.\u001b[39mExponentialLR(optimizer, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m 2.2 Current allocated memory (GB):\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_allocated() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_testing_layer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedulr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#ptrblk_fin_mod_size(model_testing_layer_size)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3 Current allocated memory (GB):\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_allocated() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, schedulr, optimizer, criterion, layer_size, starting_side, epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 103\u001b[0m, in \u001b[0;36mVGGTest.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mreshape(out\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    102\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 103\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(out)\n\u001b[1;32m    105\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(out)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x135936 and 271872x4096)"
     ]
    }
   ],
   "source": [
    "front_accuracies = []\n",
    "end_accuracies = []\n",
    "epochs = 5\n",
    "timestamp = datetime.now().strftime('%d%m%Y')\n",
    "\n",
    "save_loc = r\"/its/home/nn268/antvis/antvis/optics/Kemal/saves/\"\n",
    "\n",
    "for i in range(5, 1, -1): #12\n",
    "    print(\"1 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    model_testing_layer_size = VGGTest(start_index=i, starting_side=\"end\", conv_layers=convolution_layers)\n",
    "    print(\"1.1 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    model_testing_layer_size = model_testing_layer_size.to(mps_device)\n",
    "    ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    print(\" 2 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_testing_layer_size.parameters(), lr=1.00E-05, weight_decay= 4e-5)\n",
    "    schedulr = sch.ExponentialLR(optimizer, gamma=0.9)\n",
    "    print(\" 2.2 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    train_model(model_testing_layer_size, dataloaders, schedulr, optimizer, criterion, str(i), \"End\", epochs)\n",
    "    #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    print(\"3 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    #end_accuracies.append(test_model(model_testing_layer_size, dataloaders))\n",
    "\n",
    "    results_to_csv = {\n",
    "        \"Layer Size\" : str(i),\n",
    "        \"Epoch\": epochs,\n",
    "        \"Starting Side\": \"End\",\n",
    "        \"Loss\" : \"Cross Entropy Loss\",\n",
    "        \"Optimizer\" : \"Adam\",\n",
    "        \"Learning Rate\": \"1.00E-05\",\n",
    "        \"Wieght Decay\": \"4e-5\",\n",
    "        \"Scheduler\": \"ExponentialLR\",\n",
    "        \"Gamma\": \"0.9\",\n",
    "        \"Train Accuracy\": str(test_model_train(model_testing_layer_size, dataloaders)),\n",
    "        \"Validation Accuracy\": str(test_model_validation(model_testing_layer_size, dataloaders)),\n",
    "        \"Test Accuracy\": str(test_model(model_testing_layer_size, dataloaders)),\n",
    "    }\n",
    "\n",
    "    save2csv(results_to_csv,\"ModelResults_{}\".format(timestamp), save_loc) #antvis/antvis/optics/Kemal/saves\n",
    "    torch.cuda.empty_cache()\n",
    "    #clear_output()\n",
    "    \n",
    "    ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    print(\"4 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    del model_testing_layer_size\n",
    "\n",
    "\n",
    "for i in range(1, 12):\n",
    "    model_testing_layer_size = VGGTest(start_index=i, starting_side=\"front\", conv_layers=convolution_layers)\n",
    "    model_testing_layer_size = model_testing_layer_size.to(mps_device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_testing_layer_size.parameters(), lr=1.00E-05, weight_decay= 4e-5)\n",
    "    schedulr = sch.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    train_model(model_testing_layer_size, dataloaders, schedulr, optimizer, criterion, str(13 - i), \"Front\", epochs)\n",
    "\n",
    "    #front_accuracies.append(test_model(model_testing_layer_size, dataloaders))\n",
    "\n",
    "    results_to_csv = {\n",
    "        \"Layer Size\" : str(i),\n",
    "        \"Epoch\": epochs,\n",
    "        \"Starting Side\": \"Front\",\n",
    "        \"Loss\" : \"Cross Entropy Loss\",\n",
    "        \"Optimizer\" : \"Adam\",\n",
    "        \"Learning Rate\": \"1.00E-05\",\n",
    "        \"Wieght Decay\": \"4e-5\",\n",
    "        \"Scheduler\": \"ExponentialLR\",\n",
    "        \"Gamma\": \"0.9\",\n",
    "        \"Train Accuracy\": str(test_model_train(model_testing_layer_size, dataloaders)),\n",
    "        \"Validation Accuracy\": str(test_model_validation(model_testing_layer_size, dataloaders)),\n",
    "        \"Test Accuracy\": str(test_model(model_testing_layer_size, dataloaders)),\n",
    "    }\n",
    "\n",
    "    save2csv(results_to_csv,\"ModelResults_{}\".format(timestamp), save_loc)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"4 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    del model_testing_layer_size\n",
    "    \n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {'a':1, 'b':2, 'c':3}\n",
    "\n",
    "save2csv(di,\"testing\".format(timestamp), r\"/its/home/nn268/antvis/antvis/optics/Kemal/saves/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing batch size made no difference\n",
    "added a flatten(start_dim=1)\n",
    "\n",
    "added memory prints\n",
    "\n",
    "changed some values in self.linear_layer_dimension list\n",
    "\n",
    "\n",
    "changed save location, device type and data path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
