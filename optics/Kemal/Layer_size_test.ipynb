{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 17:22:56.445869: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-03 17:22:56.469810: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-03 17:22:56.469828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-03 17:22:56.470482: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-03 17:22:56.475847: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-03 17:22:56.947127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import torch.optim.lr_scheduler as sch\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm \n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "from functions import ImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "\n",
    "data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "\n",
    "save_loc = r\"/its/home/nn268/antvis/antvis/optics/Kemal/saves/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptrblk_fin_mod_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    size_all_gb = size_all_mb/953.674\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))\n",
    "    print('model size: {:.3f}GB'.format(size_all_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = 'cpu'# \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(directory_path):\n",
    "\n",
    "    data_directory_path = directory_path \n",
    "    data_file_path = []\n",
    "    labels = []\n",
    "\n",
    "    directory = os.fsencode(data_directory_path)\n",
    "        \n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename[:4]== 'IDSW':\n",
    "            data_file_path.append(data_directory_path+\"/\"+filename)\n",
    "            #print(filename[5:7])\n",
    "            labels.append(int(filename[5:7])- 1)\n",
    "\n",
    "    return data_file_path, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(image_paths, labels, seed):\n",
    "\n",
    "    x_remainder_train, test_data, y_remainder_train, test_labels = train_test_split(image_paths, labels, test_size=0.3, random_state=seed)\n",
    "    train_data, validation_data, train_labels, validation_labels = train_test_split(x_remainder_train, y_remainder_train, test_size=0.1, random_state=seed)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels, validation_data, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img, pad_size):\n",
    "\t\tleft_x = img[:,:pad_size,:] # h, w, c\n",
    "\t\tright_x = img[:,-pad_size:,:]\n",
    "\t\ty = img.shape[0]\n",
    "\t\tx = img.shape[1]+(pad_size*2)\n",
    "\t\tnew_x = np.full((y, x, 3),255) # h w c\n",
    "\t\tnew_x[:,:pad_size,:] = right_x\n",
    "\t\tnew_x[:,pad_size:-pad_size,:] = img\n",
    "\t\tnew_x[:,-pad_size:,:] = left_x\n",
    "\t\treturn new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(image_paths):\n",
    "\n",
    "    processed_images = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        resized_img = cv2.resize(img, (226, 72))\n",
    "        processed_img = padding(resized_img, 5)\n",
    "        im_chan = processed_img.shape[2]\n",
    "        imgY, imgX = processed_img.shape[0], processed_img.shape[1]\n",
    "        processed_img_tensor = torch.tensor(processed_img, device=mps_device, dtype = torch.float32)\n",
    "        normalized_tensor = torch.nn.functional.normalize(processed_img_tensor) \n",
    "        permuted_tensor = normalized_tensor.permute(2, 0, 1)\n",
    "\n",
    "        tensor = permuted_tensor.reshape(im_chan, imgY, imgX)\n",
    "        tensor.to(mps_device)\n",
    "        processed_images.append(tensor)\n",
    "\n",
    "    return processed_images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = random.seed(1)\n",
    "image_paths, labels = get_data(data_path)\n",
    "train_data, train_labels, test_data, test_labels, validation_data, validation_labels = train_test_validation_split(image_paths,labels,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = image_processing(train_data)\n",
    "test_data = image_processing(test_data)\n",
    "validation_data = image_processing(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 #32\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "val = []\n",
    "\n",
    "for i, data in enumerate(train_data):\n",
    "    train.append((data, train_labels[i]))\n",
    "\n",
    "for i, data in enumerate(test_data):\n",
    "    test.append((data, test_labels[i]))\n",
    "\n",
    "for i, data in enumerate(validation_data):\n",
    "    val.append((data, validation_labels[i]))\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train, batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(val, batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(t_loss, v_loss, save_location,run_name:str):\n",
    "    lab = \"Learning Curve \"+run_name\n",
    "    font1 = {'family':'serif','color':'darkblue','size':16}\n",
    "    font2 = {'family':'serif','color':'darkblue','size':15}\n",
    "    \n",
    "    plt.plot(range(len(t_loss)), t_loss, label ='Training loss')\n",
    "    plt.plot(range(len(v_loss)), v_loss, label='Validation loss')\n",
    "    plt.title(run_name+\"\\n Learning Curve \", font1)\n",
    "    plt.xlabel('Epochs', font2)\n",
    "    plt.ylabel('Loss', font2)\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    if save_location != None:\n",
    "        plt.savefig(save_location+'/'+lab+'.png') #run_name\n",
    "    else:\n",
    "        print(\"Save Location Not Specified!\")\n",
    "    plt.show()\n",
    "\n",
    "def accuracy_curve(t_accuracy_list, v_accuracy_list, save_location,run_name:str):\n",
    "    lab = \"Accuracy Curve\"+run_name\n",
    "    font1 = {'family':'serif','color':'darkblue','size':16}\n",
    "    font2 = {'family':'serif','color':'darkblue','size':15}\n",
    "\n",
    "    plt.title(run_name+\"\\n Accuracy Curve\", font1)\n",
    "    plt.plot(range(len(t_accuracy_list)), t_accuracy_list, label ='Training accuracy')\n",
    "    plt.plot(range(len(v_accuracy_list)), v_accuracy_list, label='Validation accuracy')\n",
    "    plt.xlabel('Epochs', font2)\n",
    "    plt.ylabel('Accuracy', font2)\n",
    "    plt.legend()\n",
    "    if save_location != None:\n",
    "        plt.savefig(save_location+lab+'.png', format='png')\n",
    "    else:\n",
    "        print(\"Save Location Not Specified!\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_layers = [nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGTest(nn.Module):\n",
    "    def __init__(self, start_index, starting_side, conv_layers, num_classes=11):\n",
    "        super(VGGTest, self).__init__()\n",
    "        self.starting_side = starting_side\n",
    "        self.start_index = start_index\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), ## weight of size [64, 64, 3, 3], expected input[16, 3, 72, 236] \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "\n",
    "        self.conv_layers = [self.layer1,self.layer2,self.layer3,self.layer4,self.layer5,self.layer6,self.layer7,self.layer8,self.layer9,self.layer10,self.layer11,self.layer12,self.layer13]\n",
    "        \n",
    "        self.linear_layer_dimensions = [7168, 28672, 28672, 28672, 133632, 133632,66816 ,135936, 135936, 271872, 135936, 543744, 271872] #271872 #271872 #66816\n",
    "        #self.linear_layer_dimensions = [135936,135936,135936,135936,135936,135936,135936,135936,135936,135936,135936,135936,135936]\n",
    "        #                                  16x135936 and 271872x4096) ##16x135936 and 271872x4096)\n",
    "        self.lin_lay_dim = 0                  #(16x135936 and 271872x4096)\n",
    "        if starting_side == \"front\":\n",
    "            self.lin_lay_dim = start_index\n",
    "        else:\n",
    "            self.lin_lay_dim = 13 - start_index\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.linear_layer_dimensions[self.lin_lay_dim], 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        # weight of size [64, 64, 3, 3], expected input[16, 3, 72, 236] \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.starting_side == \"end\":\n",
    "            for i in range(0, self.start_index):\n",
    "                layer = self.conv_layers[i]\n",
    "                if i == 0:\n",
    "                    out = layer(x)\n",
    "                else:\n",
    "                    out = layer(out)\n",
    "\n",
    "        else:\n",
    "            for i in range(self.start_index, 13):\n",
    "                layer = self.conv_layers[i]\n",
    "                #print('start indec: ', self.start_index)\n",
    "                #print('i: ',i)\n",
    "                if i == 1: #0:\n",
    "                    out = layer(x)\n",
    "                else:\n",
    "                    out = layer(out)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = out.flatten(start_dim=1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, schedulr, optimizer, criterion, layer_size, starting_side, epochs):\n",
    "    epoch_number = 0\n",
    "    EPOCHS = epochs\n",
    "    best_vloss = 1_000_000.\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    tr_accuracy_list = []\n",
    "    val_accuracy_list = []\n",
    "    #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    #print(\" tm 1 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    \n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        tr_num_correct = 0\n",
    "        val_num_correct = 0\n",
    "        \n",
    "        print('EPOCH {}:'.format(epoch_number + 1))\n",
    "        training_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "        #print(\" tm 2 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "        #avg_loss = train_one_epoch(epoch_number, writer)\n",
    "        for i, data in enumerate(dataloaders['train'], 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "\n",
    "            #print('inputs shape: ', inputs.shape)\n",
    "            sample = True\n",
    "            #if sample == True:\n",
    "            #    if epoch ==1:\n",
    "            #        IP = ImageProcessor(mps_device)\n",
    "            #        print(inputs[1][0].shape)\n",
    "            #        IP.view(inputs[1], 5,loop_run_name =\"string\", save_dict= None,  epoch = epoch, where = \"train\")\n",
    "            #        sample = False\n",
    "            #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "            #print(\" tm 3 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            # accuracy\n",
    "            for i in range(len(labels)-1):\n",
    "                if labels[i].argmax() == outputs[i].argmax():\n",
    "                    tr_num_correct +=1\n",
    "                \n",
    "\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 2000 mini-batches\n",
    "                training_loss = running_loss / 10 # loss per batch\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}') ###***\n",
    "                running_loss = 0.0\n",
    "\n",
    "        running_vloss = 0.0\n",
    "        model.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(dataloaders['val']):\n",
    "                vinputs, vlabels = vdata\n",
    "                vlabels = vlabels.to(mps_device)\n",
    "                voutputs = model(vinputs)\n",
    "                \n",
    "                for i in range(len(vlabels)-1):\n",
    "                    if vlabels[i].argmax() == voutputs[i].argmax():\n",
    "                        val_num_correct +=1\n",
    "                    \n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss\n",
    "                \n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(training_loss, avg_vloss))\n",
    "\n",
    "        losses.append(training_loss)\n",
    "        val_losses.append(avg_vloss.item())\n",
    "        \n",
    "        tr_acc = tr_num_correct/len(labels)\n",
    "        tr_accuracy = 100*(tr_acc)\n",
    "        tr_accuracy_list.append(tr_accuracy)\n",
    "\n",
    "        val_acc = val_num_correct/len(vlabels)\n",
    "        val_accuracy = 100*(val_acc)\n",
    "        val_accuracy_list.append(val_accuracy)\n",
    "\n",
    "        epoch_number += 1\n",
    "        schedulr.step()\n",
    "\n",
    "    learning_curve(losses, val_losses, save_loc, starting_side+\"\"+layer_size)\n",
    "    accuracy_curve(val_accuracy_list, tr_accuracy_list,  save_loc, starting_side+\"\"+layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "def save2csv(nested_dict, file_name, save_location:str):\n",
    "    columns = list(nested_dict.keys())\n",
    "    path = os.path.join(save_location, file_name +\".csv\")\n",
    "    try:\n",
    "        with open(path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            # using dictwriter\n",
    "            # using writeheader function\n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(nested_dict)\n",
    "            f.close()\n",
    "    except IOError as e:\n",
    "        print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "    except ValueError:\n",
    "              print(\"could not convert to string\")\n",
    "    except:\n",
    "              print(\"unexpected error: \", sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloaders):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['test']:\n",
    "            images, labels = data\n",
    "            images = images.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "            count += len(images)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "    print(f'Accuracy of the network on the {count} test images: {100 * correct // total} %')\n",
    "    return accuracy\n",
    "\n",
    "def test_model_train(model, dataloaders):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['train']:\n",
    "            images, labels = data\n",
    "            images = images.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "            count += len(images)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "    print(f'Accuracy of the network on the {count} train images: {100 * correct // total} %')\n",
    "    return accuracy\n",
    "\n",
    "def test_model_validation(model, dataloaders):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['val']:\n",
    "            images, labels = data\n",
    "            images = images.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "            count += len(images)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "    print(f'Accuracy of the network on the {count} validation images: {100 * correct // total} %')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%| | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.0 valid 1.9072492122650146\n",
      "EPOCH 2:\n",
      "LOSS train 0.0 valid 1.4585083723068237\n",
      "EPOCH 3:\n",
      "LOSS train 0.0 valid 1.0477192401885986\n",
      "EPOCH 4:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "front_accuracies = []\n",
    "end_accuracies = []\n",
    "epochs = 5\n",
    "timestamp = datetime.now().strftime('%d%m%Y')\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(12, 1, -1)): #12\n",
    "    #print(\"1 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    model_testing_layer_size = VGGTest(start_index=i, starting_side=\"end\", conv_layers=convolution_layers)\n",
    "    #print(\"1.1 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    model_testing_layer_size = model_testing_layer_size.to(mps_device)\n",
    "    #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    #print(\" 2 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_testing_layer_size.parameters(), lr=1.00E-05, weight_decay= 4e-5)\n",
    "    schedulr = sch.ExponentialLR(optimizer, gamma=0.9)\n",
    "    #print(\" 2.2 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    train_model(model_testing_layer_size, dataloaders, schedulr, optimizer, criterion, str(i), \"End\", epochs)\n",
    "    #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    #print(\"3 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    #end_accuracies.append(test_model(model_testing_layer_size, dataloaders))\n",
    "\n",
    "    results_to_csv = {\n",
    "        \"Starting Side\": \"End\",\n",
    "        \"Layer Size\" : str(i),\n",
    "        \"Epoch\": epochs,\n",
    "        \"Loss\" : \"Cross Entropy Loss\",\n",
    "        \"Optimizer\" : \"Adam\",\n",
    "        \"Learning Rate\": \"1.00E-05\",\n",
    "        \"Wieght Decay\": \"4e-5\",\n",
    "        \"Scheduler\": \"ExponentialLR\",\n",
    "        \"Gamma\": \"0.9\",\n",
    "        \"Train Accuracy\": str(test_model_train(model_testing_layer_size, dataloaders)),\n",
    "        \"Validation Accuracy\": str(test_model_validation(model_testing_layer_size, dataloaders)),\n",
    "        \"Test Accuracy\": str(test_model(model_testing_layer_size, dataloaders)),\n",
    "    }\n",
    "\n",
    "    save2csv(results_to_csv,\"ModelResults_{}\".format(timestamp), save_loc) #antvis/antvis/optics/Kemal/saves\n",
    "    torch.cuda.empty_cache()\n",
    "    #clear_output()\n",
    "    \n",
    "    #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    #print(\"4 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    del model_testing_layer_size\n",
    "\n",
    "\"\"\"\n",
    "for i in range(1, 12):\n",
    "    model_testing_layer_size = VGGTest(start_index=i, starting_side=\"front\", conv_layers=convolution_layers)\n",
    "    model_testing_layer_size = model_testing_layer_size.to(mps_device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_testing_layer_size.parameters(), lr=1.00E-05, weight_decay= 4e-5)\n",
    "    schedulr = sch.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    train_model(model_testing_layer_size, dataloaders, schedulr, optimizer, criterion, str(13 - i), \"Front\", epochs)\n",
    "\n",
    "    #front_accuracies.append(test_model(model_testing_layer_size, dataloaders))\n",
    "\n",
    "    results_to_csv = {\n",
    "        \"Starting Side\": \"Front\",\n",
    "        \"Layer Size\" : str(i),\n",
    "        \"Epoch\": epochs,\n",
    "        \"Loss\" : \"Cross Entropy Loss\",\n",
    "        \"Optimizer\" : \"Adam\",\n",
    "        \"Learning Rate\": \"1.00E-05\",\n",
    "        \"Wieght Decay\": \"4e-5\",\n",
    "        \"Scheduler\": \"ExponentialLR\",\n",
    "        \"Gamma\": \"0.9\",\n",
    "        \"Train Accuracy\": str(test_model_train(model_testing_layer_size, dataloaders)),\n",
    "        \"Validation Accuracy\": str(test_model_validation(model_testing_layer_size, dataloaders)),\n",
    "        \"Test Accuracy\": str(test_model(model_testing_layer_size, dataloaders)),\n",
    "    }\n",
    "\n",
    "    save2csv(results_to_csv,\"ModelResults_{}\".format(timestamp), save_loc)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"4 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    del model_testing_layer_size\n",
    "    \n",
    "    clear_output()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {'a':1, 'b':2, 'c':3}\n",
    "\n",
    "save2csv(di,\"testing\".format(timestamp), r\"/its/home/nn268/antvis/antvis/optics/Kemal/saves/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing batch size made no difference\n",
    "added a flatten(start_dim=1)\n",
    "\n",
    "added memory prints\n",
    "\n",
    "changed some values in self.linear_layer_dimension list\n",
    "\n",
    "\n",
    "changed save location, device type and data path\n",
    "\n",
    "\n",
    "\n",
    "Added a print of images, just to check the images are processed correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24/04/24\n",
    "\n",
    "edited learning curve to include the save location so that the files are saved\n",
    "edited to include the accuracies per epoch and the function to graph them\n",
    "\n",
    "edited the dict that goes into a csv to include a column that states which end the layers are removed from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
