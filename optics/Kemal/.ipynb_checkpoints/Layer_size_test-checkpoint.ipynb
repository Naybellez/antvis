{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 10:48:51.369843: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-22 10:48:51.417957: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-22 10:48:51.417992: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-22 10:48:51.419427: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-22 10:48:51.426635: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-22 10:48:52.438962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import torch.optim.lr_scheduler as sch\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm \n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "from functions import ImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "\n",
    "data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "\n",
    "save_loc = r\"/its/home/nn268/antvis/antvis/optics/Kemal/saves/with13/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptrblk_fin_mod_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    size_all_gb = size_all_mb/953.674\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))\n",
    "    print('model size: {:.3f}GB'.format(size_all_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"#'cpu'# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(directory_path):\n",
    "\n",
    "    data_directory_path = directory_path \n",
    "    data_file_path = []\n",
    "    labels = []\n",
    "\n",
    "    directory = os.fsencode(data_directory_path)\n",
    "        \n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename[:4]== 'IDSW':\n",
    "            data_file_path.append(data_directory_path+\"/\"+filename)\n",
    "            #print(filename[5:7])\n",
    "            labels.append(int(filename[5:7])- 1)\n",
    "\n",
    "    return data_file_path, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(image_paths, labels, seed):\n",
    "\n",
    "    x_remainder_train, test_data, y_remainder_train, test_labels = train_test_split(image_paths, labels, test_size=0.3, random_state=seed)\n",
    "    train_data, validation_data, train_labels, validation_labels = train_test_split(x_remainder_train, y_remainder_train, test_size=0.1, random_state=seed)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels, validation_data, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img, pad_size):\n",
    "\t\tleft_x = img[:,:pad_size,:] # h, w, c\n",
    "\t\tright_x = img[:,-pad_size:,:]\n",
    "\t\ty = img.shape[0]\n",
    "\t\tx = img.shape[1]+(pad_size*2)\n",
    "\t\tnew_x = np.full((y, x, 3),255) # h w c\n",
    "\t\tnew_x[:,:pad_size,:] = right_x\n",
    "\t\tnew_x[:,pad_size:-pad_size,:] = img\n",
    "\t\tnew_x[:,-pad_size:,:] = left_x\n",
    "\t\treturn new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(image_paths):\n",
    "\n",
    "    processed_images = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        resized_img = cv2.resize(img, (226, 72))\n",
    "        processed_img = padding(resized_img, 5)\n",
    "        im_chan = processed_img.shape[2]\n",
    "        imgY, imgX = processed_img.shape[0], processed_img.shape[1]\n",
    "        processed_img_tensor = torch.tensor(processed_img, device=mps_device, dtype = torch.float32)\n",
    "        normalized_tensor = torch.nn.functional.normalize(processed_img_tensor) \n",
    "        permuted_tensor = normalized_tensor.permute(2, 0, 1)\n",
    "\n",
    "        tensor = permuted_tensor.reshape(im_chan, imgY, imgX)\n",
    "        tensor.to(mps_device)\n",
    "        processed_images.append(tensor)\n",
    "\n",
    "    return processed_images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = random.seed(1)\n",
    "image_paths, labels = get_data(data_path)\n",
    "train_data, train_labels, test_data, test_labels, validation_data, validation_labels = train_test_validation_split(image_paths,labels,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = image_processing(train_data)\n",
    "test_data = image_processing(test_data)\n",
    "validation_data = image_processing(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #16 #32\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "val = []\n",
    "\n",
    "for i, data in enumerate(train_data):\n",
    "    train.append((data, train_labels[i]))\n",
    "\n",
    "for i, data in enumerate(test_data):\n",
    "    test.append((data, test_labels[i]))\n",
    "\n",
    "for i, data in enumerate(validation_data):\n",
    "    val.append((data, validation_labels[i]))\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train, batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(val, batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(t_loss, v_loss, save_location,run_name:str):\n",
    "    lab = \"Learning Curve \"+run_name\n",
    "    font1 = {'family':'serif','color':'darkblue','size':16}\n",
    "    font2 = {'family':'serif','color':'darkblue','size':15}\n",
    "    \n",
    "    plt.plot(range(len(t_loss)), t_loss, label ='Training loss')\n",
    "    plt.plot(range(len(v_loss)), v_loss, label='Validation loss')\n",
    "    plt.title(run_name+\"\\n Learning Curve \", font1)\n",
    "    plt.xlabel('Epochs', font2)\n",
    "    plt.ylabel('Loss', font2)\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    if save_location != None:\n",
    "        plt.savefig(save_location+'/'+lab+'.png') #run_name\n",
    "    else:\n",
    "        print(\"Save Location Not Specified!\")\n",
    "    plt.show()\n",
    "\n",
    "def accuracy_curve(t_accuracy_list, v_accuracy_list, save_location,run_name:str):\n",
    "    lab = \"Accuracy Curve\"+run_name\n",
    "    font1 = {'family':'serif','color':'darkblue','size':16}\n",
    "    font2 = {'family':'serif','color':'darkblue','size':15}\n",
    "\n",
    "    plt.title(run_name+\"\\n Accuracy Curve\", font1)\n",
    "    plt.plot(range(len(t_accuracy_list)), t_accuracy_list, label ='Training accuracy')\n",
    "    plt.plot(range(len(v_accuracy_list)), v_accuracy_list, label='Validation accuracy')\n",
    "    plt.xlabel('Epochs', font2)\n",
    "    plt.ylabel('Accuracy', font2)\n",
    "    plt.legend()\n",
    "    if save_location != None:\n",
    "        plt.savefig(save_location+lab+'.png', format='png')\n",
    "    else:\n",
    "        print(\"Save Location Not Specified!\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_layers = [nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGTest(nn.Module):\n",
    "    def __init__(self, start_index, starting_side, conv_layers, num_classes=11):\n",
    "        super(VGGTest, self).__init__()\n",
    "        self.starting_side = starting_side\n",
    "        self.start_index = start_index\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), ## weight of size [64, 64, 3, 3], expected input[16, 3, 72, 236] \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "\n",
    "        self.conv_layers = [self.layer1,self.layer2,self.layer3,self.layer4,self.layer5,self.layer6,self.layer7,self.layer8,self.layer9,self.layer10,self.layer11,self.layer12,self.layer13]\n",
    "        #                                1     2      3       4        5     6      7       8       9      10     11     12       13\n",
    "        #                                13     12    11      10      9      8        7     6      5       4       3       2       1 \n",
    "        self.linear_layer_dimensions =[7168, 28672, 28672, 28672, 133632, 133632, 66816, 271872, 271872, 135936, 543744, 271872]# [7168, 28672, 28672, 28672, 133632, 133632,66816 ,271872, 135936, 135936, 543744, 271872, 1087488] #271872 #271872 #66816\n",
    "        #s (16x271872 and 543744x4096)\n",
    "        #                               :32x28672 and 133632x4096)\n",
    "        self.outchan = [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]\n",
    "        self.lin_lay_dim = 0                  #(16x135936 and 271872x4096) (16x1087488 and 271872x4096)\n",
    "        if starting_side == \"front\":\n",
    "            self.lin_lay_dim =(start_index) +1 #-1# +1\n",
    "            print(self.linear_layer_dimensions[self.lin_lay_dim])\n",
    "        else:\n",
    "            self.lin_lay_dim = 13 - start_index\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.linear_layer_dimensions[self.lin_lay_dim], 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        # weight of size [64, 64, 3, 3], expected input[16, 3, 72, 236] \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.starting_side == \"end\":\n",
    "            for i in range(0, self.start_index):\n",
    "                layer = self.conv_layers[i]\n",
    "                if i == 0:\n",
    "                    out = layer(x)\n",
    "                else:\n",
    "                    out = layer(out)\n",
    "\n",
    "        else:\n",
    "            mp=[2,4,7,10,13]\n",
    "            \n",
    "            for i in range(self.start_index, 13): \n",
    "                #if i== self.start_index:\n",
    "                    #print(\"i in range start index to 13: \", i)\n",
    "                self.start_conv1 = nn.Sequential(\n",
    "                    nn.Conv2d(3, self.outchan[i],kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(self.outchan[i]),\n",
    "                    nn.ReLU())\n",
    "            \n",
    "                self.start_conv2 = nn.Sequential(\n",
    "                    nn.Conv2d(3, self.outchan[i],kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(self.outchan[i]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "                layer = self.conv_layers[i]\n",
    "                #if i== self.start_index:\n",
    "                    #print(\"conv layer i:  \", layer)\n",
    "                #print('start indec: ', self.start_index)\n",
    "                #print('i: ',i)\n",
    "                if i == self.start_index: #0: #local variable 'out' referenced before assignment -- changing 1 to 0. didn't work, changing to start_index\n",
    "                    if i in mp:\n",
    "                        out= self.start_conv2(x)\n",
    "                    else:\n",
    "                        out= self.start_conv1(x)\n",
    "                    #out = layer(x)\n",
    "                else:\n",
    "                    out = layer(out)\n",
    "        print(out.shape)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        print(out.shape)\n",
    "        out = out.flatten(start_dim=1)\n",
    "        print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, schedulr, optimizer, criterion, layer_size, starting_side, epochs):\n",
    "    epoch_number = 0\n",
    "    EPOCHS = epochs\n",
    "    best_vloss = 1_000_000.\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    tr_accuracy_list = []\n",
    "    val_accuracy_list = []\n",
    "    #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    #print(\" tm 1 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    \n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        tr_num_correct = 0\n",
    "        val_num_correct = 0\n",
    "        \n",
    "        print('EPOCH {}:'.format(epoch_number + 1))\n",
    "        training_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "        #print(\" tm 2 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "        #avg_loss = train_one_epoch(epoch_number, writer)\n",
    "        for i, data in enumerate(dataloaders['train'], 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "\n",
    "            #print('inputs shape: ', inputs.shape)\n",
    "            sample = True\n",
    "            #if sample == True:\n",
    "            #    if epoch ==1:\n",
    "            #        IP = ImageProcessor(mps_device)\n",
    "            #        print(inputs[1][0].shape)\n",
    "            #        IP.view(inputs[1], 5,loop_run_name =\"string\", save_dict= None,  epoch = epoch, where = \"train\")\n",
    "            #        sample = False\n",
    "            #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "            #print(\" tm 3 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            # accuracy\n",
    "            for i in range(len(labels)-1):\n",
    "                if labels[i].argmax() == outputs[i].argmax():\n",
    "                    tr_num_correct +=1\n",
    "                \n",
    "\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 2000 mini-batches\n",
    "                training_loss = running_loss / 10 # loss per batch\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}') ###***\n",
    "                running_loss = 0.0\n",
    "\n",
    "        running_vloss = 0.0\n",
    "        model.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(dataloaders['val']):\n",
    "                vinputs, vlabels = vdata\n",
    "                vlabels = vlabels.to(mps_device)\n",
    "                voutputs = model(vinputs)\n",
    "                \n",
    "                for i in range(len(vlabels)-1):\n",
    "                    if vlabels[i].argmax() == voutputs[i].argmax():\n",
    "                        val_num_correct +=1\n",
    "                    \n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss\n",
    "                \n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(training_loss, avg_vloss))\n",
    "\n",
    "        losses.append(training_loss)\n",
    "        val_losses.append(avg_vloss.item())\n",
    "        \n",
    "        tr_acc = tr_num_correct/len(labels)\n",
    "        tr_accuracy = 100*(tr_acc)\n",
    "        tr_accuracy_list.append(tr_accuracy)\n",
    "\n",
    "        val_acc = val_num_correct/len(vlabels)\n",
    "        val_accuracy = 100*(val_acc)\n",
    "        val_accuracy_list.append(val_accuracy)\n",
    "\n",
    "        epoch_number += 1\n",
    "        schedulr.step()\n",
    "\n",
    "    learning_curve(losses, val_losses, save_loc, starting_side+\"\"+layer_size)\n",
    "    accuracy_curve(val_accuracy_list, tr_accuracy_list,  save_loc, starting_side+\"\"+layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "def save2csv(nested_dict, file_name, save_location:str):\n",
    "    columns = list(nested_dict.keys())\n",
    "    path = os.path.join(save_location, file_name +\".csv\")\n",
    "    try:\n",
    "        with open(path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            # using dictwriter\n",
    "            # using writeheader function\n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(nested_dict)\n",
    "            f.close()\n",
    "    except IOError as e:\n",
    "        print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "    except ValueError:\n",
    "              print(\"could not convert to string\")\n",
    "    except:\n",
    "              print(\"unexpected error: \", sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloaders):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['test']:\n",
    "            images, labels = data\n",
    "            images = images.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "            count += len(images)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "    print(f'Accuracy of the network on the {count} test images: {100 * correct // total} %')\n",
    "    return accuracy\n",
    "\n",
    "def test_model_train(model, dataloaders):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['train']:\n",
    "            images, labels = data\n",
    "            images = images.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "            count += len(images)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "    print(f'Accuracy of the network on the {count} train images: {100 * correct // total} %')\n",
    "    return accuracy\n",
    "\n",
    "def test_model_validation(model, dataloaders):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['val']:\n",
    "            images, labels = data\n",
    "            images = images.to(mps_device)\n",
    "            labels = labels.to(mps_device)\n",
    "            count += len(images)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "    print(f'Accuracy of the network on the {count} validation images: {100 * correct // total} %')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRONT         2\n",
      "28672\n",
      "EPOCH 1:\n",
      "torch.Size([32, 512, 2, 7])\n",
      "torch.Size([32, 7168])\n",
      "torch.Size([32, 7168])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x7168 and 28672x4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_testing_layer_size\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.00E-05\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4e-5\u001b[39m)\n\u001b[1;32m     58\u001b[0m schedulr \u001b[38;5;241m=\u001b[39m sch\u001b[38;5;241m.\u001b[39mExponentialLR(optimizer, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_testing_layer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedulr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFront\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#front_accuracies.append(test_model(model_testing_layer_size, dataloaders))\u001b[39;00m\n\u001b[1;32m     64\u001b[0m results_to_csv \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Side\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFront\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer Size\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28mstr\u001b[39m(i),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(test_model(model_testing_layer_size, dataloaders)),\n\u001b[1;32m     77\u001b[0m }\n",
      "Cell \u001b[0;32mIn[15], line 49\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, schedulr, optimizer, criterion, layer_size, starting_side, epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# accuracy\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[79], line 133\u001b[0m, in \u001b[0;36mVGGTest.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 133\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(out)\n\u001b[1;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(out)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x7168 and 28672x4096)"
     ]
    }
   ],
   "source": [
    "\n",
    "front_accuracies = []\n",
    "end_accuracies = []\n",
    "epochs = 1\n",
    "timestamp = datetime.now().strftime('%d%m%Y')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for i in tqdm(range(2, 0, -1)): #13\n",
    "    print(\"starting index:  \",i)\n",
    "    #print(\"1 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    model_testing_layer_size = VGGTest(start_index=i, starting_side=\"end\", conv_layers=convolution_layers)\n",
    "    #print(\"1.1 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    model_testing_layer_size = model_testing_layer_size.to(mps_device)\n",
    "    #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    #print(\" 2 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_testing_layer_size.parameters(), lr=1.00E-05, weight_decay= 4e-5)\n",
    "    schedulr = sch.ExponentialLR(optimizer, gamma=0.9)\n",
    "    #print(\" 2.2 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    train_model(model_testing_layer_size, dataloaders, schedulr, optimizer, criterion, str(i), \"End\", epochs)\n",
    "    #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    #print(\"3 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    #end_accuracies.append(test_model(model_testing_layer_size, dataloaders))\n",
    "\n",
    "    results_to_csv = {\n",
    "        \"Starting Side\": \"End\",\n",
    "        \"Layer Size\" : str(i),\n",
    "        \"Epoch\": epochs,\n",
    "        \"Loss\" : \"Cross Entropy Loss\",\n",
    "        \"Optimizer\" : \"Adam\",\n",
    "        \"Learning Rate\": \"1.00E-05\",\n",
    "        \"Wieght Decay\": \"4e-5\",\n",
    "        \"Scheduler\": \"ExponentialLR\",\n",
    "        \"Gamma\": \"0.9\",\n",
    "        \"Train Accuracy\": str(test_model_train(model_testing_layer_size, dataloaders)),\n",
    "        \"Validation Accuracy\": str(test_model_validation(model_testing_layer_size, dataloaders)),\n",
    "        \"Test Accuracy\": str(test_model(model_testing_layer_size, dataloaders)),\n",
    "    }\n",
    "\n",
    "    save2csv(results_to_csv,\"ModelResults_{}\".format(timestamp), save_loc) #antvis/antvis/optics/Kemal/saves\n",
    "    torch.cuda.empty_cache()\n",
    "    #clear_output()\n",
    "    \n",
    "    #ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    #print(\"4 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "    del model_testing_layer_size\n",
    "\"\"\"\n",
    "\n",
    "for i in range(1, 13):\n",
    "    print('FRONT        ', i)\n",
    "    model_testing_layer_size = VGGTest(start_index=i, starting_side=\"front\", conv_layers=convolution_layers)\n",
    "    model_testing_layer_size = model_testing_layer_size.to(mps_device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_testing_layer_size.parameters(), lr=1.00E-05, weight_decay= 4e-5)\n",
    "    schedulr = sch.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    train_model(model_testing_layer_size, dataloaders, schedulr, optimizer, criterion, str(13 - i), \"Front\", epochs)\n",
    "\n",
    "    #front_accuracies.append(test_model(model_testing_layer_size, dataloaders))\n",
    "\n",
    "    results_to_csv = {\n",
    "        \"Starting Side\": \"Front\",\n",
    "        \"Layer Size\" : str(i),\n",
    "        \"Epoch\": epochs,\n",
    "        \"Loss\" : \"Cross Entropy Loss\",\n",
    "        \"Optimizer\" : \"Adam\",\n",
    "        \"Learning Rate\": \"1.00E-05\",\n",
    "        \"Wieght Decay\": \"4e-5\",\n",
    "        \"Scheduler\": \"ExponentialLR\",\n",
    "        \"Gamma\": \"0.9\",\n",
    "        \"Train Accuracy\": str(test_model_train(model_testing_layer_size, dataloaders)),\n",
    "        \"Validation Accuracy\": str(test_model_validation(model_testing_layer_size, dataloaders)),\n",
    "        \"Test Accuracy\": str(test_model(model_testing_layer_size, dataloaders)),\n",
    "    }\n",
    "\n",
    "    save2csv(results_to_csv,\"TEST_ModelResults_{}\".format(timestamp), save_loc)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"4 Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "    ptrblk_fin_mod_size(model_testing_layer_size)\n",
    "    del model_testing_layer_size\n",
    "    \n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {'a':1, 'b':2, 'c':3}\n",
    "\n",
    "save2csv(di,\"testing\".format(timestamp), r\"/its/home/nn268/antvis/antvis/optics/Kemal/saves/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing batch size made no difference\n",
    "added a flatten(start_dim=1)\n",
    "\n",
    "added memory prints\n",
    "\n",
    "changed some values in self.linear_layer_dimension list\n",
    "\n",
    "\n",
    "changed save location, device type and data path\n",
    "\n",
    "\n",
    "\n",
    "Added a print of images, just to check the images are processed correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24/04/24\n",
    "\n",
    "edited learning curve to include the save location so that the files are saved\n",
    "edited to include the accuracies per epoch and the function to graph them\n",
    "\n",
    "edited the dict that goes into a csv to include a column that states which end the layers are removed from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Run 3. finding out why and what was changed for the code to run. all parameters and layer numbers are Kemal's\n",
    "\n",
    " END runs fine\n",
    "\n",
    " FRONT - list index out of range for:\n",
    "  else:\n",
    "            for i in range(self.start_index, 13): \n",
    "                layer = self.conv_layers[i]\n",
    "                #print('start indec: ', self.start_index)\n",
    "                #print('i: ',i)\n",
    "                if i == 0: #0: #local variable 'out' referenced before assignment -- changing 1 to 0\n",
    "                    out = layer(x)\n",
    "                else:\n",
    "                    out = layer(out)\n",
    "\n",
    "Changed the original '1' to a '0' - did not work for start_index outside of 0.\n",
    "change the '1' to 'self.start_index'\n",
    "error:\n",
    " Given groups=1, weight of size [64, 64, 3, 3], expected input[32, 3, 72, 236] to have 64 channels, but got 3 channels instead\n",
    "\n",
    "\n",
    "^ this ws the reason for the 'starting convolutional sequential block', to create a convolutional layer that has the expected input of 3 channels, and outputs the expected size of the n+1th block.\n",
    "\n",
    "\n",
    "\n",
    "240524\n",
    "\n",
    "error:: mat1 and mat2 shapes cannot be multiplied (32x7168 and 28672x4096)\n",
    "thoughts- this is an indexing issue. probably my brain not thinking right.\n",
    "so, we are sequentially going through layers using i in range to index.\n",
    "we start at layer x.\n",
    "start_index states the layer to start at - layer 0, 1... 12 (13 layers, 0-12 =13)\n",
    "if i == start_layer: # say 0\n",
    "    custom layer\n",
    "i +=1 # say 1\n",
    "layer[i] # should be layer 1 (index 1, so second layer). we skip over custom layer which iage has just been through, custom layer should output the size layer[i] is expecting.\n",
    "\n",
    "but - the error we are getting does not fit this.\n",
    "7168 is the size \n",
    "\n",
    "\n",
    "\n",
    "we have two lists             \n",
    "self.linear_layer_dimensions =[7168, 28672, 28672, 28672, 133632, 133632, 66816, 271872, 271872, 135936, 543744, 271872] # len 12\n",
    "self.outchan =                [64,     64,   128,   128,    256,    256,   256,    512,    512,    512,    512,    512,  512] # len 13\n",
    "#                             7168, 28672, 28672, 28672, 133632, 133632, 66816, 271872, 271872, 135936, 543744, 271872]# double checking with kemal's original code sent over. there are 12. ###  (32x28672 and 7168x4096)\n",
    "linear layer block inpuit\n",
    "and the outputs of each layer\n",
    "\n",
    "right so,\n",
    "lin layers- there are 12. I have 13 outchans.\n",
    "outchan[i+1] ##\n",
    "\n",
    "\n",
    " with outchan[i]\n",
    "#            (32x133632 and 28672x4096)\n",
    "with adding 1 to index of linear layer di\n",
    "#             32x133632 and 28672x4096)\n",
    "\n",
    "with outchan[i+1]\n",
    ": Given groups=1, weight of size [256, 128, 3, 3], expected input[32, 256, 72, 236] to have 128 channels, but got 256 channels instead\n",
    "\n",
    "\n",
    "Seems to be working with a addition of a +1 for selecting self.linlay_dim:\n",
    "if starting_side == \"front\":\n",
    "            self.lin_lay_dim =( start_index)\n",
    "# changed to to\n",
    "if starting_side == \"front\":\n",
    "            self.lin_lay_dim =( start_index) +1\n",
    "\n",
    "\n",
    "#### worked for start_idex = 3\n",
    "not for 4\n",
    "RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x28672 and 133632x4096)\n",
    "# (32x28672 and 133632x4096)\n",
    "# (32x7168 and 28672x4096)\n",
    "#  (32x133632 and 28672x4096)           28672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
