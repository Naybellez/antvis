{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as maths\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "#from torchsummary import summary\n",
    "#import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import wandb\n",
    "import pprint\n",
    "\n",
    "\n",
    "from functions import import_imagedata, get_data, label_oh_tf,  Unwrap, ImageProcessor, IDSWDataSetLoader\n",
    "from architectures import vgg16net, smallnet1, smallnet2, smallnet3\n",
    "from loop_fns import loop, test_loop\n",
    "from fns4wandb import build_optimizer, set_optimizer, hp_sweep, train_model, train_log, log_test_score, set_lossfn, pipeline\n",
    "\n",
    "from architectures import build_net, smallnet3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config = {\\n    \\'method\\': \\'random\\',\\n    \\'metric\\':{\\n        \\'goal\\': \\'minimize\\',\\n        \\'name\\': \\'val_loss\\'},\\n    \\'parameters\\': {\\n        #\\'dropout\\':{\\n        #    \\'values\\': [0.5, 0.4, 0.3]\\n        #},\\n        \\'weight_decay\\':{\\n            \\'values\\': [1e-5,2e-5, 3e-5,4e-5]\\n        },\\n        \\'epochs\\':{\\n            \\'value\\': 3\\n        },\\n        \\'lin_layer_size\\': {\\n            \\'values\\': [100] #, 150, 50\\n        },\\n        \\'first_lin_lay\\':{\\n            \\'values\\':[248832]\\n        },\\n        \\'optimizer\\': {\\n            \\'values\\': [\\'adam\\']\\n        },\\n            \\'learning_rate\\': {\\n                # a flat distribution between 0 and 0.1\\n                \\'distribution\\': \\'log_uniform_values\\',\\n                \\'min\\': 1e-5,\\n                \\'max\\': 1e-2\\n            },\\n        \\'loss_fn\\': {\\n            \\'values\\': [\\'CrossEntropy\\'] #\\'MSE\\', \\n        },\\n        \\'data_set\\':{\\n            \\'values\\':[\\'Augmented\\']\\n        },\\n            \\'scheduler\\': {\\n            \\'values\\': [0.1, 0.01, 0.001]\\n        },\\n        \\'ks\\': {\\n            \\'values\\': [(3,5)]\\n        },\\n        \\'dropout\\':{\\n            \\'values\\': [0.5, 0.4, 0.3, 0.2, 0.7]\\n        },\\n        \\'channels\\':{\\n            \\'values\\': [3]\\n        },\\n        \\'num_classes\\': {\\n            \\'values\\': [11]\\n        },\\n        \\'model_name\\' : {\\'values\\': [\\'vgg16net\\']},\\n        \\'channels\\' : {\\'values\\': [3]},\\n        \\'image_path\\': {\\n            \\'values\\': [r\\'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/\\']\\n        },\\n        }\\n    }\\n\\ncol_dict = {\\n    \\'colour\\': \\'colour\\',\\n    \\'size\\': [452,144],\\n    \\'padding\\': 5\\n}\\n\\ntitle = f\\'BATCHTEST_IDSW_7c3l_150_122023\\'\\nsave_dict = {\\'Run\\' : title,\\n            \\'Current_Epoch\\': 0,\\n            \\'save_location\\' : r\\'pickles/\\'}\\n#pickles\\n\\n\\nsweep_id = wandb.sweep(config, project=f\"modelSize_7conv3lin_IDSW_{col_dict[\\'colour\\']}_{col_dict[\\'size\\']}_{col_dict[\\'padding\\']}\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"config = {\n",
    "    'method': 'random',\n",
    "    'metric':{\n",
    "        'goal': 'minimize',\n",
    "        'name': 'val_loss'},\n",
    "    'parameters': {\n",
    "        #'dropout':{\n",
    "        #    'values': [0.5, 0.4, 0.3]\n",
    "        #},\n",
    "        'weight_decay':{\n",
    "            'values': [1e-5,2e-5, 3e-5,4e-5]\n",
    "        },\n",
    "        'epochs':{\n",
    "            'value': 3\n",
    "        },\n",
    "        'lin_layer_size': {\n",
    "            'values': [100] #, 150, 50\n",
    "        },\n",
    "        'first_lin_lay':{\n",
    "            'values':[248832]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam']\n",
    "        },\n",
    "            'learning_rate': {\n",
    "                # a flat distribution between 0 and 0.1\n",
    "                'distribution': 'log_uniform_values',\n",
    "                'min': 1e-5,\n",
    "                'max': 1e-2\n",
    "            },\n",
    "        'loss_fn': {\n",
    "            'values': ['CrossEntropy'] #'MSE', \n",
    "        },\n",
    "        'data_set':{\n",
    "            'values':['Augmented']\n",
    "        },\n",
    "            'scheduler': {\n",
    "            'values': [0.1, 0.01, 0.001]\n",
    "        },\n",
    "        'ks': {\n",
    "            'values': [(3,5)]\n",
    "        },\n",
    "        'dropout':{\n",
    "            'values': [0.5, 0.4, 0.3, 0.2, 0.7]\n",
    "        },\n",
    "        'channels':{\n",
    "            'values': [3]\n",
    "        },\n",
    "        'num_classes': {\n",
    "            'values': [11]\n",
    "        },\n",
    "        'model_name' : {'values': ['vgg16net']},\n",
    "        'channels' : {'values': [3]},\n",
    "        'image_path': {\n",
    "            'values': [r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/']\n",
    "        },\n",
    "        }\n",
    "    }\n",
    "\n",
    "col_dict = {\n",
    "    'colour': 'colour',\n",
    "    'size': [452,144],\n",
    "    'padding': 5\n",
    "}\n",
    "\n",
    "title = f'BATCHTEST_IDSW_7c3l_150_122023'\n",
    "save_dict = {'Run' : title,\n",
    "            'Current_Epoch': 0,\n",
    "            'save_location' : r'pickles/'}\n",
    "#pickles\n",
    "\n",
    "\n",
    "sweep_id = wandb.sweep(config, project=f\"modelSize_7conv3lin_IDSW_{col_dict['colour']}_{col_dict['size']}_{col_dict['padding']}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2726140858.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    first_lin_lay = 248832 #3981312, #248832,\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = dict(\n",
    "    epochs= 80, \n",
    "    learning_rate =3.0779e-5,\n",
    "    dataset= 'IDSW',\n",
    "    architecture ='CNN',\n",
    "    optimizer= 'adam',\n",
    "    weight_decay= 4e-5,\n",
    "    dropout = 0.4,\n",
    "    first_lin_lay = 248832 #3981312, #248832,\n",
    "    lin_layer_size= 100,\n",
    "    ks = (3,5),\n",
    "    in_chan = 3,\n",
    "    image_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/',\n",
    "    model_name = 'vgg16net',\n",
    "    channels = 3,\n",
    "    num_classes = 11,\n",
    "    loss_fn = 'CrossEntropy',\n",
    "    scheduler = 0.01\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "col_dict = {\n",
    "    'colour': 'colour',\n",
    "    'size': [452,144],\n",
    "    'padding': 5\n",
    "}\n",
    "\n",
    "title = f'BATCHTEST_IDSW_7c3l_150_122023'\n",
    "save_dict = {'Run' : title,\n",
    "            'Current_Epoch': 0,\n",
    "            'save_location' : r'pickles/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'architecture': 'CNN',\n",
      " 'channels': 3,\n",
      " 'dataset': 'IDSW',\n",
      " 'dropout': 0.4,\n",
      " 'epochs': 80,\n",
      " 'first_lin_lay': 3981312,\n",
      " 'image_path': '/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/',\n",
      " 'in_chan': 3,\n",
      " 'ks': (3, 5),\n",
      " 'learning_rate': 3.0779e-05,\n",
      " 'lin_layer_size': 100,\n",
      " 'loss_fn': 'CrossEntropy',\n",
      " 'model_name': 'vgg16net',\n",
      " 'num_classes': 11,\n",
      " 'optimizer': 'adam',\n",
      " 'scheduler': 0.01,\n",
      " 'weight_decay': 4e-05}\n",
      "<class 'dict'>\n",
      "{'colour': 'colour', 'padding': 5, 'size': [452, 144]}\n",
      "<class 'dict'>\n",
      "colour\n"
     ]
    }
   ],
   "source": [
    "import pprint \n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(config)\n",
    "print(type(config))\n",
    "pp.pprint(col_dict)\n",
    "print(type(col_dict))\n",
    "\n",
    "c = col_dict['colour']\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/its/home/nn268/antvis/antvis/optics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/its/home/nn268/antvis/antvis/optics/wandb/run-20240115_144015-tgj6tqr2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antvis/BATCHTEST_IDSW_7c3l_150_122023/runs/tgj6tqr2' target=\"_blank\">prime-flower-31</a></strong> to <a href='https://wandb.ai/antvis/BATCHTEST_IDSW_7c3l_150_122023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antvis/BATCHTEST_IDSW_7c3l_150_122023' target=\"_blank\">https://wandb.ai/antvis/BATCHTEST_IDSW_7c3l_150_122023</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antvis/BATCHTEST_IDSW_7c3l_150_122023/runs/tgj6tqr2' target=\"_blank\">https://wandb.ai/antvis/BATCHTEST_IDSW_7c3l_150_122023/runs/tgj6tqr2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model, col dict is a <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                               | 0/80 [00:00<?, ?it/s]/its/home/nn268/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "  0%|                               | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre loop, col_dict is a:  <class 'dict'>\n",
      "in loop, col_dict is a:  <class 'dict'> {'colour': 'colour', 'size': [452, 144], 'padding': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/its/home/nn268/antvis/antvis/optics/fns4wandb.py\", line 259, in pipeline\n",
      "    train_model(model, train_loader, val_loader, loss_fn, config, col_dict, device)\n",
      "  File \"/its/home/nn268/antvis/antvis/optics/fns4wandb.py\", line 218, in train_model\n",
      "    t_loss, predict_list, t_num_correct, model, optimizer = loop(model, train_loader, epoch, loss_fn, device, col_dict, config.num_classes, optimizer=optimizer, scheduler=scheduler) #model, x_train, y_train, epoch, loss_fn, device, col_dict, config.num_classes, optimizer=optimizer, scheduler=scheduler\n",
      "  File \"/its/home/nn268/antvis/antvis/optics/loop_fns.py\", line 103, in loop\n",
      "    loss.backward()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacty of 23.65 GiB of which 160.75 MiB is free. Process 29726 has 7.08 GiB memory in use. Including non-PyTorch memory, this process has 16.40 GiB memory in use. Of the allocated memory 14.22 GiB is allocated by PyTorch, and 1.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">prime-flower-31</strong> at: <a href='https://wandb.ai/antvis/BATCHTEST_IDSW_7c3l_150_122023/runs/tgj6tqr2' target=\"_blank\">https://wandb.ai/antvis/BATCHTEST_IDSW_7c3l_150_122023/runs/tgj6tqr2</a><br/> View job at <a href='https://wandb.ai/antvis/BATCHTEST_IDSW_7c3l_150_122023/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyOTA1ODIzNw==/version_details/v8' target=\"_blank\">https://wandb.ai/antvis/BATCHTEST_IDSW_7c3l_150_122023/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyOTA1ODIzNw==/version_details/v8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240115_144015-tgj6tqr2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacty of 23.65 GiB of which 160.75 MiB is free. Process 29726 has 7.08 GiB memory in use. Including non-PyTorch memory, this process has 16.40 GiB memory in use. Of the allocated memory 14.22 GiB is allocated by PyTorch, and 1.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/antvis/antvis/optics/fns4wandb.py:259\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(config, col_dict, title, device, image_file_path)\u001b[0m\n\u001b[1;32m    257\u001b[0m model \u001b[38;5;241m=\u001b[39m choose_model(config)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[1;32m    258\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m set_lossfn(config\u001b[38;5;241m.\u001b[39mloss_fn)\n\u001b[0;32m--> 259\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m test_loop(model, test_loader, device, col_dict, title)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m#train_model(model, x_train, y_train, x_val, y_val, loss_fn, config, col_dict, device)\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m#test_loop(model, x_text, y_test, device, col_dict, title)\u001b[39;00m\n",
      "File \u001b[0;32m~/antvis/antvis/optics/fns4wandb.py:218\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, loss_fn, config, col_dict, device)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mepochs)):            \n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m#train                    \u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre loop, col_dict is a: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m(col_dict))          \u001b[38;5;66;03m#model, loader, epoch, loss_fn, device, col_dict, num_classes, pad_size =5, optimizer =None, scheduler= None, train =True                                    \u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     t_loss, predict_list, t_num_correct, model, optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#model, x_train, y_train, epoch, loss_fn, device, col_dict, config.num_classes, optimizer=optimizer, scheduler=scheduler\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     sample_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x_train)\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# validation\u001b[39;00m\n",
      "File \u001b[0;32m~/antvis/antvis/optics/loop_fns.py:103\u001b[0m, in \u001b[0;36mloop\u001b[0;34m(model, loader, epoch, loss_fn, device, col_dict, num_classes, pad_size, optimizer, scheduler, train)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[1;32m    102\u001b[0m \toptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 103\u001b[0m \t\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \toptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    105\u001b[0m \t\u001b[38;5;66;03m#if display:\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \t\u001b[38;5;66;03m#\tprint('Avatar Kioshi')\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \t\u001b[38;5;66;03m#\tprint_gpu_mem()\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacty of 23.65 GiB of which 160.75 MiB is free. Process 29726 has 7.08 GiB memory in use. Including non-PyTorch memory, this process has 16.40 GiB memory in use. Of the allocated memory 14.22 GiB is allocated by PyTorch, and 1.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model= pipeline(config, col_dict, title, device, image_file_path= r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"def tr(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model = hp_sweep(config, col_dict, save_dict, device)\n",
    "\n",
    "wandb.agent(sweep_id, tr, count=2)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
