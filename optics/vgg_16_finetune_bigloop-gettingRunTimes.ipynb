{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4fd19-5a09-4232-bdc4-42bbef0b6802",
   "metadata": {},
   "source": [
    "last updated 11 03 24\n",
    "\n",
    "This notebook is to get the run times for each model on the highest and lowest resolutions; to estimate an average run time.IG DICITONARY!\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6be64f-3efe-4c20-885c-1333846ffbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6dbd95-2129-42b5-b70b-ee9f057b24c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from functions import import_imagedata, ImageProcessor, label_oh_tf\n",
    "from fns4wandb import  set_lossfn\n",
    "from architectures import sevennet, smallnet1, smallnet2, smallnet3\n",
    "from loop_fns import loop\n",
    "from plotting import learning_curve, accuracy_curve, plot_confusion\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import collections\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c1e605-9a3b-48dc-a38e-8a955bd3c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "_save_location = r'/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/'\n",
    "\n",
    "data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "\n",
    "gitHASH = '5b835027b98560be2802b81891d000be97a6c8bc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1481ccd-4d87-4c05-84d5-77e29ee981b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaughticalnonsence\u001b[0m (\u001b[33mantvis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49eb7e06-506f-48e6-b28c-8caa7641b11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install datetime\n",
    "\n",
    "d = date.today()\n",
    "#print(str(d), type(str(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87383b",
   "metadata": {},
   "source": [
    "452 144               5/452 *100 = 1%\n",
    "226 72                5/226 *100 = 2%\n",
    "113 36                5/113 *100 = 4% -- 2/113 *100= 1.7% ~ 2%\n",
    "57  18   (56.5,)      5/57 *100  = 8% -- 2/57 *100 = 3.5% ~ 4%.   1/57 = 1.75%\n",
    "29   9   (28.5,)      5/29 *100  = 17% -- 2/29 *100 = 6.89 ~ 7%   1/28 = 3.57 ~ 4%\n",
    "15   5   (14.5, 4.5)\n",
    "8    3   (7.5,2.5)\n",
    "4,   2   (, 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52c8e7-2092-4ad5-9ee5-47bf42573efb",
   "metadata": {},
   "source": [
    "## interesting_result_to_discuss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87dc8393-e7da-43eb-b0e7-b11c4a46c8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def save2csv_nest_dict(nested_dict, file_name, save_location:str):\n",
    "  # flattern nested dictionary\n",
    "  flatterend_dict = {}\n",
    "  for k,v in nested_dict.items():\n",
    "    if isinstance(v, dict):\n",
    "      for nested_key, nested_val in v.items():\n",
    "        flatterend_dict[f\"{k}_{nested_key}\"] = nested_val\n",
    "    else:\n",
    "      flatterend_dict[k] =v\n",
    "\n",
    "  columns = list(flatterend_dict.keys())\n",
    "\n",
    "  with open(save_location+str(file_name)+'.csv', \"a+\", newline=\"\") as f:\n",
    "      # using dictwriter\n",
    "      writer = csv.DictWriter(f, fieldnames=columns)\n",
    "      # using writeheader function\n",
    "      if f.tell() == 0:\n",
    "        writer.writeheader()\n",
    "      writer.writerow(flatterend_dict)\n",
    "      f.close()\n",
    "\n",
    "# check dictionary values for json and csv\n",
    "\n",
    "def check_obj4np(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: check_obj4np(value) for key, value in obj.items()}\n",
    "    if isinstance(obj,list):\n",
    "        return [check_obj4np(item) for item in obj]\n",
    "    if isinstance(obj,np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# save to json\n",
    "def save2josn_nested_dict(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    with open(save_location+str(file_name)+'.json', 'a+') as f:\n",
    "        f.write(json_obj)\n",
    "        f.close()\n",
    "\n",
    "    \n",
    "#save_location+str(file_name)+'.csv'\n",
    "def save2csv(nested_dict, file_name, save_location:str):\n",
    "    \n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    \n",
    "    columns = list(nested_dict.keys())\n",
    "    path = os.path.join(save_location, file_name +\".csv\")\n",
    "    try:\n",
    "        with open(path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            # using dictwriter\n",
    "            # using writeheader function\n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(nested_dict)\n",
    "            f.close()\n",
    "    except IOError as e:\n",
    "        print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "    except ValueError:\n",
    "              print(\"could not convert to string\")\n",
    "    except:\n",
    "              print(\"unexpected error: \", sys.exc_info()[0])\n",
    "        \n",
    "\n",
    "def save2json(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    #print(nested_dict)\n",
    "    #print(nested_dict.items())\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    #print(json_obj)\n",
    "    path = os.path.join(save_location, file_name+\".json\")\n",
    "    #print(path)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(json_obj)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def read_in_json(file_path, file_name):\n",
    "    path = os.path.join(file_path, 'file_name')\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            #obj = f.read()\n",
    "            dj = json.load(f, object_pairs_hook= collections.OrderedDict) #obj, \n",
    "            #print(dj)\n",
    "    except Exception as e:\n",
    "        print(\"Error decoding Json\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "class Flattern(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flattern, self).__init__()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.flatten()\n",
    "        return x\n",
    "\n",
    "\n",
    "def choose_model(model_name, lin_lay, dropout):\n",
    "\n",
    "    #for model_card in config.model_cards:\n",
    "    #print('\\n choose_model \\n MODEL NAME: ',model_name)\n",
    "\n",
    "    if model_name == '4c3l':\n",
    "        return smallnet1(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '3c2l':\n",
    "        return smallnet2(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks = (3,5), dropout=dropout)\n",
    "    elif model_name == '2c2l':\n",
    "        return smallnet3(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '7c3l':\n",
    "        return sevennet(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == 'vgg16':\n",
    "        model_vgg16 = vgg16(weights=\"IMAGENET1K_V1\")\n",
    "        vgg_feats = model_vgg16.features\n",
    "        vgg_classifier = model_vgg16.classifier\n",
    "        vgg_classifier.pop(6)\n",
    "\n",
    "        vgg = nn.Sequential(\n",
    "            vgg_feats,\n",
    "            Flattern(),\n",
    "            vgg_classifier,\n",
    "            nn.Linear(4096,11),\n",
    "            nn.Softmax(dim=0),\n",
    "            )\n",
    "        return vgg\n",
    "    else:\n",
    "        print('Model Name Not Recognised')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ddbb49-828b-4de8-a31c-2a576cd736f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries\n",
    "\n",
    "date = date.today()\n",
    "\n",
    "model_card_vgg = {'name': 'vgg', 'model': 'vgg16',\n",
    "                  'f_lin_lay':[4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                            ],\n",
    "                 'idx': 0,\n",
    "                 'dropout':0.2}\n",
    "\n",
    "\n",
    "model_card_7c3l = {'name': '7c3l', 'model': '7c3l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[248832,    # 452 144    # p5\n",
    "                            59904,      # 226 72     # p5\n",
    "                            11264,      # 113  36    # p2\n",
    "                            1536,       # 57 18      # p1\n",
    "                            172032,           # 29  9\n",
    "                            172032,          # 15 5\n",
    "                            172032,         # 8 3\n",
    "                              ], \n",
    "                   'idx': 1,\n",
    "                  'dropout':0.2}\n",
    "\n",
    "\n",
    "\n",
    "model_card_4c3l = {'name': '4c3l', 'model': '4c3l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[539904,    # 452 144    # p5\n",
    "                             141056,    # 226 72     # p5\n",
    "                             304640,     # 113  36    # p2\n",
    "                             9984,      # 57 18      # p1\n",
    "                             2304,      # 29  9\n",
    "                             512,       # 15 5\n",
    "                             256],      # 8 3\n",
    "                  'idx': 2,\n",
    "                  'dropout':0.2}      \n",
    "\n",
    "model_card_3c2l = {'name': '3c2l', 'model': '3c2l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[1069888,    # 452 144    # p5\n",
    "                             274688,     #226 72      # p5\n",
    "                             68096,      # 113  36    # p2\n",
    "                             17280,      # 57 18      # p1\n",
    "                             3840,       # 29  9\n",
    "                             960,        # 15 5\n",
    "                             256],\n",
    "                  'idx': 3,\n",
    "                  'dropout':0.2}       # 8 3\n",
    "\n",
    "model_card_2c2l = {'name': '2c2l', 'model': '2c2l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[1055232,    # 452 144    # p5\n",
    "                             267264,     #226 72      # p5\n",
    "                             64512,      # 113  36    # p2\n",
    "                             15552,      # 57 18      # p1\n",
    "                             3072,       # 29  9\n",
    "                             640,        # 15 5\n",
    "                             128],\n",
    "                  'idx': 4,\n",
    "                  'dropout':0.2}       # 8 3\n",
    "\n",
    "resolution_card_452144 = {'resolution':[452,144], 'padding':5, 'index':0}\n",
    "\n",
    "resolution_card_83 = {'resolution':[8,3], 'padding':0, 'index':6}\n",
    "\n",
    "\n",
    "resolution_cards = [resolution_card_452144, resolution_card_83]\n",
    "\n",
    "learning_rate_cards = [1e-4]\n",
    "wd_cards = [4e-5]\n",
    "scheduler_cards = [0.2]\n",
    "\n",
    "seeds = [2]\n",
    "\n",
    "model_cards =[model_card_vgg, model_card_7c3l, model_card_4c3l, model_card_3c2l, model_card_2c2l]\n",
    "\n",
    "loss_fn_cards = ['CrossEntropy']\n",
    "                        \n",
    "config = dict({'parameters': 'parameters for big loop run'})\n",
    "config.update({'model_cards':model_cards})\n",
    "config.update({'resolution_cards':resolution_cards})\n",
    "config.update({'learning_rate_cards':learning_rate_cards})\n",
    "config.update({'wd_cards':wd_cards})\n",
    "config.update({'scheduler_cards':scheduler_cards})\n",
    "config.update({'seeds':seeds})\n",
    "config.update({'loss_fn_cards': loss_fn_cards})\n",
    "\n",
    "\n",
    "#print(model_card_vgg)\n",
    "#print('')\n",
    "#pp.pprint(config) # dictionary of dictionaries of lists and lists of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "495f38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, x_train, x_val, y_train, y_val, res, pad, save_dict, lr, scheduler, loss_fn, epochs, model_name): #train_dl, val_dl, \n",
    "\n",
    "\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)#build_optimizer(mo\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=scheduler, last_epoch=-1) \n",
    "    #scheduler'\n",
    "    ####\n",
    "    \n",
    "    #model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    #losses= []\n",
    "    #predictions = []\n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "    total_epochs = 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        if epoch ==0:\n",
    "            best_model=model\n",
    "            best_acc=0\n",
    "\n",
    "        print('Training...')\n",
    "    \n",
    "        t_loss, train_prediction, t_correct, model, optimizer = loop(model=model, X=x_train, Y=y_train, loss_fn=loss_fn, device=device, \n",
    "                                                                     size= res,  pad=pad, num_classes=11, model_name= model_name, \n",
    "                                                                     optimizer=optimizer, scheduler =scheduler)\n",
    "        t_accuracy = (t_correct/len(x_train)*100)\n",
    "        t_accuracy_list.append(t_accuracy)\n",
    "        wandb.log({'t_accuracy', t_accuracy})\n",
    "        t_loss_list.append(t_loss)\n",
    "        \n",
    "        t_predict_list.append(train_prediction)\n",
    "        \n",
    "        \n",
    "        wandb.log({'t_loss_list':t_loss})\n",
    "        wandb.log({'t_predict_list':train_prediction})\n",
    "        wandb.log({'train_labels':list(y_train)})\n",
    "        train_acc = (t_correct / len(x_train))\n",
    "        t_accuracy_list.append(train_acc)\n",
    "        wandb.log({'train_acc':train_acc})\n",
    "        #y_train_save = y_train.tolist()\n",
    "\n",
    "        \n",
    "        #clear_output()\n",
    "        \n",
    "            \n",
    "        print('validating...')\n",
    "        \n",
    "        v_loss, val_prediction, val_correct= loop(model=model, X=x_val, Y=y_val, loss_fn=loss_fn, device=device, size= res,  pad=pad, num_classes=11, model_name= model_name, train=False)\n",
    "\n",
    "\n",
    "        v_loss_list.append(v_loss)\n",
    "        v_predict_list.append(val_prediction)\n",
    "        wandb.log({'v_loss_list':v_loss})\n",
    "\n",
    "        v_accuracy_list.append((val_correct/len(y_val)*100))\n",
    "        #v_accuracy_list.append(val_correct)\n",
    "        #wand.log({'v_accuracy': (val_correct/len(y_val)*100)})\n",
    "        \n",
    "        #wandb.log({'v_predict_list':val_prediction})\n",
    "        #wandb.log({'y_val':list(y_val)})\n",
    "        val_acc = (t_correct / len(x_val))\n",
    "        v_accuracy_list.append(val_acc)\n",
    "        wandb.log({'val_acc':(val_correct/len(y_val)*100)})\n",
    "\n",
    "        #clear_output()\n",
    "            \n",
    "        total_epochs += 1\n",
    "        \n",
    "\n",
    "    save_dict['training_samples'] = len(x_train)\n",
    "    save_dict['validation_samples'] = len(x_val)\n",
    "    save_dict['Current_Epoch'] += epochs\n",
    "    model = best_model\n",
    "    save_dict['t_loss_list'] = t_loss_list\n",
    "    save_dict['t_labels'] = y_train\n",
    "    save_dict['t_predict_list'] = t_predict_list \n",
    "    \n",
    "    #wandb.log({'y_train':y_train})\n",
    "    wandb.log({'t_predict_list':t_predict_list})\n",
    "\n",
    "    save_dict['t_accuracy_list'] = t_accuracy_list \n",
    "    #wandb.log({'t_accuracy_list':t_accuracy_list})\n",
    "\n",
    "    #y_val_save = y_val.tolist()\n",
    "    save_dict['v_loss_list'] = v_loss_list\n",
    "    save_dict['v_predict_list'] = v_predict_list  #\n",
    "    #save_dict['v_labels'] = y_val\n",
    "\n",
    "    save_dict['v_accuracy_list'] = v_accuracy_list  #\n",
    "    #wandb.log({'v_accuracy_list':v_accuracy_list})\n",
    "\n",
    "    return model, save_dict\n",
    "\n",
    "def test_loop(model, model_name, X, Y, res, pad, save_dict, loss_fn, device, num_classes=11):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    current_loss = 0\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    colour ='colour'\n",
    "    size =  res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print('Testing...') \n",
    "        for idx, img in enumerate(X):\n",
    "            prepro = ImageProcessor(device)\n",
    "            if model_name == 'vgg16':\n",
    "                tense = prepro.colour_size_tense(img, colour, size, pad, vg=True) #[29, 9], 15, 5, [8,3]\n",
    "            elif (model_name == '7c3l' and size == [29, 9]) or (model_name == '7c3l' and size == [15, 5]) or (model_name == '7c3l' and size ==[8, 3]):\n",
    "                tense = prepro.colour_size_tense(img, colour, size, pad, vg=True)\n",
    "            else:\n",
    "                tense = prepro.colour_size_tense(img, colour, size, pad)\n",
    "            prediction = model.forward(tense)\n",
    "            label = label_oh_tf(Y[idx], num_classes).to(device)\n",
    "            loss = loss_fn(prediction, label)\n",
    "\n",
    "            if prediction.argmax()==label.argmax():\n",
    "                num_correct +=1\n",
    "            total_count +=1\n",
    "            correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "\n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "        predict_list.append(prediction)\n",
    "        current_loss += loss.item()\n",
    "    return accuracy, predict_list, Y, current_loss\n",
    "\n",
    "\n",
    "def get_data(random_seed):\n",
    "    file_path =  data_path\n",
    "    #print(file_path)\n",
    "    img_len = len(os.listdir(file_path))\n",
    "    \n",
    "    x, y = import_imagedata(file_path)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "    \n",
    "def get_lin_lay(model_card, resolution):\n",
    "    if resolution == [452, 144]:\n",
    "        lin_lay = model_card['f_lin_lay'][0]\n",
    "    elif resolution == [226, 72]:\n",
    "        lin_lay = model_card['f_lin_lay'][1]\n",
    "    elif resolution == [113, 36]:\n",
    "        lin_lay = model_card['f_lin_lay'][2]\n",
    "    elif resolution == [57, 18]:\n",
    "        lin_lay = model_card['f_lin_lay'][3]\n",
    "    elif resolution == [29, 9]:\n",
    "        lin_lay = model_card['f_lin_lay'][4]\n",
    "    elif resolution == [15, 5]:\n",
    "        lin_lay = model_card['f_lin_lay'][5]\n",
    "    elif resolution == [8, 3]:\n",
    "        lin_lay = model_card['f_lin_lay'][6]\n",
    "    else:\n",
    "        print(\"PARAMETER NOT FOUND: \\n f_lin_lay FROM MODEL CARD\")\n",
    "    return lin_lay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "650c0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c19d9613",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def _go(config=None):\n",
    "    with wandb.init(config=config, project=f\"test Run Big Loop\", notes=\"First logging test of big loop. limitied data\",):\n",
    "        if len(gitHASH) <1:\n",
    "            print(\"YOU FORGET THE GIT HASH\")\n",
    "            return\n",
    "        else:\n",
    "            print('Git Hash registered')\n",
    "            \n",
    "        config = wandb.config\n",
    "        start = time.process_time()\n",
    "\n",
    "        for model_idx, model_card in enumerate(config.model_cards):\n",
    "            \n",
    "            model_name = model_card['model']\n",
    "            model_index = model_card['idx']\n",
    "            dropout = model_card['dropout'] \n",
    "            \n",
    "            \n",
    "            for res_idx, resolution_card in enumerate(config['resolution_cards']):\n",
    "\n",
    "                resolution = resolution_card['resolution']\n",
    "                pad = resolution_card['padding']\n",
    "               \n",
    "                lin_lay = get_lin_lay(model_card, resolution)\n",
    "\n",
    "                \n",
    "                for lr_idx, lr in enumerate(config['learning_rate_cards']):\n",
    "                    for wd_idx, wd_card in enumerate(wd_cards):\n",
    "                        for sched_idx, scheduler in enumerate(config['scheduler_cards']):\n",
    "                            for seed_idx, seed in enumerate(config['seeds']):\n",
    "                                seed = seed\n",
    "                                for lossfn_idx, lossfn in enumerate(config['loss_fn_cards']):\n",
    "\n",
    "                                    print('Model: ', str(model_name), f\" idx: {model_idx} / {len(config['model_cards'])}\")\n",
    "                                    print('resolution: ', str(resolution), f\"  idx: {res_idx} / {len(config['resolution_cards'])}\")\n",
    "                                    print('learning rate: ', str(lr), f\"  idx: {lr_idx} / {len(config['learning_rate_cards'])}\")\n",
    "                                    print('weight decay: ', str(wd_card), f\"  idx: {wd_idx} / {len(config['wd_cards'])}\")\n",
    "                                    print('scheduler: ', str(scheduler), f\"  idx: {sched_idx} / {len(config['scheduler_cards'])}\")\n",
    "                                    print('seed: ', str(seed), f\"  idx:  {seed_idx} / {len(config['seeds'])}\")\n",
    "                                    print('loss function: ', str(lossfn), f\" idx: {lossfn_idx} / {len(config['loss_fn_cards'])}\")\n",
    "                                    run_start_time = time.process_time()\n",
    "                                    print(run_start_time)\n",
    "   \n",
    "                                    print(time.process_time() - start)\n",
    "                                    \n",
    "        \n",
    "                                    epochs = 2\n",
    "\n",
    "                                    print(f\"Total epochs: {epochs}\")\n",
    "                                     \n",
    "                                    wandb.log({'gitHash':gitHASH})\n",
    "                                    wandb.log({'Epochs': epochs})\n",
    "                                    # set save dictionary\n",
    "                                    save_dict = {'Run' : f\"GettingComputationTime_{model_name}{resolution}{date}\",\n",
    "                                                 'Current_Epoch': 0,\n",
    "                                                 'save_location' : _save_location}\n",
    "                                    \n",
    "                                    # set model\n",
    "                                    model = choose_model(model_name, lin_lay, dropout).to(device)\n",
    "                                    #print(model, '\\n', type(config))\n",
    "                                    # get image data\n",
    "                                    x_train, y_train, x_val, y_val, x_test, y_test = get_data(seed)\n",
    "                                    \n",
    "                                    # set loss function\n",
    "                                    loss_fn = set_lossfn(lossfn)\n",
    "                                    \n",
    "                                    # set optimizer\n",
    "                                    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "                                    \n",
    "                                    wandb.watch(model, loss_fn, log='all', log_freq=2, idx = model_index)\n",
    "                                    model, save_dict=  train_model(model, x_train, x_val, y_train, y_val, resolution, pad, save_dict, lr, scheduler, loss_fn,epochs, model_name)\n",
    "\n",
    "                                    #test                                               Y,          \n",
    "                                    test_acc,test_predict_list, y_test, test_loss = test_loop(model, model_name, x_test, y_test,resolution, pad, save_dict,loss_fn, device, num_classes=11) #model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\n",
    "                                    print(' \\n train acc: ', save_dict['t_accuracy_list'][-1])\n",
    "                                    print(' \\n val acc: ', save_dict['v_accuracy_list'][-1])\n",
    "                                    print(' \\n test acc: ', test_acc)\n",
    "                                    \n",
    "                                    save_dict.update({'test_acc': test_acc})\n",
    "                                    save_dict.update({'test_predict': test_predict_list})\n",
    "                                    save_dict.update({'test_labels': list(y_test)})\n",
    "                                    save_dict.update({'test_loss':test_loss})\n",
    "                                    wandb.log({'test_acc': test_acc})\n",
    "                                    wandb.log({'test_predict': test_predict_list})\n",
    "                                    wandb.log({'test_labels': list(y_test)})\n",
    "                                    #saving\n",
    "                                    diction = {}\n",
    "                                    d = date.today()\n",
    "                                    d=str(d)\n",
    "                                    diction.update({'Date':d})\n",
    "                                    diction.update({'gitHASH':str(gitHASH)})\n",
    "                                    diction.update({'model_name': str(model_name)})\n",
    "                                    diction.update({'loss_fn': str(lossfn)})\n",
    "                                    diction.update({'lr': str(lr)})\n",
    "                                    diction.update({'wd': str(wd_card)})\n",
    "                                    diction.update({'scheduler': str(scheduler)})\n",
    "                                    diction.update({'seed': str(seed)})\n",
    "                                    diction.update({'resolution': str(resolution)})\n",
    "                                    diction.update({'pad': int(pad)})\n",
    "                                    diction.update({'lin_lay': int(lin_lay)})\n",
    "                                    diction.update({'run time': (time.process_time() - run_start_time)})\n",
    "                                    diction.update(save_dict)\n",
    "                                    \n",
    "                                    save_location = save_dict['save_location']\n",
    "                                    title = save_dict['Run']\n",
    "                                    save2json(diction, title, save_location)\n",
    "                                    save2csv(diction, title, save_location)\n",
    "        \n",
    "                                    diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "        \n",
    "                                    with open(f\"{save_location}{title}.pkl\", 'wb+') as f:\n",
    "                                        pickle.dump(diction, f)\n",
    "                                    \n",
    "                                    #clear_output()\n",
    "                                    \n",
    "                                    print(f' \\n END {model_name} {resolution} Run Time: ',time.process_time() - run_start_time)\n",
    "\n",
    "        print('Final Run time:  ',time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b58d7d27-ef9d-43d9-98a8-1f11ff50090d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/its/home/nn268/antvis/antvis/optics/wandb/run-20240311_162349-mv3gtltu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antvis/test%20Run%20Big%20Loop/runs/mv3gtltu' target=\"_blank\">helpful-glade-136</a></strong> to <a href='https://wandb.ai/antvis/test%20Run%20Big%20Loop' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antvis/test%20Run%20Big%20Loop' target=\"_blank\">https://wandb.ai/antvis/test%20Run%20Big%20Loop</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antvis/test%20Run%20Big%20Loop/runs/mv3gtltu' target=\"_blank\">https://wandb.ai/antvis/test%20Run%20Big%20Loop/runs/mv3gtltu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git Hash registered\n",
      "Model:  vgg16  idx: 0 / 5\n",
      "resolution:  [452, 144]   idx: 0 / 2\n",
      "learning rate:  0.0001   idx: 0 / 1\n",
      "weight decay:  4e-05   idx: 0 / 1\n",
      "scheduler:  0.2   idx: 0 / 1\n",
      "seed:  2   idx:  0 / 1\n",
      "loss function:  CrossEntropy  idx: 0 / 1\n",
      "3383.093470737\n",
      "0.0005287779999889608\n",
      "Total epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████                           | 1/2 [00:52<00:52, 52.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2/2 [01:46<00:00, 53.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      " \n",
      " train acc:  0.08982748364069007\n",
      " \n",
      " val acc:  0.20943134535367544\n",
      " \n",
      " test acc:  10.29126213592233\n",
      " \n",
      " END vgg16 [452, 144] Run Time:  814.8248087229999\n",
      "Model:  vgg16  idx: 0 / 5\n",
      "resolution:  [8, 3]   idx: 1 / 2\n",
      "learning rate:  0.0001   idx: 0 / 1\n",
      "weight decay:  4e-05   idx: 0 / 1\n",
      "scheduler:  0.2   idx: 0 / 1\n",
      "seed:  2   idx:  0 / 1\n",
      "loss function:  CrossEntropy  idx: 0 / 1\n",
      "4197.919299019\n",
      "814.8263719099996\n",
      "Total epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████                           | 1/2 [00:52<00:52, 52.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2/2 [01:45<00:00, 52.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      " \n",
      " train acc:  0.09161213563355146\n",
      " \n",
      " val acc:  0.21359223300970873\n",
      " \n",
      " test acc:  10.29126213592233\n",
      " \n",
      " END vgg16 [8, 3] Run Time:  790.6642428329997\n",
      "Model:  7c3l  idx: 1 / 5\n",
      "resolution:  [452, 144]   idx: 0 / 2\n",
      "learning rate:  0.0001   idx: 0 / 1\n",
      "weight decay:  4e-05   idx: 0 / 1\n",
      "scheduler:  0.2   idx: 0 / 1\n",
      "seed:  2   idx:  0 / 1\n",
      "loss function:  CrossEntropy  idx: 0 / 1\n",
      "4988.584992353\n",
      "1605.4920475809995\n",
      "Total epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/nn268/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████                           | 1/2 [00:21<00:21, 21.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2/2 [00:42<00:00, 21.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      " \n",
      " train acc:  0.09934562760261749\n",
      " \n",
      " val acc:  0.231622746185853\n",
      " \n",
      " test acc:  10.29126213592233\n",
      " \n",
      " END 7c3l [452, 144] Run Time:  595.142999449\n",
      "Model:  7c3l  idx: 1 / 5\n",
      "resolution:  [8, 3]   idx: 1 / 2\n",
      "learning rate:  0.0001   idx: 0 / 1\n",
      "weight decay:  4e-05   idx: 0 / 1\n",
      "scheduler:  0.2   idx: 0 / 1\n",
      "seed:  2   idx:  0 / 1\n",
      "loss function:  CrossEntropy  idx: 0 / 1\n",
      "5583.729304203\n",
      "2200.636364051\n",
      "Total epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████                           | 1/2 [00:17<00:17, 17.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2/2 [00:35<00:00, 17.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      " \n",
      " train acc:  0.11124330755502677\n",
      " \n",
      " val acc:  0.2593619972260749\n",
      " \n",
      " test acc:  9.12621359223301\n",
      " \n",
      " END 7c3l [8, 3] Run Time:  558.7648307910003\n",
      "Model:  4c3l  idx: 2 / 5\n",
      "resolution:  [452, 144]   idx: 0 / 2\n",
      "learning rate:  0.0001   idx: 0 / 1\n",
      "weight decay:  4e-05   idx: 0 / 1\n",
      "scheduler:  0.2   idx: 0 / 1\n",
      "seed:  2   idx:  0 / 1\n",
      "loss function:  CrossEntropy  idx: 0 / 1\n",
      "6142.497317367\n",
      "2759.4044596989997\n",
      "Total epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████                           | 1/2 [00:24<00:24, 24.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      " \n",
      " train acc:  0.08149910767400356\n",
      " \n",
      " val acc:  0.1900138696255201\n",
      " \n",
      " test acc:  10.29126213592233\n",
      " \n",
      " END 4c3l [452, 144] Run Time:  600.8170843120006\n",
      "Model:  4c3l  idx: 2 / 5\n",
      "resolution:  [8, 3]   idx: 1 / 2\n",
      "learning rate:  0.0001   idx: 0 / 1\n",
      "weight decay:  4e-05   idx: 0 / 1\n",
      "scheduler:  0.2   idx: 0 / 1\n",
      "seed:  2   idx:  0 / 1\n",
      "loss function:  CrossEntropy  idx: 0 / 1\n",
      "6743.315475109\n",
      "3360.222535094\n",
      "Total epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████                           | 1/2 [00:07<00:07,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      " \n",
      " train acc:  0.08625817965496728\n",
      " \n",
      " val acc:  0.20110957004160887\n",
      " \n",
      " test acc:  10.29126213592233\n",
      " \n",
      " END 4c3l [8, 3] Run Time:  17.213747571000567\n",
      "Model:  3c2l  idx: 3 / 5\n",
      "resolution:  [452, 144]   idx: 0 / 2\n",
      "learning rate:  0.0001   idx: 0 / 1\n",
      "weight decay:  4e-05   idx: 0 / 1\n",
      "scheduler:  0.2   idx: 0 / 1\n",
      "seed:  2   idx:  0 / 1\n",
      "loss function:  CrossEntropy  idx: 0 / 1\n",
      "6760.53011375\n",
      "3377.437172995\n",
      "Total epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████                           | 1/2 [00:36<00:36, 36.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2/2 [01:12<00:00, 36.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      " \n",
      " train acc:  0.091017251635931\n",
      " \n",
      " val acc:  0.21220527045769763\n",
      " \n",
      " test acc:  10.29126213592233\n",
      " \n",
      " END 3c2l [452, 144] Run Time:  663.609470202\n",
      "Model:  3c2l  idx: 3 / 5\n",
      "resolution:  [8, 3]   idx: 1 / 2\n",
      "learning rate:  0.0001   idx: 0 / 1\n",
      "weight decay:  4e-05   idx: 0 / 1\n",
      "scheduler:  0.2   idx: 0 / 1\n",
      "seed:  2   idx:  0 / 1\n",
      "loss function:  CrossEntropy  idx: 0 / 1\n",
      "7424.140740861\n",
      "4041.047794338\n",
      "Total epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████                           | 1/2 [00:06<00:06,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      " \n",
      " train acc:  0.09280190362879238\n",
      " \n",
      " val acc:  0.21636615811373092\n",
      " \n",
      " test acc:  9.320388349514563\n",
      " \n",
      " END 3c2l [8, 3] Run Time:  14.583072256999912\n",
      "Model:  2c2l  idx: 4 / 5\n",
      "resolution:  [452, 144]   idx: 0 / 2\n",
      "learning rate:  0.0001   idx: 0 / 1\n",
      "weight decay:  4e-05   idx: 0 / 1\n",
      "scheduler:  0.2   idx: 0 / 1\n",
      "seed:  2   idx:  0 / 1\n",
      "loss function:  CrossEntropy  idx: 0 / 1\n",
      "7438.724573147\n",
      "4055.6316275399995\n",
      "Total epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████                           | 1/2 [00:34<00:34, 34.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2/2 [01:08<00:00, 34.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      " \n",
      " train acc:  0.09161213563355146\n",
      " \n",
      " val acc:  0.21359223300970873\n",
      " \n",
      " test acc:  10.29126213592233\n",
      " \n",
      " END 2c2l [452, 144] Run Time:  656.3340054359996\n",
      "Model:  2c2l  idx: 4 / 5\n",
      "resolution:  [8, 3]   idx: 1 / 2\n",
      "learning rate:  0.0001   idx: 0 / 1\n",
      "weight decay:  4e-05   idx: 0 / 1\n",
      "scheduler:  0.2   idx: 0 / 1\n",
      "seed:  2   idx:  0 / 1\n",
      "loss function:  CrossEntropy  idx: 0 / 1\n",
      "8095.059519324\n",
      "4711.966574894\n",
      "Total epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████                           | 1/2 [00:05<00:05,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2/2 [00:11<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      " \n",
      " train acc:  0.091017251635931\n",
      " \n",
      " val acc:  0.21220527045769763\n",
      " \n",
      " test acc:  10.29126213592233\n",
      " \n",
      " END 2c2l [8, 3] Run Time:  12.849077755000508\n",
      "Final Run time:   4724.816061371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 1.4%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epochs</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>t_loss_list</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▃▃▁▁██▁▁</td></tr><tr><td>test_acc</td><td>███▁███▂██</td></tr><tr><td>train_acc</td><td>▃▃▃▃▃▅██▆▁▄▂▃▃▂▄▃▃▇▃</td></tr><tr><td>v_loss_list</td><td>▂▂▁▁▂▂▂▂▂▂▂▂▁▁▂▂██▂▂</td></tr><tr><td>val_acc</td><td>▃▃▃▃▃▅██▆▁▄▂▃▃▂▄▃▃▇▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epochs</td><td>2</td></tr><tr><td>gitHash</td><td>5b835027b98560be2802...</td></tr><tr><td>t_loss_list</td><td>4030.73341</td></tr><tr><td>test_acc</td><td>10.29126</td></tr><tr><td>train_acc</td><td>0.09102</td></tr><tr><td>v_loss_list</td><td>1728.79282</td></tr><tr><td>val_acc</td><td>0.21221</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">helpful-glade-136</strong> at: <a href='https://wandb.ai/antvis/test%20Run%20Big%20Loop/runs/mv3gtltu' target=\"_blank\">https://wandb.ai/antvis/test%20Run%20Big%20Loop/runs/mv3gtltu</a><br/> View job at <a href='https://wandb.ai/antvis/test%20Run%20Big%20Loop/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NzcxOTUyMg==/version_details/v7' target=\"_blank\">https://wandb.ai/antvis/test%20Run%20Big%20Loop/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NzcxOTUyMg==/version_details/v7</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240311_162349-mv3gtltu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_go(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964b31e-4bae-4f65-bc46-ee1334a8f239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571c92f-0269-4532-9274-548e60b89bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
