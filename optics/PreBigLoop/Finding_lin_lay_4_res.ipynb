{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 050224\n",
    "# testing dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as maths\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "#from torchsummary import summary\n",
    "#import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "import pprint\n",
    "\n",
    "\n",
    "from functions import import_imagedata, get_data, label_oh_tf,  Unwrap, ImageProcessor,IDSWDataSetLoader\n",
    "from architectures import sevennet, smallnet1, smallnet2, smallnet3, build_net\n",
    "from loop_fns import loop, test_loop\n",
    "from fns4wandb import build_optimizer, set_optimizer, train_model, train_log, log_test_score, set_lossfn, pipeline\n",
    "\n",
    "\n",
    "from fns4wandb import hp_sweep_DL\n",
    "import pickle\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "from fns4wandb import train\n",
    "from datetime import date\n",
    "\n",
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model,  x_train, x_val, y_train, y_val, config, best_acc=0): #train_dl, val_dl, \n",
    "\n",
    "    \n",
    "    \n",
    "    loss_fn = set_lossfn(config['loss_fn']) # ****\n",
    "    \n",
    "    lr = config['learning_rate'] #1e-5 #config.learning_rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)#build_optimizer(model, optimizer=torch.optim.Adam(model.parameters(), lr=lr))#config.optimizer, config.learning_rate, config.weight_decay)\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=config['scheduler'], last_epoch=-1) #gamma=config.scheduler, last_epoch=-1)\n",
    "                                                                    #scheduler'\n",
    "    ####\n",
    "    \n",
    "    #model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    #losses= []\n",
    "    #predictions = []\n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "\n",
    "    \n",
    "    total_epochs = 0\n",
    "    for epoch in tqdm(range(config['epochs'])): #config.epochs)):\n",
    "        if epoch ==0:\n",
    "            best_model=model\n",
    "            best_acc=0\n",
    "\n",
    "        t_loss, train_prediction, t_correct, model, optimizer = loop(model=model, X=x_train, Y=y_train, loss_fn=loss_fn, device=device, col_dict=col_dict, num_classes=11, model_name= config['model_name'], optimizer=optimizer, scheduler =scheduler)\n",
    "        \n",
    "        \n",
    "        save_dict['t_loss_list'] = t_loss_list\n",
    "        save_dict['t_labels'] = y_train\n",
    "        save_dict['t_predict_list'] = t_predict_list \n",
    "\n",
    "        train_acc = (t_correct / len(x_train))\n",
    "        t_accuracy_list.append(train_acc)\n",
    "        \n",
    "        save_dict['t_accuracy_list'] = t_accuracy_list \n",
    "        clear_output()\n",
    "        \n",
    "            \n",
    "        print('validating...')\n",
    "        \n",
    "        v_loss, val_prediction, val_correct= loop(model=model, X=x_val, Y=y_val, loss_fn=loss_fn, device=device, col_dict=col_dict, num_classes=11, model_name= config['model_name'], train=False)\n",
    "\n",
    "\n",
    "        save_dict['v_loss_list'] = v_loss_list\n",
    "        save_dict['v_predict_list'] = v_predict_list  #\n",
    "        save_dict['v_labels'] = y_val\n",
    "        \n",
    "        val_acc = (t_correct / len(x_val))\n",
    "        v_accuracy_list.append(val_acc)\n",
    "        save_dict['v_accuracy_list'] = v_accuracy_list  #\n",
    "        \n",
    "\n",
    "        clear_output()\n",
    "            \n",
    "        total_epochs += epoch\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "\n",
    "            best_acc = val_acc\n",
    "\n",
    "            best_model = model#deepcopy(model)\n",
    "            \n",
    "            save_dict['Current_Epoch'] += config['epochs']\n",
    "            save_dict['training_samples'] = len(x_train)\n",
    "            save_dict['validation_samples'] = len(x_val)\n",
    "            \n",
    "\n",
    "            title = save_dict['Run']\n",
    "            save_location = save_dict['save_location']\n",
    "            conf= dict(config)\n",
    "            diction = {}\n",
    "            d = date.today()\n",
    "            d=str(d)\n",
    "            diction.update({'Date':d})\n",
    "            diction.update(save_dict)\n",
    "            diction.update(conf)\n",
    "            diction.update(col_dict)\n",
    "            print(diction)\n",
    "            \n",
    "            save2json(conf, title, save_location)\n",
    "            save2csv(diction, title, save_location)\n",
    "            \n",
    "            diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "            \n",
    "            with open(f\"{save_location}{title}.pkl\", 'wb+') as f:\n",
    "                pickle.dump(diction, f)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print('improvment in metrics. model saved')\n",
    "\n",
    "            #print('END Of SAve -----------------------------')\n",
    "            #!nvidia-smi\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "    model = best_model\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def pipeline(config, save_dict, col_dict): \n",
    "    # set model\n",
    "    l = config['f_lin_lay']\n",
    "    \n",
    "    \n",
    "    # load in data\n",
    "    file_path =  r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "    random_seed =1\n",
    "    img_len = len(os.listdir(file_path))\n",
    "\n",
    "\n",
    "    #print(ids[4])\n",
    "    x, y = import_imagedata(file_path)\n",
    "\n",
    "    x_train, x_test, y_train, y_tests = train_test_split(x,y, test_size=0.2, train_size=0.8,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.1, train_size=0.8,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "\n",
    "    x_train, x_val = x_train[:2], x_val[:2] # for testing purposes, shortened data\n",
    "    #!nvidia-smi\n",
    "    \n",
    "    loss_list=[]\n",
    "    #loss_fn = nn.CrossEntropyLoss()\n",
    "    #loss_fn = nn.MSELoss()\n",
    "    title=save_dict['Run']\n",
    "    \n",
    "    \"\"\"l = config['f_lin_lay']\n",
    "    model_vgg16 = vgg16(weights=\"IMAGENET1K_V1\")\n",
    "    vgg_feats = model_vgg16.features\n",
    "    vgg_classifier = model_vgg16.classifier\n",
    "    #print(vgg_classifier)\n",
    "    vgg_classifier.pop(6)\n",
    "    vgg = nn.Sequential(\n",
    "        vgg_feats,\n",
    "        Flattern(),\n",
    "        vgg_classifier,\n",
    "        nn.Linear(l,11),\n",
    "        nn.Softmax(dim=0),\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    model =sevennet(in_chan=3, f_lin_lay=config['f_lin_lay'], l_lin_lay=11, ks=config['ks'], dropout = config['dropout']).to(device)\n",
    "    #model = vgg\n",
    "    model = train_model(model,x_train, x_val, y_train, y_val, config) #train_dl, val_dl\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"model_name\" : '7c3l',\n",
    "    \"epochs\" :2, \n",
    "    \"learning_rate\" : 5.97E-05, #6.62E-05, #5.97E-05, #6.01E-05, #6.62E-05, #0.00, 00821591686076769, #8e-5,\n",
    "    \"dataset\" : 'IDSW_Aug',\n",
    "    \"architecture\" :'CNN',\n",
    "    \"optimizer\": 'adam',\n",
    "    \"loss_fn\" : 'CrossEntropy',\n",
    "    \"weight_decay\": 2e-5, #4e-5, #2e-5, #3.00E-05,\n",
    "    \"dropout\" : 0.4, #0.4,\n",
    "    \"lin_layer_size\": 100,\n",
    "    \"ks\" : [3,5],\n",
    "    \"in_chan\" : 3,\n",
    "    \"num_classes\" :11,\n",
    "    \"scheduler\" : 0.2,\n",
    "    \"channels\": 3,\n",
    "    \"f_lin_lay\" :172032\n",
    "    , \n",
    "     \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#r'/its/home/nn268/antvis/optics/\n",
    "#pickles\n",
    "col_dict = {\n",
    "    'colour': 'colour',\n",
    "    'size': [15, 5],\n",
    "    'pad': 0,\n",
    "    'model_size': '2c2l'\n",
    "}\n",
    "\n",
    "\n",
    "save_dict = {'Run' : 'testin 7c small res blank padding',\n",
    "            'Current_Epoch': 0,\n",
    "            'save_location' : r'pickles/'}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 2/2 [00:00<00:00, 60.55it/s]\n"
     ]
    }
   ],
   "source": [
    "class Flattern(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flattern, self).__init__()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.flatten()\n",
    "        return x\n",
    "\n",
    "model = pipeline(config, save_dict, col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
