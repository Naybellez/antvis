{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as maths\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "#from torchsummary import summary\n",
    "#import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "\n",
    "from functions import Unwrap, label_oh_tf, import_imagedata, get_data, ImageProcessor\n",
    "from loop_fns import loop, test_loop\n",
    "from fns4wandb import build_optimizer, set_optimizer, set_lossfn, train, train_model, train_log, log_test_score\n",
    "from architectures import build_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaughticalnonsence\u001b[0m (\u001b[33mantvis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"'distribution': 'log_uniform_values',\n",
    "            'min': 1e-5,\n",
    "            'max': 7e-5\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 36wsgole\n",
      "Sweep URL: https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/sweeps/36wsgole\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# HP sweep\n",
    "\n",
    "config = {\n",
    "    'method': 'random',\n",
    "    'metric':{\n",
    "        'goal': 'minimize',\n",
    "        'name': 'val_loss'},\n",
    "    'parameters': {\n",
    "        'dropout':{\n",
    "            'values': [0.4] #0.5, 0.45, 0.55\n",
    "        },\n",
    "        'weight_decay':{\n",
    "            'values': [4e-5,1e-5] #1e-5,2e-5, 3e-5,1e-4, 1e-6,2e-5, 3e-5\n",
    "        },\n",
    "        'epochs':{\n",
    "            'value': 80\n",
    "        },\n",
    "        'lin_layer_size': {\n",
    "            'values': [100]\n",
    "        },\n",
    "        'first_lin_lay':{\n",
    "            'values':[10240] #1x10240 and 12288x100)\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam']\n",
    "        },\n",
    "        'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'log_uniform_values',\n",
    "        'min': 0.000001,\n",
    "        'max': 0.001\n",
    "        },\n",
    "        'kernal_size': {\n",
    "            'values': [(3,5), (3,4), (4,5)] #,(3,5), (4,5), (4,6)  ### KERNAL SIZE AFFECTS CONV OUTPUT SIZE!\n",
    "        },\n",
    "        'loss_fn': {\n",
    "            'values': ['MSE', 'CrossEntropy']\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(config, project='HPS_basedon_decent-sweep-24_UNwrapped_36113')\n",
    "\n",
    "\n",
    "col_dict={\n",
    "    'colour': 'colour',\n",
    "    'size': [113,36]\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "config = dict(\n",
    "    epochs= 120, \n",
    "    learning_rate =1.7543891908426036e-05, #1e-5,\n",
    "    dataset= 'IDSW',\n",
    "    architecture ='CNN',\n",
    "    optimizer= 'adam',\n",
    "    weight_decay= 1.0e-05, #1e-4,\n",
    "    loss_fn = 'MSE',\n",
    "    dropout = 0.4,\n",
    "    lin_layer_size = 100,\n",
    "    first_lin_lay= 10240,\n",
    "    kernal_size = [3,5],\n",
    "    in_chan = 3\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "col_dict={\n",
    "    'colour': 'colour',\n",
    "    'size': [36,113]\n",
    "}\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colour': 'colour', 'size': [36, 113]}\n"
     ]
    }
   ],
   "source": [
    "print(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = get_data()\n",
    "                            # Common functions\n",
    "\n",
    "\"\"\"def build_optimizer(network, optimizer, learning_rate, weight_decay=0):\n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        if weight_decay == 0:\n",
    "            optimizer = torch.optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "        optimizer = torch.optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate, weight_decay=weight_decay)\n",
    "    return optimizer\n",
    "\n",
    "def train_log(t_loss, v_loss, sample_count, epoch):\n",
    "    wandb.log({'epoch': epoch,\n",
    "              't_loss': t_loss,\n",
    "              'v_loss': v_loss},\n",
    "             step=sample_count)\n",
    "    print(f'loss after {str(sample_count).zfill(5)} examples: {v_loss:.3f}')\n",
    "\n",
    "                                # HP Sweep\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        model = build_net(config.lin_layer_size,config.dropout, config.first_lin_lay, config.kernal_size).to(device)\n",
    "        if config.loss_fn == 'MSE':\n",
    "            loss_fn = nn.MSELoss()\n",
    "        elif config.loss_fn == 'CrossEntropy':\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "        e_count = 0\n",
    "        #optimizer = build_optimizer(network, config.optimizer, config.learning_rate, config.weight_decay)\n",
    "        if e_count >= 20:\n",
    "            optimizer = build_optimizer(model, config.optimizer, config.learning_rate, config.weight_decay)\n",
    "        else:\n",
    "            optimizer = build_optimizer(model, config.optimizer, config.learning_rate)\n",
    "        \n",
    "        for epoch in range(config.epochs):\n",
    "\n",
    "            t_loss, predict_list, t_num_correct, model, optimizer = loop(model, x_train, y_train, epoch, loss_fn, device, col_dict, optimizer=optimizer)\n",
    "            \n",
    "            t_accuracy = (t_num_correct /len(x_train))*100\n",
    "            \n",
    "            v_loss, __, v_num_correct= loop(model, x_val, y_val, epoch, loss_fn, device,col_dict, train=False) \n",
    "            \n",
    "            v_accuracy= (v_num_correct / len(x_val))*100\n",
    "            \n",
    "            t_avg_loss =t_loss/len(x_train)\n",
    "            v_avg_loss = v_loss /len(x_val)\n",
    "            \n",
    "            e_count +=1\n",
    "            \n",
    "            wandb.log({'avg_train_loss': t_avg_loss, 'epoch':epoch})\n",
    "            wandb.log({'avg_val_loss': v_avg_loss, 'epoch':epoch})\n",
    "            wandb.log({'train_loss': t_loss, 'epoch':epoch})\n",
    "            wandb.log({'val_loss': v_loss, 'epoch':epoch})\n",
    "            wandb.log({'train_accuracy_%': t_accuracy})\n",
    "            wandb.log({'val_accuracy_%': v_accuracy})\n",
    "\"\"\"\n",
    "                                #Training\n",
    "            \n",
    "\"\"\"def train_model(model, x_train, y_train, x_val, y_val,loss_fn, config):\n",
    "    wandb.watch(model, loss_fn, log='all', log_freq=10)\n",
    "    \n",
    "    sample_count =0\n",
    "    batch_count = 0\n",
    "    e_count = 0\n",
    "    \n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        if e_count >= 20:\n",
    "            optimizer = build_optimizer(model, config.optimizer, config.learning_rate, config.weight_decay)\n",
    "        else:\n",
    "            optimizer = build_optimizer(model, config.optimizer, config.learning_rate)\n",
    "            \n",
    "        #train\n",
    "        t_loss, predict_list, t_num_correct, model, optimizer = loop(model, x_train, y_train, epoch, loss_fn, device, col_dict, optimizer=optimizer)\n",
    "        sample_count += len(x_train)\n",
    "       \n",
    "        # validation\n",
    "        v_loss, __, v_num_correct= loop(model, x_val, y_val, epoch, loss_fn, device,col_dict, train=False) \n",
    "        batch_count +=1\n",
    "        \n",
    "        if (batch_count +1)%25 ==0:\n",
    "            train_log(t_loss,v_loss, sample_count, epoch)\n",
    "        e_count +=1\n",
    "        clear_output()\"\"\"\n",
    "        \n",
    "    \n",
    "\"\"\"if col_dict['size'][0]!= col_dict['size'][1]:\n",
    "    wrap = 'UNwrapped'\n",
    "elif col_dict['size'][0]== col_dict['size'][1]:\n",
    "    wrap = 'Wrapped'\"\"\"\n",
    "\n",
    "def pipeline(hp, col_dict): \n",
    "    if col_dict['size'][0]== col_dict['size'][1]:\n",
    "        wrap = 'wrapped'\n",
    "    elif col_dict['size'][0]!= col_dict['size'][1]:\n",
    "        wrap = 'unwrapped'\n",
    "        \n",
    "    title = f\"{col_dict['colour']}_{wrap}_{col_dict['size']}\"\n",
    "\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = get_data()\n",
    "    \n",
    "    with wandb.init(project=title, config=hp):\n",
    "        config = wandb.config\n",
    "        model = build_net(lin_layer_size=config.lin_layer_size,\n",
    "                          dropout=config.dropout,\n",
    "                          first_lin_lay=config.first_lin_lay,\n",
    "                          ks= config.kernal_size,\n",
    "                          in_chan=config.in_chan).to(device)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        \n",
    "        train_model(model, x_train, y_train, x_val, y_val,loss_fn, config, col_dict)\n",
    "        test_loop(model, x_test, y_test, loss_fn, device, col_dict,title)\n",
    "        \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colour': 'colour', 'size': [36, 113]}\n",
      "different\n"
     ]
    }
   ],
   "source": [
    "print(col_dict)\n",
    "if col_dict['size'][0]== col_dict['size'][1]:\n",
    "    print('same')\n",
    "elif col_dict['size'][0]!= col_dict['size'][1]:\n",
    "    print('different')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/its/home/nn268/optics/wandb/run-20231005_154416-6mxcu86y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antvis/colour_UNwrapped_%5B36%2C%20113%5D/runs/6mxcu86y' target=\"_blank\">vital-violet-8</a></strong> to <a href='https://wandb.ai/antvis/colour_UNwrapped_%5B36%2C%20113%5D' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antvis/colour_UNwrapped_%5B36%2C%20113%5D' target=\"_blank\">https://wandb.ai/antvis/colour_UNwrapped_%5B36%2C%20113%5D</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antvis/colour_UNwrapped_%5B36%2C%20113%5D/runs/6mxcu86y' target=\"_blank\">https://wandb.ai/antvis/colour_UNwrapped_%5B36%2C%20113%5D/runs/6mxcu86y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-8-759d35540b03>\", line 117, in pipeline\n",
      "    train_model(model, x_train, y_train, x_val, y_val,loss_fn, config, col_dict)\n",
      "  File \"/its/home/nn268/optics/fns4wandb.py\", line 120, in train_model\n",
      "    t_loss, predict_list, t_num_correct, model, optimizer = loop(model, x_train, y_train, epoch, loss_fn, device, col_dict, optimizer=optimizer)\n",
      "NameError: name 'loop' is not defined\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9288ea8104334cb8babb124bafc238dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vital-violet-8</strong> at: <a href='https://wandb.ai/antvis/colour_UNwrapped_%5B36%2C%20113%5D/runs/6mxcu86y' target=\"_blank\">https://wandb.ai/antvis/colour_UNwrapped_%5B36%2C%20113%5D/runs/6mxcu86y</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231005_154416-6mxcu86y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'loop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e0a327fa363a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-759d35540b03>\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(hp, col_dict)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/optics/fns4wandb.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train, x_val, y_val, loss_fn, config, col_dit)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mt_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_num_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0msample_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loop' is not defined"
     ]
    }
   ],
   "source": [
    "model = pipeline(config, col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ykh64eg1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_lin_lay: 10240\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernal_size: [3, 5]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008285560907048908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlin_layer_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_fn: MSE\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/its/home/nn268/optics/wandb/run-20231002_161659-ykh64eg1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/runs/ykh64eg1' target=\"_blank\">apricot-sweep-1</a></strong> to <a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/sweeps/36wsgole' target=\"_blank\">https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/sweeps/36wsgole</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113' target=\"_blank\">https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/sweeps/36wsgole' target=\"_blank\">https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/sweeps/36wsgole</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/runs/ykh64eg1' target=\"_blank\">https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/runs/ykh64eg1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#wandb.agent(sweep_id, train, count=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
