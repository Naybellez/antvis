{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 050224\n",
    "# testing dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as maths\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "#from torchsummary import summary\n",
    "#import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "import pprint\n",
    "\n",
    "\n",
    "from functions import import_imagedata, get_data, label_oh_tf,  Unwrap, ImageProcessor,IDSWDataSetLoader\n",
    "from architectures import sevennet, smallnet1, smallnet2, smallnet3, build_net\n",
    "from loop_fns import loop, test_loop\n",
    "from fns4wandb import build_optimizer, set_optimizer, train_model, train_log, log_test_score, set_lossfn, pipeline\n",
    "\n",
    "\n",
    "from fns4wandb import hp_sweep_DL\n",
    "import pickle\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "from fns4wandb import train\n",
    "from datetime import date\n",
    "\n",
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model,  x_train, x_val, y_train, y_val, config, best_acc=0): #train_dl, val_dl, \n",
    "\n",
    "    \n",
    "    \n",
    "    loss_fn = set_lossfn(config['loss_fn']) # ****\n",
    "    \n",
    "    lr = config['learning_rate'] #1e-5 #config.learning_rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)#build_optimizer(model, optimizer=torch.optim.Adam(model.parameters(), lr=lr))#config.optimizer, config.learning_rate, config.weight_decay)\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=config['scheduler'], last_epoch=-1) #gamma=config.scheduler, last_epoch=-1)\n",
    "                                                                    #scheduler'\n",
    "    ####\n",
    "    \n",
    "    #model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    #losses= []\n",
    "    #predictions = []\n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "\n",
    "    \n",
    "    total_epochs = 0\n",
    "    for epoch in tqdm(range(config['epochs'])): #config.epochs)):\n",
    "        if epoch ==0:\n",
    "            best_model=model\n",
    "            best_acc=0\n",
    "\n",
    "        t_loss, train_prediction, t_correct, model, optimizer = loop(model=model, X=x_train, Y=y_train, loss_fn=loss_fn, device=device, col_dict=col_dict, num_classes=11, model_name= config['model_name'], optimizer=optimizer, scheduler =scheduler)\n",
    "        \n",
    "        \n",
    "        save_dict['t_loss_list'] = t_loss_list\n",
    "        save_dict['t_labels'] = y_train\n",
    "        save_dict['t_predict_list'] = t_predict_list \n",
    "\n",
    "        train_acc = (t_correct / len(x_train))\n",
    "        t_accuracy_list.append(train_acc)\n",
    "        \n",
    "        save_dict['t_accuracy_list'] = t_accuracy_list \n",
    "        clear_output()\n",
    "        \n",
    "            \n",
    "        print('validating...')\n",
    "        \n",
    "        v_loss, val_prediction, val_correct= loop(model=model, X=x_val, Y=y_val, loss_fn=loss_fn, device=device, col_dict=col_dict, num_classes=11, model_name= config['model_name'], train=False)\n",
    "\n",
    "\n",
    "        save_dict['v_loss_list'] = v_loss_list\n",
    "        save_dict['v_predict_list'] = v_predict_list  #\n",
    "        save_dict['v_labels'] = y_val\n",
    "        \n",
    "        val_acc = (t_correct / len(x_val))\n",
    "        v_accuracy_list.append(val_acc)\n",
    "        save_dict['v_accuracy_list'] = v_accuracy_list  #\n",
    "        \n",
    "\n",
    "        clear_output()\n",
    "            \n",
    "        total_epochs += epoch\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "\n",
    "            best_acc = val_acc\n",
    "\n",
    "            best_model = model#deepcopy(model)\n",
    "            \n",
    "            save_dict['Current_Epoch'] += config['epochs']\n",
    "            save_dict['training_samples'] = len(x_train)\n",
    "            save_dict['validation_samples'] = len(x_val)\n",
    "            \n",
    "\n",
    "            title = save_dict['Run']\n",
    "            save_location = save_dict['save_location']\n",
    "            conf= dict(config)\n",
    "            diction = {}\n",
    "            d = date.today()\n",
    "            d=str(d)\n",
    "            diction.update({'Date':d})\n",
    "            diction.update(save_dict)\n",
    "            diction.update(conf)\n",
    "            diction.update(col_dict)\n",
    "            print(diction)\n",
    "            \n",
    "            save2json(conf, title, save_location)\n",
    "            save2csv(diction, title, save_location)\n",
    "            \n",
    "            diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "            \n",
    "            with open(f\"{save_location}{title}.pkl\", 'wb+') as f:\n",
    "                pickle.dump(diction, f)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print('improvment in metrics. model saved')\n",
    "\n",
    "            #print('END Of SAve -----------------------------')\n",
    "            #!nvidia-smi\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "    model = best_model\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def pipeline(config, save_dict, col_dict): \n",
    "    # set model\n",
    "    l = config['f_lin_lay']\n",
    "    \n",
    "    \n",
    "    # load in data\n",
    "    file_path =  r'//smbhome.uscs.susx.ac.uk/nn268/Documents/PHD/antvis/optics/AugmentedDS_IDSW/'\n",
    "    random_seed =1\n",
    "    img_len = len(os.listdir(file_path))\n",
    "\n",
    "\n",
    "    #print(ids[4])\n",
    "    x, y = import_imagedata(file_path)\n",
    "\n",
    "    x_train, x_test, y_train, y_tests = train_test_split(x,y, test_size=0.2, train_size=0.8,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.1, train_size=0.8,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "\n",
    "    x_train, x_val = x_train[:2], x_val[:2] # for testing purposes, shortened data\n",
    "    #!nvidia-smi\n",
    "    \n",
    "    loss_list=[]\n",
    "    #loss_fn = nn.CrossEntropyLoss()\n",
    "    #loss_fn = nn.MSELoss()\n",
    "    title=save_dict['Run']\n",
    "    \n",
    "    \"\"\"l = config['f_lin_lay']\n",
    "    model_vgg16 = vgg16(weights=\"IMAGENET1K_V1\")\n",
    "    vgg_feats = model_vgg16.features\n",
    "    vgg_classifier = model_vgg16.classifier\n",
    "    #print(vgg_classifier)\n",
    "    vgg_classifier.pop(6)\n",
    "    vgg = nn.Sequential(\n",
    "        vgg_feats,\n",
    "        Flattern(),\n",
    "        vgg_classifier,\n",
    "        nn.Linear(l,11),\n",
    "        nn.Softmax(dim=0),\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    model =sevennet(in_chan=3, f_lin_lay=config['f_lin_lay'], l_lin_lay=11, ks=config['ks'], dropout = config['dropout']).to(device)\n",
    "    #model = vgg\n",
    "    model = train_model(model,x_train, x_val, y_train, y_val, config) #train_dl, val_dl\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"model_name\" : '7c3l',\n",
    "    \"epochs\" :2, \n",
    "    \"learning_rate\" : 5.97E-05, #6.62E-05, #5.97E-05, #6.01E-05, #6.62E-05, #0.00, 00821591686076769, #8e-5,\n",
    "    \"dataset\" : 'IDSW_Aug',\n",
    "    \"architecture\" :'CNN',\n",
    "    \"optimizer\": 'adam',\n",
    "    \"loss_fn\" : 'CrossEntropy',\n",
    "    \"weight_decay\": 2e-5, #4e-5, #2e-5, #3.00E-05,\n",
    "    \"dropout\" : 0.4, #0.4,\n",
    "    \"lin_layer_size\": 100,\n",
    "    \"ks\" : [3,5],\n",
    "    \"in_chan\" : 3,\n",
    "    \"num_classes\" :11,\n",
    "    \"scheduler\" : 0.2,\n",
    "    \"channels\": 3,\n",
    "    \"f_lin_lay\" :4096\n",
    "    , \n",
    "     \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#r'/its/home/nn268/antvis/optics/\n",
    "#pickles\n",
    "col_dict = {\n",
    "    'colour': 'colour',\n",
    "    'size': [8,3],\n",
    "    'pad': 0,\n",
    "    'model_size': '2c2l'\n",
    "}\n",
    "\n",
    "\n",
    "save_dict = {'Run' : title,\n",
    "            'Current_Epoch': 0,\n",
    "             title = f\"\",\n",
    "            'save_location' : r'pickles/'}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 452, 3)\n",
      "(3, 8, 3)\n",
      "torch.Size([3, 3, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (4 x 2). Kernel size: (3 x 5). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m pipeline(config, save_dict, col_dict)\n",
      "Cell \u001b[1;32mIn[20], line 160\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(config, save_dict, col_dict)\u001b[0m\n\u001b[0;32m    158\u001b[0m model \u001b[38;5;241m=\u001b[39msevennet(in_chan\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, f_lin_lay\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf_lin_lay\u001b[39m\u001b[38;5;124m'\u001b[39m], l_lin_lay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m, ks\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mks\u001b[39m\u001b[38;5;124m'\u001b[39m], dropout \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m#model = vgg\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(model,x_train, x_val, y_train, y_val, config) \u001b[38;5;66;03m#train_dl, val_dl\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[1;32mIn[20], line 36\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, x_train, x_val, y_train, y_val, config, best_acc)\u001b[0m\n\u001b[0;32m     33\u001b[0m     best_model\u001b[38;5;241m=\u001b[39mmodel\n\u001b[0;32m     34\u001b[0m     best_acc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 36\u001b[0m t_loss, train_prediction, t_correct, model, optimizer \u001b[38;5;241m=\u001b[39m loop(model\u001b[38;5;241m=\u001b[39mmodel, X\u001b[38;5;241m=\u001b[39mx_train, Y\u001b[38;5;241m=\u001b[39my_train, loss_fn\u001b[38;5;241m=\u001b[39mloss_fn, device\u001b[38;5;241m=\u001b[39mdevice, col_dict\u001b[38;5;241m=\u001b[39mcol_dict, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m], optimizer\u001b[38;5;241m=\u001b[39moptimizer, scheduler \u001b[38;5;241m=\u001b[39mscheduler)\n\u001b[0;32m     39\u001b[0m save_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_loss_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m t_loss_list\n\u001b[0;32m     40\u001b[0m save_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_labels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_train\n",
      "File \u001b[1;32m~\\OneDrive - University of Sussex\\Sussex\\phd\\antvis_exp1\\feb24\\loop_fns.py:58\u001b[0m, in \u001b[0;36mloop\u001b[1;34m(model, X, Y, loss_fn, device, col_dict, num_classes, model_name, optimizer, scheduler, train)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     tense \u001b[38;5;241m=\u001b[39m prepro\u001b[38;5;241m.\u001b[39mcolour_size_tense(img, colour, size, pad)\n\u001b[1;32m---> 58\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(tense)\n\u001b[0;32m     59\u001b[0m label \u001b[38;5;241m=\u001b[39m label_oh_tf(Y[idx], num_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m#if train:\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#\tlr_ls.append(optimizer.param_groups[0]['lr'])\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive - University of Sussex\\Sussex\\phd\\antvis_exp1\\feb24\\architectures.py:53\u001b[0m, in \u001b[0;36msevennet.<locals>.SevenNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;66;03m#forward method. opposition to backward pass\u001b[39;00m\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;66;03m#print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m   x\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_layers(x)\n\u001b[0;32m     54\u001b[0m   x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     55\u001b[0m   x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (4 x 2). Kernel size: (3 x 5). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "class Flattern(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flattern, self).__init__()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.flatten()\n",
    "        return x\n",
    "\n",
    "model = pipeline(config, save_dict, col_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
