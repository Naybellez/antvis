{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision.models import vgg16\n",
    "#from torchvision.models import resnet101\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "from fns4wandb import train_log, build_optimizer, set_lossfn\n",
    "\n",
    "from functions import save2csv, save2json, read_in_json, import_imagedata, label_oh_tf, ImageProcessor\n",
    "#from loop_fns import loop\n",
    "\n",
    "import pickle\n",
    "import csv\n",
    "import json\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_vgg16 = vgg16(weights=\"IMAGENET1K_V1\")\n",
    "vgg_feats = model_vgg16.features\n",
    "vgg_classifier = model_vgg16.classifier\n",
    "print(vgg_classifier)\n",
    "vgg_classifier.pop(6)\n",
    "print(vgg_classifier)\n",
    "#print(vgg_feats)\n",
    "#print(model_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(label, prediction): #TypeError: Singleton array tensor(3) cannot be considered a valid collection.\n",
    "    \n",
    "    label= np.array(label.cpu())\n",
    "\n",
    "    predictions_np = prediction.cpu().detach().numpy()\n",
    "    #y_pred' parameter of f1_score must be an array-like or a sparse matrix. Got 7 instead.\n",
    "    predicted_classes = np.argmax(predictions_np, axis=0)\n",
    "    #print('metrics Label:   ', label)\n",
    "    #print('metrics prediction   ', predicted_classes)\n",
    "    #avg_f1_score = f1_score(label, predictions_np, average='macro')\n",
    "    acc = accuracy_score(label, predicted_classes)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in x_train[:3]:\\n    print(i[59:])\\n    print(len(i))\\n    #i=i[59:]\\n    #k = cv2.imread(i)\\n    #print(k, type(k))\\n    k = preprocess_im(i)\\n    \\n    k = k.squeeze()\\n    k = k.permute(1,2,0)\\n    k = np.array(k.cpu())*5\\n    plt.imshow(k)\\n    plt.show()'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for i in x_train[:3]:\n",
    "    print(i[59:])\n",
    "    print(len(i))\n",
    "    #i=i[59:]\n",
    "    #k = cv2.imread(i)\n",
    "    #print(k, type(k))\n",
    "    k = preprocess_im(i)\n",
    "    \n",
    "    k = k.squeeze()\n",
    "    k = k.permute(1,2,0)\n",
    "    k = np.array(k.cpu())*5\n",
    "    plt.imshow(k)\n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaughticalnonsence\u001b[0m (\u001b[33mantvis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nn268\\Desktop\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "#r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squeeze(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Squeeze, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        x = x.squeeze(0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nconfig = {\\n    'method': 'random',\\n    'metric':{\\n        'goal': 'minimize',\\n        'name': 'val_loss'},\\n    'parameters': {\\n        #'dropout':{\\n        #    'values': [0.5, 0.4, 0.3]\\n        #},\\n        'epochs':{\\n            'value': 3\\n        },\\n\\n        'first_lin_lay':{\\n            'values':[248832]\\n        },\\n        'optimizer': {\\n            'values': ['adam']\\n        },\\n        'learning_rate': {\\n                # a flat distribution between 0 and 0.1\\n                'distribution': 'log_uniform_values',\\n                'min': 1e-7,\\n                'max': 1e-2\\n            },\\n        'loss_fn': {\\n            'values': ['CrossEntropy', 'MSE'] #'MSE', \\n        },\\n        'data_set':{\\n            'values':['Augmented']\\n        },\\n            'scheduler': {\\n            'values': [0.2, 0.3, 0.4, 0.6]\\n        },\\n        'ks': {\\n            'values': [(3,5)]\\n        },\\n        'channels':{\\n            'values': [3]\\n        },\\n        'num_classes': {\\n            'values': [11]\\n        },\\n        'model_name' : {'values': ['vgg16net_mlp']},\\n        'channels' : {'values': [3]},\\n        'image_path': {\\n            'values': [r'//smbhome.uscs.susx.ac.uk/nn268/Documents/PHD/antvis/optics/AugmentedDS_IDSW/']\\n        }\\n        }\\n    }\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "    epochs= 2, #30, \n",
    "    learning_rate =1.00E-05,\n",
    "    architecture ='CNN',\n",
    "    optimizer= 'adam',\n",
    "    weight_decay= 4e-5,\n",
    "    ks = (3,5),\n",
    "    loss_fn = 'CrossEntropy',\n",
    "    scheduler=0.2,\n",
    "    f_lin_lay = 4096, #7168 #1024*7 = 7168 4096\n",
    "    random_seed = 1,\n",
    ")\n",
    "\n",
    "save_dict = {'Run' :'IDSW_VGG16_fine_280224_TEST',\n",
    "            'Current_Epoch': 0,\n",
    "            'save_location' : r'C:/Users/nn268/OneDrive - University of Sussex/Sussex/phd/antvis_exp1/saves/'}\n",
    "\n",
    "col_dict =dict(\n",
    "    pad = 5,\n",
    "    colour = 'colour',\n",
    "    size = [113,36]\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "config = {\n",
    "    'method': 'random',\n",
    "    'metric':{\n",
    "        'goal': 'minimize',\n",
    "        'name': 'val_loss'},\n",
    "    'parameters': {\n",
    "        #'dropout':{\n",
    "        #    'values': [0.5, 0.4, 0.3]\n",
    "        #},\n",
    "        'epochs':{\n",
    "            'value': 3\n",
    "        },\n",
    "\n",
    "        'first_lin_lay':{\n",
    "            'values':[248832]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam']\n",
    "        },\n",
    "        'learning_rate': {\n",
    "                # a flat distribution between 0 and 0.1\n",
    "                'distribution': 'log_uniform_values',\n",
    "                'min': 1e-7,\n",
    "                'max': 1e-2\n",
    "            },\n",
    "        'loss_fn': {\n",
    "            'values': ['CrossEntropy', 'MSE'] #'MSE', \n",
    "        },\n",
    "        'data_set':{\n",
    "            'values':['Augmented']\n",
    "        },\n",
    "            'scheduler': {\n",
    "            'values': [0.2, 0.3, 0.4, 0.6]\n",
    "        },\n",
    "        'ks': {\n",
    "            'values': [(3,5)]\n",
    "        },\n",
    "        'channels':{\n",
    "            'values': [3]\n",
    "        },\n",
    "        'num_classes': {\n",
    "            'values': [11]\n",
    "        },\n",
    "        'model_name' : {'values': ['vgg16net_mlp']},\n",
    "        'channels' : {'values': [3]},\n",
    "        'image_path': {\n",
    "            'values': [r'//smbhome.uscs.susx.ac.uk/nn268/Documents/PHD/antvis/optics/AugmentedDS_IDSW/']\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "#sweep_id = wandb.sweep(config, project=f\"{run_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def luminance(img):\n",
    "    r,g,b = img[:,:,2], img[:,:,1], img[:,:,0]\n",
    "    lum =(0.114*b)+(0.587*g)+(0.299*r)\n",
    "    mean_lum = np.mean(lum)\n",
    "    return mean_lum\n",
    "    \n",
    "\"\"\"\n",
    "ValueError: could not broadcast input array from shape (224,224,3) into shape (0,224,3)\n",
    "blank padding (144, 452, 3)\n",
    "\"\"\"\n",
    "\n",
    "def blank_padding(col_dict, img, size:tuple):\n",
    "\n",
    "    img = cv2.resize(img, col_dict['size']) \n",
    "    w = size[1]\n",
    "    h = size[0]\n",
    "\n",
    "    delta_w = w -img.shape[1]\n",
    "    delta_h = h-img.shape[0]\n",
    "\n",
    "    half_delta_h = int(np.floor(delta_h/2))\n",
    "    half_delta_w = int(np.floor(delta_w/2))\n",
    "    \n",
    "    avg_lum = int(luminance(img))\n",
    "    new_x = np.full((h,w,3), avg_lum) \n",
    "\n",
    "    if img.shape[1]%2 ==0:\n",
    "        if img.shape[0]%2 == 0:\n",
    "            new_x[half_delta_h:-half_delta_h,half_delta_w:-half_delta_w,:] = img\n",
    "        else:\n",
    "            new_x[half_delta_h:-(half_delta_h+1),half_delta_w:-half_delta_w,:] = img\n",
    "    else:\n",
    "        if img.shape[0]%2 == 0:\n",
    "            new_x[half_delta_h:-half_delta_h,half_delta_w:-(half_delta_w+1),:] = img #*#*#\n",
    "        else:\n",
    "            new_x[half_delta_h:-(half_delta_h+1),half_delta_w:-(half_delta_w+1),:] = img\n",
    "            \n",
    "    return new_x\n",
    "\n",
    "\n",
    "def to_tensor(img):\n",
    "    im_chan = img.shape[2]\n",
    "    imgy, imgx = img.shape[0], img.shape[1]\n",
    "    tensor = torch.tensor(img, dtype=torch.float32)\n",
    "    tensor = F.normalize(tensor)\n",
    "    tensor = tensor.permute(2,0,1)\n",
    "    tensor = tensor.reshape(im_chan,imgy, imgx)\n",
    "    return tensor\n",
    "    \n",
    "def preprocess_im(col_dict, img_path:str):\n",
    "    img = cv2.imread(img_path) #\n",
    "    if img is not None:\n",
    "        #print('1',img.shape)\n",
    "        img = blank_padding(col_dict, img, (224,224))\n",
    "        #print('2',img.shape)\n",
    "        img = to_tensor(img).to(device)\n",
    "        #print(img.shape)\n",
    "        return img\n",
    "    else:\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def loop(model, X, Y, loss_fn, device, col_dict, num_classes, pad_size =5, optimizer =None, scheduler= None, train =True):\t# Train and Val loops. Default is train\n",
    "    model = model\n",
    "    total_samples = len(X)\n",
    "    if train:\n",
    "        model.train()\n",
    "        #lr_ls = []\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    predict_list = []\n",
    "    total_count = 0\n",
    "    num_correct = 0\n",
    "    current_loss = 0\n",
    "    colour = col_dict['colour']\n",
    "    size = col_dict['size']\n",
    "    pad = col_dict['pad']\n",
    "    issue_list =[]\n",
    "\n",
    "    for idx, img in enumerate(X):\n",
    "        #tense = tensoring(img).to(device)\n",
    "        #prepro = ImageProcessor(device)\n",
    "        \n",
    "        tense = preprocess_im(col_dict, img_path= img) # col_dict, img_path:str\n",
    "        if tense is None:\n",
    "            issue_list.append((idx, img))\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "            prediction = model.forward(tense)\n",
    "            label = label_oh_tf(Y[idx], num_classes).to(device)\n",
    "            #if train:\n",
    "            #\tlr_ls.append(optimizer.param_groups[0]['lr'])\n",
    "            loss = loss_fn(prediction, label)\n",
    "            predict_list.append(prediction.argmax())\n",
    "\n",
    "            if prediction.argmax() == label.argmax():\n",
    "                num_correct +=1\n",
    "                #if train:\n",
    "                #\tprint(f'\\n ########################### HIT ###########################  -- {idx} / {total_samples} \\n')\n",
    "            total_count+=1\n",
    "            current_loss += loss.item()\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "        #print(num_correct/len(X))\n",
    "    if train:\n",
    "        return current_loss, predict_list, num_correct, model, optimizer, issue_list #, lr_ls\n",
    "    else:\n",
    "        return current_loss, predict_list, num_correct, issue_list\n",
    "\n",
    "\n",
    "\n",
    "def test_loop(model, X, Y, loss_fn, device, col_dict,title, num_classes):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    colour = col_dict['colour']\n",
    "    size = col_dict['size']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, img in enumerate(X):\n",
    "            #prepro = ImageProcessor(device)\n",
    "            #tense = prepro.colour_size_tense(img, colour, size)\n",
    "            tense = preprocess_im(img)\n",
    "            prediction = model.forward(tense)\n",
    "            label = label_oh_tf(Y[idx], num_classes).to(device)\n",
    "\n",
    "            if prediction.argmax()==label.argmax():\n",
    "                num_correct +=1\n",
    "            total_count +=1\n",
    "            correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "\n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "\n",
    "        X = list(X)\n",
    "        log_test_score(acc, accuracy, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model,  x_train, x_val, y_train, y_val, config, best_acc=0): #train_dl, val_dl, \n",
    "    wandb.watch(model, log='all', log_freq=10)\n",
    "    \n",
    "    loss_fn = set_lossfn(config.loss_fn) # ****\n",
    "    \n",
    "    lr = config['learning_rate'] #1e-5 #config.learning_rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)#build_optimizer(model, optimizer=torch.optim.Adam(model.parameters(), lr=lr))#config.optimizer, config.learning_rate, config.weight_decay)\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=config.scheduler, last_epoch=-1) #gamma=config.scheduler, last_epoch=-1)\n",
    "                                                                    #scheduler'\n",
    "    ####\n",
    "    \n",
    "    #model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    #losses= []\n",
    "    #predictions = []\n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "    issue_list = []\n",
    "    \n",
    "    total_epochs = 0\n",
    "    for epoch in tqdm(range(config['epochs'])): #config.epochs)):\n",
    "        if epoch ==0:\n",
    "            best_model=model\n",
    "            best_acc=0\n",
    "                                  \n",
    "        t_loss, train_prediction, t_correct, model, optimizer, t_issue_list = loop(model=model, X=x_train, Y=y_train, loss_fn=loss_fn, device=device, col_dict=col_dict, num_classes=11, pad_size=col_dict['pad'], optimizer=optimizer, scheduler =scheduler)\n",
    "        \n",
    "        \n",
    "        save_dict['t_loss_list'] = t_loss_list\n",
    "        save_dict['t_labels'] = y_train\n",
    "        save_dict['t_predict_list'] = t_predict_list \n",
    "\n",
    "        train_acc = (t_correct / len(x_train))\n",
    "        t_accuracy_list.append(train_acc)\n",
    "        \n",
    "        save_dict['t_accuracy_list'] = t_accuracy_list \n",
    "        clear_output()\n",
    "        \n",
    "            \n",
    "        print('validating...')\n",
    "        \n",
    "        v_loss, val_prediction, val_correct, v_issue_list = loop(model=model, X=x_val, Y=y_val, loss_fn=loss_fn, device=device, col_dict=col_dict, num_classes=11, pad_size=col_dict['pad'], train=False)\n",
    "\n",
    "\n",
    "        save_dict['v_loss_list'] = v_loss_list\n",
    "        save_dict['v_predict_list'] = v_predict_list  #\n",
    "        save_dict['v_labels'] = y_val\n",
    "        \n",
    "        val_acc = (t_correct / len(x_val))\n",
    "        v_accuracy_list.append(val_acc)\n",
    "        save_dict['v_accuracy_list'] = v_accuracy_list  #\n",
    "        \n",
    "        issue_list.append([t_issue_list, v_issue_list])\n",
    "        clear_output()\n",
    "            \n",
    "        total_epochs += epoch\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "\n",
    "            best_acc = val_acc\n",
    "\n",
    "            best_model = model#deepcopy(model)\n",
    "            \n",
    "            save_dict['Current_Epoch'] += config['epochs']\n",
    "            save_dict['training_samples'] = len(x_train)\n",
    "            save_dict['validation_samples'] = len(x_val)\n",
    "\n",
    "            \n",
    "            model_architecture = [nn.Sequential(\n",
    "                PrintLayer(),\n",
    "                vgg_feats,\n",
    "                PrintLayer(),\n",
    "                Flattern(),\n",
    "                PrintLayer(),\n",
    "                vgg_classifier,\n",
    "                PrintLayer(),\n",
    "                nn.Linear(4096,11),\n",
    "                nn.Softmax(dim=0),\n",
    "            )]\n",
    "\n",
    "            \n",
    "\n",
    "            title = save_dict['Run']\n",
    "            save_location = save_dict['save_location']\n",
    "            conf= dict(config)\n",
    "            diction = {}\n",
    "            d = date.today()\n",
    "            d=str(d)\n",
    "            diction.update({'Date':d})\n",
    "            diction.update(save_dict)\n",
    "            diction.update(conf)\n",
    "            diction.update(col_dict)\n",
    "            print(diction)\n",
    "            \n",
    "            save2json(conf, title, save_location)\n",
    "            save2csv(diction, title, save_location)\n",
    "            \n",
    "            diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "            diction['model_architecture_untrained'] = model_architecture\n",
    "            \n",
    "            with open(f\"{save_location}{title}.pkl\", 'wb+') as f:\n",
    "                pickle.dump(diction, f)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print('improvment in metrics. model saved')\n",
    "\n",
    "            #print('END Of SAve -----------------------------')\n",
    "            #!nvidia-smi\n",
    "\n",
    "        \n",
    "\n",
    "        if (epoch+1)%2==0:\n",
    "            train_log(t_loss, v_loss, epoch)\n",
    "            wandb.log({'train_accuracy_%': train_acc, 'epoch':epoch})\n",
    "            wandb.log({'val_accuracy_%': val_acc, 'epoch':epoch})\n",
    "            \n",
    "    model = best_model\n",
    "\n",
    "    return model\n",
    "\n",
    "class Flattern(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flattern, self).__init__()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.flatten()\n",
    "        return x\n",
    "\n",
    "class PrintLayer(nn.Module):\n",
    "    # usefule for printing network layers\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "def pipeline(config, save_dict, col_dict): \n",
    "    # set model\n",
    "    l = config['f_lin_lay']\n",
    "    model_vgg16 = vgg16(weights=\"IMAGENET1K_V1\")\n",
    "    vgg_feats = model_vgg16.features\n",
    "    vgg_classifier = model_vgg16.classifier\n",
    "    print(vgg_classifier)\n",
    "    vgg_classifier.pop(6)\n",
    "    vgg = nn.Sequential(\n",
    "        PrintLayer(),\n",
    "        vgg_feats,\n",
    "        PrintLayer(),\n",
    "        Flattern(),\n",
    "        #Squeeze(),\n",
    "        #Flattern(),\n",
    "        PrintLayer(),\n",
    "        vgg_classifier,\n",
    "        PrintLayer(),\n",
    "        nn.Linear(l,11),\n",
    "        nn.Softmax(dim=0),\n",
    "        )\n",
    "    \n",
    "    #model_vgg16.to('cpu')\n",
    "    \n",
    "    vgg.to(device)\n",
    "    \n",
    "    # load in data\n",
    "    file_path =  r'//smbhome.uscs.susx.ac.uk/nn268/Documents/PHD/antvis/optics/AugmentedDS_IDSW/'\n",
    "    random_seed =1\n",
    "    img_len = len(os.listdir(file_path))\n",
    "\n",
    "\n",
    "    #print(ids[4])\n",
    "    x, y = import_imagedata(file_path)\n",
    "\n",
    "    x_train, x_test, y_train, y_tests = train_test_split(x,y, test_size=0.2, train_size=0.8,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.1, train_size=0.8,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "\n",
    "    x_train, y_train = x_train[:10], y_train[:10] # for testing purposes, shortened data\n",
    "    x_val, y_val = x_val[:10], y_val[:10]#\n",
    "    #!nvidia-smi\n",
    "    \n",
    "    loss_list=[]\n",
    "    #loss_fn = nn.CrossEntropyLoss()\n",
    "    #loss_fn = nn.MSELoss()\n",
    "    title=save_dict['Run']\n",
    "    with wandb.init(project=title, config=config):\n",
    "        config = wandb.config\n",
    "        model = vgg\n",
    "\n",
    "        model = train_model(model,x_train, x_val, y_train, y_val, config) #train_dl, val_dl\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:00<00:00, 30.48s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁</td></tr><tr><td>t_loss</td><td>▁</td></tr><tr><td>train_accuracy_%</td><td>▁</td></tr><tr><td>v_loss</td><td>▁</td></tr><tr><td>val_accuracy_%</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>t_loss</td><td>24.06439</td></tr><tr><td>train_accuracy_%</td><td>0.0</td></tr><tr><td>v_loss</td><td>24.00764</td></tr><tr><td>val_accuracy_%</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-pine-38</strong> at: <a href='https://wandb.ai/antvis/IDSW_VGG16_fine_280224_TEST/runs/y7waw162' target=\"_blank\">https://wandb.ai/antvis/IDSW_VGG16_fine_280224_TEST/runs/y7waw162</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240229_124535-y7waw162\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline(config, save_dict, col_dict) #7,168\n",
    "\n",
    "#def tr(config=None):\n",
    "#    with wandb.init(config=config):\n",
    "#        config = wandb.config\n",
    "#        model, save_dict = pipeline(config)\n",
    "        \n",
    "\n",
    "#wandb.agent(sweep_id, tr, count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential(\n",
    "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "  (1): ReLU(inplace=True)\n",
    "  (2): Dropout(p=0.5, inplace=False)\n",
    "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "  (4): ReLU(inplace=True)\n",
    "  (5): Dropout(p=0.5, inplace=False)\n",
    "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    ")\n",
    "Sequential(\n",
    "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "  (1): ReLU(inplace=True)\n",
    "  (2): Dropout(p=0.5, inplace=False)\n",
    "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "  (4): ReLU(inplace=True)\n",
    "  (5): Dropout(p=0.5, inplace=False)\n",
    ")\n",
    "\n",
    "\n",
    "    vgg = nn.Sequential(\n",
    "        PrintLayer(),\n",
    "        vgg_feats,\n",
    "        PrintLayer(),\n",
    "        Flattern(),\n",
    "        #Squeeze(),\n",
    "        #Flattern(),\n",
    "        PrintLayer(),\n",
    "        vgg_classifier,\n",
    "        PrintLayer(),\n",
    "        nn.Linear(l,11),\n",
    "        nn.Softmax(dim=0),\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{save_dict['save_location']}{title}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    vgg = nn.Sequential(\n",
    "        vgg_feats,\n",
    "        Squeeze(),\n",
    "        Flattern(),\n",
    "        vgg_classifier,\n",
    "        \n",
    "        nn.Linear(4096,11),\n",
    "        nn.Softmax(dim=0),\n",
    "        )\n",
    "#print(vgg)\n",
    "\n",
    "print(vgg_feats)\n",
    "print('------------------------------------')\n",
    "print(vgg_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "\n",
    "def plot_confusion(predictions:list, actual:list, title:str):\n",
    "    predict_list = [int(t.argmax()) for t in predictions]\n",
    "    actual = [int(l.argmax()) for l in actual]\n",
    "\n",
    "    actual = np.array(actual)\n",
    "    predict_list = np.array(predict_list)\n",
    "\n",
    "\n",
    "    #FixedLocator locations (3), usually from a call to set_ticks, does not match the number of labels (11).\n",
    "    print(f'\\n     {title}')\n",
    "    train_epoch_matrix = confusion_matrix(actual, predict_list, labels= [0,1,2,3,4,5,6,7,8,9,10])\n",
    "    disp= ConfusionMatrixDisplay(train_epoch_matrix, display_labels=[0,1,2,3,4,5,6,7,8,9,10])\n",
    "    disp.plot()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_predict = save_dict['t_predict_list']\n",
    "t_labels = save_dict['t_labels']\n",
    "\n",
    "v_predict = save_dict['v_predict_list'] # WHY IS THERE NOTHING IN V OREDICT LIST!\n",
    "v_labels = save_dict['v_labels']\n",
    "\n",
    "plot_confusion(t_predict, t_labels, 'Train Confusion Matrix')\n",
    "plot_confusion(v_predict, v_labels, 'Validation Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =nn.Sequential(\n",
    "    PrintLayer(),\n",
    "    model_vgg16,\n",
    "    PrintLayer(),\n",
    "    Squeeze(),\n",
    "    PrintLayer(),\n",
    "    nn.Linear(4096,11),\n",
    "    PrintLayer(),\n",
    "    nn.Softmax(dim=0),\n",
    "    PrintLayer()\n",
    "\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(x_train[347])\n",
    "print(x_train[348])\n",
    "print(x_train[349])\n",
    "\n",
    "\n",
    "p0 = x_train[348]\n",
    "p_1 = x_train[347]\n",
    "p1 = x_train[349]\n",
    "\n",
    "p0 = cv2.imread(p0)\n",
    "p_1 = cv2.imread(p_1)\n",
    "p1 = cv2.imread(p1)\n",
    "\n",
    "plt.imshow(p0)\n",
    "p0 = cv2.resize(p0, [224, 72]) #img = cv2.resize(img, [224, 72])\n",
    "print(p0.shape)\n",
    "print(p_1.shape)\n",
    "plt.show()\n",
    "plt.imshow(p_1)\n",
    "p_1 = cv2.resize(p_1, [224,72])\n",
    "print(p_1.shape)\n",
    "plt.show()\n",
    "plt.imshow(p1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg = nn.Sequential(\n",
    "        model_vgg16,\n",
    "        Squeeze(),\n",
    "        nn.Linear(4096,11),\n",
    "        nn.Softmax(dim=0),\n",
    "    )\n",
    "\n",
    "#model_vgg16.to('cpu')\n",
    "\n",
    "vgg.to(device)\n",
    "next(vgg.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = preprocess_im(x_train[0])\n",
    "\n",
    "\n",
    "train_prediction = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to('cpu').state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
