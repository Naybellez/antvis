{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functions import import_imagedata, label_oh_tf, ImageProcessor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from torchvision.models import vgg16\n",
    "from torchvision.models import resnet101\n",
    "\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "from fns4wandb import train_log, build_optimizer\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from fns4wandb import set_lossfn\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_resnet = resnet101(weights=\"IMAGENET1K_V1\")#.eval\n",
    "\n",
    "newmodel = torch.nn.Sequential(*(list(model_resnet.children())[:-1]))\n",
    "newmodel=newmodel.to(device)\n",
    "print(newmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(label, prediction): #TypeError: Singleton array tensor(3) cannot be considered a valid collection.\n",
    "    \n",
    "    label= np.array(label.cpu())\n",
    "\n",
    "    predictions_np = prediction.cpu().detach().numpy()\n",
    "    #y_pred' parameter of f1_score must be an array-like or a sparse matrix. Got 7 instead.\n",
    "    predicted_classes = np.argmax(predictions_np, axis=0)\n",
    "    #print('metrics Label:   ', label)\n",
    "    #print('metrics prediction   ', predicted_classes)\n",
    "    #avg_f1_score = f1_score(label, predictions_np, average='macro')\n",
    "    acc = accuracy_score(label, predicted_classes)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_im(img):\n",
    "    IP = ImageProcessor(device='cpu')\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img_path) #\n",
    "    #imgx = img.shape[0]\n",
    "    #imgy = img.shape[1]\n",
    "    #img = img.reshape(imgx, imgy,1)\n",
    "    #img = IP.blank_padding(img, (224,224))\n",
    "    img = IP.to_tensor(img).to(device)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"file_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\\nrandom_seed =1\\nimg_len = len(os.listdir(file_path))\\n\\n\\n#print(ids[4])\\nx, y = import_imagedata(file_path)\\n\\nx_train, x_test, y_train, y_tests = train_test_split(x,y, test_size=0.2, train_size=0.8,\\n                                 random_state=random_seed, shuffle=True)\\nx_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.1, train_size=0.8,\\n                                 random_state=random_seed, shuffle=True)\\n\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get len of \n",
    "\n",
    "\"\"\"file_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "random_seed =1\n",
    "img_len = len(os.listdir(file_path))\n",
    "\n",
    "\n",
    "#print(ids[4])\n",
    "x, y = import_imagedata(file_path)\n",
    "\n",
    "x_train, x_test, y_train, y_tests = train_test_split(x,y, test_size=0.2, train_size=0.8,\n",
    "                                 random_state=random_seed, shuffle=True)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.1, train_size=0.8,\n",
    "                                 random_state=random_seed, shuffle=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'IDSW_resnet_fine_mnisttest_122023'\n",
    "save_dict = {'Run' : title,\n",
    "            'Current_Epoch': 0}\n",
    "                #r'/its/home/nn268/antvis/optics/\n",
    "save_location = r'pickles/'#pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run_title = \"IDSW_RESNET_hp_fine_112023\"\\n\\nconfig = {\\n    \\'method\\': \\'random\\',\\n    \\'metric\\':{\\n        \\'goal\\': \\'minimize\\',\\n        \\'name\\': \\'val_loss\\'},\\n    \\'parameters\\': {\\n        #\\'dropout\\':{\\n        #    \\'values\\': [0.5, 0.4, 0.3]\\n        #},\\n        \\'weight_decay\\':{\\n            \\'values\\': [1e-5,2e-5, 3e-5,4e-5]\\n        },\\n        \\'epochs\\':{\\n            \\'value\\': 120\\n        },\\n        \\'lin_layer_size\\': {\\n            \\'values\\': [100] #, 150, 50\\n        },\\n        \\'first_lin_lay\\':{\\n            \\'values\\':[248832]\\n        },\\n        \\'optimizer\\': {\\n            \\'values\\': [\\'adam\\']\\n        },\\n            \\'learning_rate\\': {\\n                # a flat distribution between 0 and 0.1\\n                \\'distribution\\': \\'log_uniform_values\\',\\n                \\'min\\': 1e-6,\\n                \\'max\\': 1e-3\\n            },\\n        \\'loss_fn\\': {\\n            \\'values\\': [\\'CrossEntropy\\'] #\\'MSE\\', \\n        },\\n        \\'data_set\\':{\\n            \\'values\\':[\\'Augmented\\']\\n        },\\n            \\'scheduler\\': {\\n            \\'values\\': [0.2, 0.3, 0.4, 0.6]\\n        },\\n        \\'ks\\': {\\n            \\'values\\': [(3,5)]\\n        },\\n        \\'dropout\\':{\\n            \\'values\\': [0.5, 0.4, 0.3]\\n        },\\n        \\'channels\\':{\\n            \\'values\\': [3]\\n        },\\n        \\'num_classes\\': {\\n            \\'values\\': [10]\\n        },\\n        \\'model_name\\' : {\\'values\\': [\\'resnet_mlp\\']},\\n        \\'channels\\' : {\\'values\\': [3]},\\n        \\'image_path\\': {\\n            \\'values\\': [r\\'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/\\']\\n        }\\n        }\\n    }\\n\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"run_title = \"IDSW_RESNET_hp_fine_112023\"\n",
    "\n",
    "config = {\n",
    "    'method': 'random',\n",
    "    'metric':{\n",
    "        'goal': 'minimize',\n",
    "        'name': 'val_loss'},\n",
    "    'parameters': {\n",
    "        #'dropout':{\n",
    "        #    'values': [0.5, 0.4, 0.3]\n",
    "        #},\n",
    "        'weight_decay':{\n",
    "            'values': [1e-5,2e-5, 3e-5,4e-5]\n",
    "        },\n",
    "        'epochs':{\n",
    "            'value': 120\n",
    "        },\n",
    "        'lin_layer_size': {\n",
    "            'values': [100] #, 150, 50\n",
    "        },\n",
    "        'first_lin_lay':{\n",
    "            'values':[248832]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam']\n",
    "        },\n",
    "            'learning_rate': {\n",
    "                # a flat distribution between 0 and 0.1\n",
    "                'distribution': 'log_uniform_values',\n",
    "                'min': 1e-6,\n",
    "                'max': 1e-3\n",
    "            },\n",
    "        'loss_fn': {\n",
    "            'values': ['CrossEntropy'] #'MSE', \n",
    "        },\n",
    "        'data_set':{\n",
    "            'values':['Augmented']\n",
    "        },\n",
    "            'scheduler': {\n",
    "            'values': [0.2, 0.3, 0.4, 0.6]\n",
    "        },\n",
    "        'ks': {\n",
    "            'values': [(3,5)]\n",
    "        },\n",
    "        'dropout':{\n",
    "            'values': [0.5, 0.4, 0.3]\n",
    "        },\n",
    "        'channels':{\n",
    "            'values': [3]\n",
    "        },\n",
    "        'num_classes': {\n",
    "            'values': [10]\n",
    "        },\n",
    "        'model_name' : {'values': ['resnet_mlp']},\n",
    "        'channels' : {'values': [3]},\n",
    "        'image_path': {\n",
    "            'values': [r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/']\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IDSW_resnet_fine_mnisttest_122023'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dict['Run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squeeze(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Squeeze, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        x = x.squeeze(0)\n",
    "        x = x.squeeze(1)\n",
    "        x = x.squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"config = dict(\n",
    "    epochs= 80, #30, \n",
    "    learning_rate =1e-6,\n",
    "    architecture ='CNN',\n",
    "    optimizer= 'adam',\n",
    "    weight_decay= 4e-5,\n",
    "    ks = (3,5),\n",
    "    scheduler=0.2,\n",
    "    f_lin_lay = 7168 #1024*7 = 7168\n",
    ")\"\"\"\n",
    "\n",
    "run_title = \"IDSW_resnet_fine_cifar10_122023\"\n",
    "\n",
    "config = {\n",
    "    'method': 'random',\n",
    "    'metric':{\n",
    "        'goal': 'minimize',\n",
    "        'name': 'val_loss'},\n",
    "    'parameters': {\n",
    "        #'dropout':{\n",
    "        #    'values': [0.5, 0.4, 0.3]\n",
    "        #},\n",
    "\n",
    "        'epochs':{\n",
    "            'value': 2\n",
    "        },\n",
    "\n",
    "        'first_lin_lay':{\n",
    "            'values':[248832]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam']\n",
    "        },\n",
    "            'learning_rate': {\n",
    "                # a flat distribution between 0 and 0.1\n",
    "                'distribution': 'log_uniform_values',\n",
    "                'min': 1e-7,\n",
    "                'max': 1e-2\n",
    "            },\n",
    "        'loss_fn': {\n",
    "            'values': ['CrossEntropy', 'MSE'] #'MSE', \n",
    "        },\n",
    "        'data_set':{\n",
    "            'values':['Augmented']\n",
    "        },\n",
    "            'scheduler': {\n",
    "            'values': [0.1, 0.01, 0.001]\n",
    "        },\n",
    "        'ks': {\n",
    "            'values': [(3,5)]\n",
    "        },\n",
    "\n",
    "        'channels':{\n",
    "            'values': [3]\n",
    "        },\n",
    "        'num_classes': {\n",
    "            'values': [10]\n",
    "        },\n",
    "        'model_name' : {'values': ['resnet_fine']},\n",
    "        'channels' : {'values': [3]},\n",
    "        'image_path': {\n",
    "            'values': [r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/']\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wandb login 2bf372d1273e4af99733e10529509d9b252efe88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 366u2jd1\n",
      "Sweep URL: https://wandb.ai/antvis/IDSW_resnet_fine_cifar10_122023/sweeps/366u2jd1\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(config, project=f\"{run_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(model):\n",
    "\n",
    "    #### This function, used specifically for the visualisation of gradient flow, was found in the following stackoverflow thread: https://stackoverflow.com/questions/70394788/pytorch-adam-optimizer-dramatically-cuts-gradient-flow-compared-to-sgd\n",
    "    model = model.to('cpu')\n",
    "    named_parameters = model.named_parameters()\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        #print(n,p)\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            #print('gradddssss', p.grad)\n",
    "            #print('p: ', p)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom = -0.001, top=1) #  top=0.02) # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    model = model.to('gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "from functions import ImageProcessor\n",
    "\n",
    "IP= ImageProcessor(device)\n",
    "\n",
    "def preprocessMNIST():\n",
    "    #load data\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_val,y_train,  y_val = train_test_split(x_train, y_train, test_size=0.2, shuffle=True)\n",
    "    #print(x_train.shape,x_test.shape, x_val.shape)\n",
    "    #print(len(x_train))\n",
    "    #print('1')\n",
    "    #IP.view(x_train[0],5)\n",
    "\n",
    "\n",
    "    def convert(data): # convert greyscale image to a 3d gray image\n",
    "        data_list = []\n",
    "        for i in data:\n",
    "            i = cv2.resize(i, (48,48))\n",
    "            i = cv2.cvtColor(i, cv2.COLOR_GRAY2BGR)\n",
    "            #print(type(i))\n",
    "            data_list.append(i)\n",
    "        data = np.array(data_list)\n",
    "        return data\n",
    "\n",
    "\n",
    "    x_train = convert(x_train)\n",
    "    x_val = convert(x_val)\n",
    "    x_test = convert(x_test)\n",
    "    #print('post convert',x_train[0].shape)\n",
    "    \n",
    "    # normalise pixel vals\n",
    "    x_train = [i/ 255 for i in x_train]\n",
    "    x_test = [i/ 255 for i in x_test]\n",
    "    x_val = [i/ 255 for i in x_val]\n",
    "    \n",
    "    # ensure array\n",
    "    x_train= np.array(x_train)\n",
    "    x_test= np.array(x_test)\n",
    "    x_val= np.array(x_val)\n",
    "    #print(type(x_train))\n",
    "    #print('norm \\n', x_train[0].shape, type(x_train),'\\n', len(x_train))\n",
    "    #IP.view(x_train[0],5)\n",
    "\n",
    "    # convert to float 32\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_val = x_val.astype('float32')\n",
    "    #print('flaot', x_train.shape, type(x_train), '\\n')\n",
    "    #IP.view(x_train[0],5)\n",
    "    return x_train,y_train, x_val, y_val,  x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render progress bar, see the user log for details\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\n",
      "Exception in thread Thread-8 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1192, in __iter__\n",
      "    self.update(n - last_print_n)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1243, in update\n",
      "    self.refresh(lock_args=self.lock_args)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1348, in refresh\n",
      "    self.display()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1495, in display\n",
      "    self.moveto(pos)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1444, in moveto\n",
      "    self.fp.write('\\n' * n + _term_move_up() * -n)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/utils.py\", line 195, in inner\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/lib/redirect.py\", line 640, in write\n",
      "    self._old_write(data)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 662, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 559, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 266, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3089746/2750901999.py\", line 6, in tr\n",
      "  File \"/tmp/ipykernel_3089746/1629366966.py\", line 27, in pipeline\n",
      "  File \"/tmp/ipykernel_3089746/3700447817.py\", line 43, in train_model\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1197, in __iter__\n",
      "    self.close()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1303, in close\n",
      "    self.display(pos=0)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1496, in display\n",
      "    self.sp(self.__str__() if msg is None else msg)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 462, in print_status\n",
      "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 456, in fp_write\n",
      "    fp_flush()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/utils.py\", line 195, in inner\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 573, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 266, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py\", line 113, in update\n",
      "    self._progress.value = value\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/traitlets/traitlets.py\", line 718, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/traitlets/traitlets.py\", line 707, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/traitlets/traitlets.py\", line 1515, in _notify_trait\n",
      "    self.notify_change(\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 700, in notify_change\n",
      "    self.send_state(key=name)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 586, in send_state\n",
      "    self._send(msg, buffers=buffers)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 825, in _send\n",
      "    self.comm.send(data=msg, buffers=buffers)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/comm/base_comm.py\", line 141, in send\n",
      "    self.publish_msg(\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/comm/comm.py\", line 37, in publish_msg\n",
      "    self.kernel.session.send(\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/jupyter_client/session.py\", line 863, in send\n",
      "    stream.send_multipart(to_send, copy=copy)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 345, in send_multipart\n",
      "    return self.io_thread.send_multipart(*args, **kwargs)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 275, in send_multipart\n",
      "    self.schedule(lambda: self._really_send(*args, **kwargs))\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 266, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2211, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2451, in _on_finish\n",
      "    _ = exit_handle.wait(timeout=-1, on_progress=self._on_progress_exit)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 303, in wait\n",
      "    on_progress(progress_handle)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2430, in _on_progress_exit\n",
      "    self._footer_file_pusher_status_info(\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3571, in _footer_file_pusher_status_info\n",
      "    Run._footer_single_run_file_pusher_status_info(\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3622, in _footer_single_run_file_pusher_status_info\n",
      "    printer.progress_update(line, percent_done)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/lib/printer.py\", line 288, in progress_update\n",
      "    self._progress.update(percent_done, text)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py\", line 121, in update\n",
      "    wandb.termwarn(\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/errors/term.py\", line 50, in termwarn\n",
      "    _log(\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/errors/term.py\", line 95, in _log\n",
      "    click.echo(line, file=sys.stderr, nl=newline)\n",
      "  File \"/usr/lib/python3/dist-packages/click/utils.py\", line 298, in echo\n",
      "    file.write(out)  # type: ignore\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 662, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 559, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 266, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_3089746/2750901999.py\", line 4, in tr\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3280, in __exit__\n",
      "    self._finish(exit_code=exit_code)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1968, in _finish\n",
      "    self._atexit_cleanup(exit_code=exit_code)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2224, in _atexit_cleanup\n",
      "    wandb.termerror(\"Problem finishing run\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/errors/term.py\", line 61, in termerror\n",
      "    _log(\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/errors/term.py\", line 95, in _log\n",
      "    click.echo(line, file=sys.stderr, nl=newline)\n",
      "  File \"/usr/lib/python3/dist-packages/click/utils.py\", line 299, in echo\n",
      "    file.flush()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 573, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 266, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 4013, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1953, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1966, in _finish\n",
      "    hook.call()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 460, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n",
      "Exception in threading.excepthook:\n",
      "Exception ignored in thread started by: <bound method Thread._bootstrap of <Thread(Thread-8 (_run_job), stopped 140150306879040)>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1018, in _bootstrap_inner\n",
      "    self._invoke_excepthook(self)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1336, in invoke_excepthook\n",
      "    local_print(\"Exception in threading.excepthook:\",\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 573, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 266, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 573, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 266, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train_model(model,  x_train, x_val, y_train, y_val, config, best_acc=0): #train_dl, val_dl, \n",
    "    #wandb.watch(model, log='all', log_freq=10)\n",
    "    print(config)\n",
    "    loss_fn = set_lossfn(config['loss_fn']) # ****\n",
    "    \n",
    "    lr = config['learning_rate'] #1e-5 #config.learning_rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)#build_optimizer(model, optimizer=torch.optim.Adam(model.parameters(), lr=lr))#config.optimizer, config.learning_rate, config.weight_decay)\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=config['scheduler'], last_epoch=-1) #gamma=config.scheduler, last_epoch=-1)\n",
    "    \n",
    "    ####\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    #losses= []\n",
    "    #predictions = []\n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "    \n",
    "    total_epochs = 0\n",
    "    for epoch in tqdm(range(config['epochs'])): #config.epochs)):\n",
    "        print('E   ', epoch)\n",
    "        t_correct = 0\n",
    "        v_correct = 0\n",
    "    \n",
    "        if epoch == 0:\n",
    "            model = model.to('cpu')\n",
    "            best_model = deepcopy(model)\n",
    "            model = model.to(device)\n",
    "            \n",
    "            \n",
    "        #train_ids = random.shuffle(train_ids)\n",
    "        #print(type(train_ids))\n",
    "        print('training...')\n",
    "        for idx, img in enumerate(x_train): \n",
    "            model.train()\n",
    "\n",
    "            x = preprocess_im(img)\n",
    "\n",
    "            train_prediction = model.forward(x)\n",
    "            \n",
    "            y = label_oh_tf(y_train[idx], device=device, num_classes=10) # use same index val to index y (labels) and turn into onehot encoded label\n",
    "\n",
    "            \"\"\"\n",
    "            if idx % 1000 == 0:\n",
    "                print(idx, ' / ', len(x_train))\n",
    "                !nvidia-smi\n",
    "            \"\"\"\n",
    "            #print(train_prediction, train_label)\n",
    "        \n",
    "        \n",
    "            t_loss = loss_fn(train_prediction, y)\n",
    "\n",
    "            if train_prediction.argmax() == y.argmax():\n",
    "                t_correct+=1\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            t_loss.backward()\n",
    "            if epoch == config['epochs']-1:\n",
    "                plot_grad_flow(model)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            t_loss_list.append(t_loss.to('cpu'))\n",
    "            t_predict_list.append(train_prediction.to('cpu'))\n",
    "            t_label_list.append(y.to('cpu'))\n",
    "            \n",
    "            train_acc = (t_correct / len(x_train))\n",
    "        t_accuracy_list.append(train_acc)\n",
    "            \n",
    "            # accuracy at every step. every epoch / by x_train\n",
    "            \n",
    "        print('validating...')\n",
    "        \n",
    "        for idx, img in enumerate(x_val):\n",
    "            model.eval()\n",
    "            x = preprocess_im(img)\n",
    "\n",
    "            val_prediction = model.forward(x)\n",
    "            \n",
    "            y = label_oh_tf(y_val[idx], device=device, num_classes=10)\n",
    "            \"\"\"\n",
    "            if idx % 100 == 0:\n",
    "                print(idx, ' / ', len(x_val))\n",
    "                !nvidia-smi\n",
    "            \"\"\"\n",
    "\n",
    "            v_loss = loss_fn(val_prediction, y)\n",
    "            \n",
    "            if val_prediction.argmax() == y.argmax():\n",
    "                v_correct +=1\n",
    "                \n",
    "\n",
    "            v_loss = v_loss.to('cpu')\n",
    "            v_loss_list.append(v_loss.item())\n",
    "            \n",
    "            \n",
    "            val_prediction = val_prediction.to('cpu')\n",
    "            v_predict_list.append(val_prediction.detach().numpy())\n",
    "            \n",
    "            v_label_list.append(y.to('cpu').detach().numpy())\n",
    "            \n",
    "        val_acc = (v_correct / len(y_val))\n",
    "        v_accuracy_list.append(val_acc)\n",
    "            \n",
    "        total_epochs += epoch\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "    \n",
    "            #print('Start Of SAve -----------------------------')\n",
    "            #!nvidia-smi\n",
    "\n",
    "            best_acc = val_acc\n",
    "            \n",
    "            model = model.to('cpu')\n",
    "            best_model = model#deepcopy(model)\n",
    "            model = model.to(device)\n",
    "            \n",
    "\n",
    "            \n",
    "            save_dict['Current_Epoch'] += config['epochs']\n",
    "            save_dict['training_samples'] = len(x_train)\n",
    "            save_dict['validation_samples'] = len(x_val)\n",
    "            save_dict['t_loss_list'] = t_loss_list\n",
    "            save_dict['t_predict_list'] = t_predict_list  \n",
    "            save_dict['t_accuracy_list'] = t_accuracy_list  #\n",
    "            save_dict['v_loss_list'] = v_loss_list\n",
    "            save_dict['v_predict_list'] = v_predict_list  #\n",
    "            save_dict['v_accuracy_list'] = v_accuracy_list  #\n",
    "            save_dict['t_labels'] = t_label_list\n",
    "            save_dict['v_labels'] = v_label_list\n",
    "            \n",
    "            \"\"\"model_architecture = [nn.Sequential(\n",
    "                            model_vgg16,\n",
    "                            Squeeze(),\n",
    "                            nn.Linear(4096,10),\n",
    "                            nn.Softmax(dim=0),\n",
    "                        )]\"\"\"\n",
    "\n",
    "            save_dict['model.state_dict'] = model.state_dict()# .to('cpu')\n",
    "            #save_dict['model_architecture_untrained'] = model_architecture\n",
    "\n",
    "            title = save_dict['Run']\n",
    "            with open(f'{save_location}{title}.pkl', 'wb+') as f:\n",
    "                pickle.dump(save_dict, f)\n",
    "            \n",
    "            print('improvment in metrics. model saved')\n",
    "\n",
    "            #print('END Of SAve -----------------------------')\n",
    "            #!nvidia-smi\n",
    "\n",
    "        \n",
    "\n",
    "        if (epoch+1)%2==0:\n",
    "            train_log(t_loss, v_loss, epoch)\n",
    "            wandb.log({'train_accuracy_%': train_acc, 'epoch':epoch})\n",
    "            wandb.log({'val_accuracy_%': val_acc, 'epoch':epoch})\n",
    "            \n",
    "    model = best_model\n",
    "    #labels = zip(t_label_list, v_label_list)\n",
    "    #losses = zip(t_loss_list, v_loss_list)\n",
    "    #predictions = zip(t_predict_list, v_predict_list)\n",
    "    return model,save_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nx, y, _,_,_,_ = preprocessMNIST()\\n\\nt = x[0]\\nprint(t.shape, type(t))\\n\\n#IP = ImageProcessor(device)\\n#if type(x[5]) == np.ndarray:\\n#    print('array')\\n#IP.view(t, 5)\\nprint('4')\\n#t = np.reshape(t, (48,48,3))\\nprint('t')\\nplt.imshow(t)\\nplt.show()\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "x, y, _,_,_,_ = preprocessMNIST()\n",
    "\n",
    "t = x[0]\n",
    "print(t.shape, type(t))\n",
    "\n",
    "#IP = ImageProcessor(device)\n",
    "#if type(x[5]) == np.ndarray:\n",
    "#    print('array')\n",
    "#IP.view(t, 5)\n",
    "print('4')\n",
    "#t = np.reshape(t, (48,48,3))\n",
    "print('t')\n",
    "plt.imshow(t)\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with wandb.init(project=title, config=config):\\n    config = wandb.config\\n    model = resnet\\n\\n    model, save_dict = train_model(model,x_train, x_val, y_train, y_val, config) #train_dl, val_dl\"\"\\n\\nreturn model, save_dict'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        print(x.shape)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def pipeline(config): \n",
    "    \n",
    "    resnet = nn.Sequential(\n",
    "            #nn.Conv2d(1, 64,3),\n",
    "            newmodel,\n",
    "            Squeeze(),\n",
    "            nn.Linear(2048,10), #2048\n",
    "            nn.Softmax(dim=0),\n",
    "        )\n",
    "    \n",
    "    resnet.to(device)\n",
    "    model=resnet\n",
    "    loss_list=[]\n",
    "    x_train,y_train, x_val, y_val,  x_test, y_test = preprocessMNIST()\n",
    "    \n",
    "\n",
    "    model, save_dict = train_model(model,x_train, x_val, y_train, y_val, config) #train_dl, val_dl\"\"\n",
    "\n",
    "    return model, save_dict\n",
    "\n",
    "\"\"\"with wandb.init(project=title, config=config):\n",
    "    config = wandb.config\n",
    "    model = resnet\n",
    "\n",
    "    model, save_dict = train_model(model,x_train, x_val, y_train, y_val, config) #train_dl, val_dl\"\"\n",
    "\n",
    "return model, save_dict\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model, save_dict = pipeline(config['loss_fn'])\n",
    "\n",
    "def tr(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        model, save_dict = pipeline(config)\n",
    "        \n",
    "\n",
    "wandb.agent(sweep_id, tr, count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#model,save_dict = pipeline(config) #7,168\\n\\ndef tr(config=None):\\n    print(\\'1\\')\\n    with wandb.init(config=config):\\n        print(\\'2\\')\\n        config = wandb.config\\n        print(\\'3\\')\\n        model, save_dict = pipeline(config)\\n        \\nsweep_id = wandb.sweep(config, project=f\"{run_title}\"),\\n#wandb.agent(sweep_id, tr, count=20)'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#model,save_dict = pipeline(config) #7,168\n",
    "\n",
    "def tr(config=None):\n",
    "    print('1')\n",
    "    with wandb.init(config=config):\n",
    "        print('2')\n",
    "        config = wandb.config\n",
    "        print('3')\n",
    "        model, save_dict = pipeline(config)\n",
    "        \n",
    "sweep_id = wandb.sweep(config, project=f\"{run_title}\"),\n",
    "#wandb.agent(sweep_id, tr, count=20)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "797it [00:25, 12.47it/s]\u001b[A\n",
      "800it [00:25, 14.22it/s]\u001b[A\n",
      "803it [00:25, 15.90it/s]\u001b[A\n",
      "806it [00:26, 17.62it/s]\u001b[A\n",
      "809it [00:26, 19.83it/s]\u001b[A\n",
      "812it [00:26, 21.08it/s]\u001b[A\n",
      "815it [00:26, 22.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec  7 16:44:52 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:17:00.0  On |                  Off |\n",
      "| 50%   63C    P2             235W / 450W |  14432MiB / 24564MiB |     67%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        On  | 00000000:4E:00.0 Off |                  Off |\n",
      "| 30%   47C    P2             161W / 450W |  12934MiB / 24564MiB |     65%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   3028376      C   /usr/bin/python3                           8630MiB |\n",
      "|    0   N/A  N/A   3089746      C   /usr/bin/python3                            382MiB |\n",
      "|    0   N/A  N/A   3092626      C   /usr/bin/python3                           1342MiB |\n",
      "|    0   N/A  N/A   3092906      C   /usr/bin/python3                            624MiB |\n",
      "|    0   N/A  N/A   3093110      C   /usr/bin/python3                            694MiB |\n",
      "|    0   N/A  N/A   3171898      C   /usr/bin/python3                           2732MiB |\n",
      "|    1   N/A  N/A   1431183      C   /usr/bin/python3                           1482MiB |\n",
      "|    1   N/A  N/A   3028376      C   /usr/bin/python3                           3632MiB |\n",
      "|    1   N/A  N/A   3070485      C   /usr/bin/python3                           1374MiB |\n",
      "|    1   N/A  N/A   3071034      C   /usr/bin/python3                           4654MiB |\n",
      "|    1   N/A  N/A   3089746      C   /usr/bin/python3                           1766MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "818it [00:26, 23.37it/s]\u001b[A\n",
      "821it [00:26, 23.22it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "\n",
    "def plot_confusion(predictions:list, actual:list, title:str):\n",
    "    predict_list = [int(t.argmax()) for t in predictions]\n",
    "    actual = [int(l.argmax()) for l in actual]\n",
    "\n",
    "    actual = np.array(actual)\n",
    "    predict_list = np.array(predict_list)\n",
    "\n",
    "\n",
    "    #FixedLocator locations (3), usually from a call to set_ticks, does not match the number of labels (11).\n",
    "    print(f'\\n     {title}')\n",
    "    train_epoch_matrix = confusion_matrix(actual, predict_list, labels= [0,1,2,3,4,5,6,7,8,9,10])\n",
    "    disp= ConfusionMatrixDisplay(train_epoch_matrix, display_labels=[0,1,2,3,4,5,6,7,8,9,10])\n",
    "    disp.plot()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'t_predict_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t_predict \u001b[38;5;241m=\u001b[39m \u001b[43msave_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt_predict_list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m t_labels \u001b[38;5;241m=\u001b[39m save_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_labels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m v_predict \u001b[38;5;241m=\u001b[39m save_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv_predict_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# WHY IS THERE NOTHING IN V OREDICT LIST!\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 't_predict_list'"
     ]
    }
   ],
   "source": [
    "t_predict = save_dict['t_predict_list']\n",
    "t_labels = save_dict['t_labels']\n",
    "\n",
    "v_predict = save_dict['v_predict_list'] # WHY IS THERE NOTHING IN V OREDICT LIST!\n",
    "v_labels = save_dict['v_labels']\n",
    "\n",
    "plot_confusion(t_predict, t_labels, 'Train Confusion Matrix')\n",
    "plot_confusion(v_predict, v_labels, 'Validation Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model =nn.Sequential(\n",
    "    PrintLayer(),\n",
    "    model_vgg16,\n",
    "    PrintLayer(),\n",
    "    Squeeze(),\n",
    "    PrintLayer(),\n",
    "    nn.Linear(2048,11),\n",
    "    PrintLayer(),\n",
    "    nn.Softmax(dim=0),\n",
    "    PrintLayer()\n",
    "\n",
    ").to(device)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = preprocess_im(x_train[0])\n",
    "\n",
    "\n",
    "train_prediction = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "824it [00:26, 21.47it/s]\u001b[A\n",
      "827it [00:26, 22.86it/s]\u001b[A\n",
      "830it [00:27, 23.78it/s]\u001b[A\n",
      "833it [00:27, 24.38it/s]\u001b[A\n",
      "836it [00:27, 24.57it/s]\u001b[A\n",
      "839it [00:27, 24.34it/s]\u001b[A\n",
      "842it [00:27, 24.95it/s]\u001b[A\n",
      "845it [00:27, 24.79it/s]\u001b[A\n",
      "848it [00:27, 25.15it/s]\u001b[A\n",
      "851it [00:27, 25.76it/s]\u001b[A\n",
      "854it [00:27, 25.32it/s]\u001b[A\n",
      "857it [00:28, 25.21it/s]\u001b[A\n",
      "860it [00:28, 25.13it/s]\u001b[A\n",
      "863it [00:28, 25.98it/s]\u001b[A\n",
      "866it [00:28, 26.57it/s]\u001b[A\n",
      "869it [00:28, 26.33it/s]\u001b[A\n",
      "872it [00:28, 26.59it/s]\u001b[A\n",
      "875it [00:28, 26.27it/s]\u001b[A\n",
      "878it [00:28, 25.64it/s]\u001b[A\n",
      "881it [00:28, 26.52it/s]\u001b[A\n",
      "884it [00:29, 26.93it/s]\u001b[A\n",
      "887it [00:29, 27.15it/s]\u001b[A\n",
      "890it [00:29, 27.00it/s]\u001b[A\n",
      "893it [00:29, 26.59it/s]\u001b[A\n",
      "896it [00:29, 26.40it/s]\u001b[A\n",
      "899it [00:29, 26.50it/s]\u001b[A\n",
      "902it [00:29, 26.10it/s]\u001b[A\n",
      "905it [00:29, 25.08it/s]\u001b[A\n",
      "908it [00:30, 26.08it/s]\u001b[A\n",
      "911it [00:30, 26.09it/s]\u001b[A\n",
      "914it [00:30, 25.81it/s]\u001b[A\n",
      "917it [00:30, 26.58it/s]\u001b[A\n",
      "920it [00:30, 27.32it/s]\u001b[A\n",
      "923it [00:30, 26.79it/s]\u001b[A\n",
      "926it [00:30, 26.17it/s]\u001b[A\n",
      "929it [00:30, 25.21it/s]\u001b[A\n",
      "932it [00:30, 24.38it/s]\u001b[A\n",
      "935it [00:31, 25.24it/s]\u001b[A\n",
      "938it [00:31, 25.34it/s]\u001b[A\n",
      "941it [00:31, 25.88it/s]\u001b[A\n",
      "944it [00:31, 25.72it/s]\u001b[A\n",
      "947it [00:31, 25.89it/s]\u001b[A\n",
      "950it [00:31, 25.99it/s]\u001b[A\n",
      "953it [00:31, 26.02it/s]\u001b[A\n",
      "956it [00:31, 25.13it/s]\u001b[A\n",
      "959it [00:31, 25.74it/s]\u001b[A\n",
      "962it [00:32, 25.34it/s]\u001b[A\n",
      "965it [00:32, 25.65it/s]\u001b[A\n",
      "968it [00:32, 25.31it/s]\u001b[A\n",
      "971it [00:32, 25.87it/s]\u001b[A\n",
      "974it [00:32, 25.02it/s]\u001b[A\n",
      "977it [00:32, 25.60it/s]\u001b[A\n",
      "980it [00:32, 26.45it/s]\u001b[A\n",
      "983it [00:32, 26.55it/s]\u001b[A\n",
      "986it [00:33, 26.64it/s]\u001b[A\n",
      "989it [00:33, 26.84it/s]\u001b[A\n",
      "992it [00:33, 26.34it/s]\u001b[A\n",
      "995it [00:33, 25.79it/s]\u001b[A\n",
      "998it [00:33, 26.68it/s]\u001b[A\n",
      "1001it [00:33, 26.77it/s]\u001b[A\n",
      "1004it [00:33, 26.47it/s]\u001b[A\n",
      "1007it [00:33, 26.02it/s]\u001b[A\n",
      "1010it [00:33, 25.74it/s]\u001b[A\n",
      "1013it [00:34, 25.72it/s]\u001b[A\n",
      "1016it [00:34, 25.70it/s]\u001b[A\n",
      "  0%| | 0/2 [00:3Exception ignored in: <generator object tqdm.__iter__ at 0x7f774b451a80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1197, in __iter__\n",
      "    self.close()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1303, in close\n",
      "    self.display(pos=0)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1496, in display\n",
      "    self.sp(self.__str__() if msg is None else msg)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 462, in print_status\n",
      "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 456, in fp_write\n",
      "    fp_flush()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/utils.py\", line 195, in inner\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 573, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 266, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 573, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 266, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Traceback (most recent call last):\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1192, in __iter__\n",
      "    self.update(n - last_print_n)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1243, in update\n",
      "    self.refresh(lock_args=self.lock_args)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1348, in refresh\n",
      "    self.display()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1495, in display\n",
      "    self.moveto(pos)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1444, in moveto\n",
      "    self.fp.write('\\n' * n + _term_move_up() * -n)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/utils.py\", line 195, in inner\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/sdk/lib/redirect.py\", line 640, in write\n",
      "    self._old_write(data)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 662, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 559, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 266, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3089746/2750901999.py\", line 6, in tr\n",
      "    model, save_dict = pipeline(config)\n",
      "  File \"/tmp/ipykernel_3089746/1629366966.py\", line 27, in pipeline\n",
      "    model, save_dict = train_model(model,x_train, x_val, y_train, y_val, config) #train_dl, val_dl\"\"\n",
      "  File \"/tmp/ipykernel_3089746/3700447817.py\", line 43, in train_model\n",
      "    for idx, img in tqdm(enumerate(x_train)):\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1197, in __iter__\n",
      "    self.close()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1303, in close\n",
      "    self.display(pos=0)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1496, in display\n",
      "    self.sp(self.__str__() if msg is None else msg)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 462, in print_status\n",
      "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/std.py\", line 456, in fp_write\n",
      "    fp_flush()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/tqdm/utils.py\", line 195, in inner\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 573, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/ipykernel/iostream.py\", line 266, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu').state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
