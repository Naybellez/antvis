{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4fd19-5a09-4232-bdc4-42bbef0b6802",
   "metadata": {},
   "source": [
    "last updated 11 03 24\n",
    "\n",
    "This notebook is to get the run times for each model on the highest and lowest resolutions; to estimate an average run time.IG DICITONARY!\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6be64f-3efe-4c20-885c-1333846ffbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a364e97a-adf8-4aa3-aadf-a32df7852d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6dbd95-2129-42b5-b70b-ee9f057b24c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from functions import import_imagedata, ImageProcessor, label_oh_tf, IDSWDataSetLoader2\n",
    "from fns4wandb import  set_lossfn\n",
    "from architectures import sevennet, smallnet1, smallnet2, smallnet3\n",
    "from loop_fns import loop#, loop_batch, test_loop_batch\n",
    "from plotting import learning_curve, accuracy_curve, plot_confusion\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import collections\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6ace79-5b6a-4955-9fd3-52aeaddf0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = torch.cuda.memory_summary(device, abbreviated=False)\n",
    "#pp = pprint.PrettyPrinter(indent=4)\n",
    "#pp.pprint(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c1e605-9a3b-48dc-a38e-8a955bd3c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "_save_location = r'/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/2c2l/'\n",
    "\n",
    "data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "\n",
    "gitHASH = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1481ccd-4d87-4c05-84d5-77e29ee981b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaughticalnonsence\u001b[0m (\u001b[33mantvis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49eb7e06-506f-48e6-b28c-8caa7641b11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install datetime\n",
    "\n",
    "d = date.today()\n",
    "#print(str(d), type(str(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87383b",
   "metadata": {},
   "source": [
    "452 144               5/452 *100 = 1%\n",
    "226 72                5/226 *100 = 2%\n",
    "113 36                5/113 *100 = 4% -- 2/113 *100= 1.7% ~ 2%\n",
    "57  18   (56.5,)      5/57 *100  = 8% -- 2/57 *100 = 3.5% ~ 4%.   1/57 = 1.75%\n",
    "29   9   (28.5,)      5/29 *100  = 17% -- 2/29 *100 = 6.89 ~ 7%   1/28 = 3.57 ~ 4%\n",
    "15   5   (14.5, 4.5)\n",
    "8    3   (7.5,2.5)\n",
    "4,   2   (, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87dc8393-e7da-43eb-b0e7-b11c4a46c8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def save2csv_nest_dict(nested_dict, file_name, save_location:str):\n",
    "  # flattern nested dictionary\n",
    "  flatterend_dict = {}\n",
    "  for k,v in nested_dict.items():\n",
    "    if isinstance(v, dict):\n",
    "      for nested_key, nested_val in v.items():\n",
    "        flatterend_dict[f\"{k}_{nested_key}\"] = nested_val\n",
    "    else:\n",
    "      flatterend_dict[k] =v\n",
    "\n",
    "  columns = list(flatterend_dict.keys())\n",
    "\n",
    "  with open(save_location+str(file_name)+'.csv', \"a+\", newline=\"\") as f:\n",
    "      # using dictwriter\n",
    "      writer = csv.DictWriter(f, fieldnames=columns)\n",
    "      # using writeheader function\n",
    "      if f.tell() == 0:\n",
    "        writer.writeheader()\n",
    "      writer.writerow(flatterend_dict)\n",
    "      f.close()\n",
    "\n",
    "# check dictionary values for json and csv\n",
    "\n",
    "def check_obj4np(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: check_obj4np(value) for key, value in obj.items()}\n",
    "    if isinstance(obj,list):\n",
    "        return [check_obj4np(item) for item in obj]\n",
    "    if isinstance(obj,np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# save to json\n",
    "def save2josn_nested_dict(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    with open(save_location+str(file_name)+'.json', 'a+') as f:\n",
    "        f.write(json_obj)\n",
    "        f.close()\n",
    "\n",
    "    \n",
    "#save_location+str(file_name)+'.csv'\n",
    "def save2csv(nested_dict, file_name, save_location:str):\n",
    "    \n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    \n",
    "    columns = list(nested_dict.keys())\n",
    "    path = os.path.join(save_location, file_name +\".csv\")\n",
    "    try:\n",
    "        with open(path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            # using dictwriter\n",
    "            # using writeheader function\n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(nested_dict)\n",
    "            f.close()\n",
    "    except IOError as e:\n",
    "        print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "    except ValueError:\n",
    "              print(\"could not convert to string\")\n",
    "    except:\n",
    "              print(\"unexpected error: \", sys.exc_info()[0])\n",
    "        \n",
    "\n",
    "def save2json(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    #print(nested_dict)\n",
    "    #print(nested_dict.items())\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    #print(json_obj)\n",
    "    path = os.path.join(save_location, file_name+\".json\")\n",
    "    #print(path)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(json_obj)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def read_in_json(file_path, file_name):\n",
    "    path = os.path.join(file_path, 'file_name')\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            #obj = f.read()\n",
    "            dj = json.load(f, object_pairs_hook= collections.OrderedDict) #obj, \n",
    "            #print(dj)\n",
    "    except Exception as e:\n",
    "        print(\"Error decoding Json\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "class Flattern(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flattern, self).__init__()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.flatten()\n",
    "        return x\n",
    "\n",
    "\n",
    "def choose_model(model_name, lin_lay, dropout):\n",
    "\n",
    "    #for model_card in config.model_cards:\n",
    "    #print('\\n choose_model \\n MODEL NAME: ',model_name)\n",
    "\n",
    "    if model_name == '4c3l':\n",
    "        return smallnet1(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '3c2l':\n",
    "        return smallnet2(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks = (3,5), dropout=dropout)\n",
    "    elif model_name == '2c2l':\n",
    "        return smallnet3(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '7c3l':\n",
    "        return sevennet(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == 'vgg16':\n",
    "        model_vgg16 = vgg16(weights=\"IMAGENET1K_V1\")\n",
    "        vgg_feats = model_vgg16.features\n",
    "        vgg_classifier = model_vgg16.classifier\n",
    "        vgg_classifier.pop(6)\n",
    "\n",
    "        vgg = nn.Sequential(\n",
    "            vgg_feats,\n",
    "            Flattern(),\n",
    "            vgg_classifier,\n",
    "            nn.Linear(4096,11),\n",
    "            nn.Softmax(dim=0),\n",
    "            )\n",
    "        return vgg\n",
    "    else:\n",
    "        print('Model Name Not Recognised')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41ddbb49-828b-4de8-a31c-2a576cd736f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries\n",
    "\n",
    "date = date.today()\n",
    "\n",
    "model_card_vgg = {'name': 'vgg', 'model': 'vgg16',\n",
    "                  'f_lin_lay':[4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                            ],\n",
    "                 'idx': 0,\n",
    "                 'dropout':0.2}\n",
    "\n",
    "\n",
    "model_card_7c3l = {'name': '7c3l', 'model': '7c3l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[248832,    # 452 144    # p5\n",
    "                            59904,      # 226 72     # p5\n",
    "                            11264,      # 113  36    # p2\n",
    "                            1536,       # 57 18      # p1\n",
    "                            172032,           # 29  9\n",
    "                            172032,          # 15 5\n",
    "                            172032,         # 8 3\n",
    "                              ], \n",
    "                   'idx': 1,\n",
    "                  'dropout':0.2}\n",
    "\n",
    "\n",
    "\n",
    "model_card_4c3l = {'name': '4c3l', 'model': '4c3l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[539904,    # 452 144    # p5\n",
    "                             141056,    # 226 72     # p5\n",
    "                             304640,     # 113  36    # p2\n",
    "                             9984,      # 57 18      # p1\n",
    "                             2304,      # 29  9\n",
    "                             512,       # 15 5\n",
    "                             256],      # 8 3\n",
    "                  'idx': 2,\n",
    "                  'dropout':0.2}      \n",
    "\n",
    "model_card_3c2l = {'name': '3c2l', 'model': '3c2l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[1069888,    # 452 144    # p5\n",
    "                             274688,     #226 72      # p5\n",
    "                             68096,      # 113  36    # p2\n",
    "                             17280,      # 57 18      # p1\n",
    "                             3840,       # 29  9\n",
    "                             960,        # 15 5\n",
    "                             256],\n",
    "                  'idx': 3,\n",
    "                  'dropout':0.2}       # 8 3\n",
    "\n",
    "model_card_2c2l = {'name': '2c2l', 'model': '2c2l', 'channels': 3, 'ks': (3,5),\n",
    "                  'f_lin_lay':[5276160,    # 452 144    # p5 # (1x33767424 and 1055232x100) (1x5276160 and 15828480x100)\n",
    "                             267264,     #226 72      # p5\n",
    "                             64512,      # 113  36    # p2\n",
    "                             15552,      # 57 18      # p1\n",
    "                             3072,       # 29  9\n",
    "                             640,        # 15 5\n",
    "                             128],\n",
    "                  'idx': 4,\n",
    "                  'dropout':0.1}       # 8 3\n",
    "\n",
    "resolution_card_452144 = {'resolution':[452,144], 'padding':5, 'index':0}\n",
    "resolution_card_22672 = {'resolution':[226,72], 'padding':5, 'index':1}\n",
    "resolution_card_11336 = {'resolution':[113,36], 'padding':2, 'index':2}\n",
    "resolution_card_5715 = {'resolution':[57,18], 'padding':1, 'index':3}\n",
    "\n",
    "resolution_card_299 = {'resolution':[29,9], 'padding':0, 'index':4} # \n",
    "resolution_card_155 = {'resolution':[15,5], 'padding':0, 'index':5}\n",
    "resolution_card_83 = {'resolution':[8,3], 'padding':0, 'index':6}\n",
    "\n",
    "\n",
    "\n",
    "resolution_cards = [resolution_card_452144, resolution_card_22672, resolution_card_11336, resolution_card_5715,\n",
    "                    resolution_card_299, resolution_card_155, resolution_card_83]#]#\n",
    "#resolution_cards = [resolution_card_11336]\n",
    "\n",
    "#learning_rate_cards = [5e-5, 6e-5, 8e-5]\n",
    "#learning_rate_cards =  [8.21592E-05, 6.62E-05, 6.01E-05, 5.97E-05]\n",
    "learning_rate_cards=  [0.0001]#, 6e-5, 7e-5, 8e-5]\n",
    "#wd_cards = [4e-5, 5e-5, 3.00E-05, 2.00E-05]\n",
    "wd_cards =[0]\n",
    "scheduler_cards = [0]#, 0.1, 0.2]\n",
    "\n",
    "seeds = [8]#,2,3] # 4, 5,6\n",
    "\n",
    "#model_cards =[model_card_vgg, model_card_7c3l, model_card_4c3l, model_card_3c2l, model_card_2c2l]\n",
    "model_cards =[model_card_2c2l]\n",
    "\n",
    "loss_fn_cards = ['MSE'] #,'CrossEntropy' \n",
    "                        \n",
    "config = dict({'parameters': 'parameters for big loop run'})\n",
    "config.update({'model_cards':model_cards})\n",
    "config.update({'resolution_cards':resolution_cards})\n",
    "config.update({'learning_rate_cards':learning_rate_cards})\n",
    "config.update({'wd_cards':wd_cards})\n",
    "config.update({'scheduler_cards':scheduler_cards})\n",
    "config.update({'seeds':seeds})\n",
    "config.update({'loss_fn_cards': loss_fn_cards})\n",
    "\n",
    "\n",
    "#print(model_card_vgg)\n",
    "#print('')\n",
    "#pp.pprint(config) # dictionary of dictionaries of lists and lists of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "495f38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_batch(model, train, val, save_dict, lr, loss_fn, epochs,optimizer, scheduler_value, device): #train_dl, val_dl, \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    print(type(train))\n",
    "    #for t, l in train:\n",
    "    #    print('train_val_batch   trai: ',type(t), type(l))\n",
    "    #    break\n",
    "    #for t, l in val:\n",
    "    #    print('train_val_batch   val:',type(t), type(l))\n",
    "    #    break\n",
    "\n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "\n",
    "    \n",
    "    total_epochs = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        print('Training...')\n",
    "        \n",
    "        \"\"\"\n",
    "        model, X, Y, loss_fn, device, size, pad, num_classes, model_name, av_lum,colour= 'colour', optimizer =None, scheduler= None, train =True\n",
    "        \"\"\"\n",
    "        \n",
    "        t_loss, train_prediction, t_correct, model, optimizer = loop_batch(model, train, loss_fn, device, optimizer =optimizer, scheduler= scheduler_value, train =True) #,   scheduler =scheduler\n",
    "        \n",
    "        t_loss_list.append(t_loss)\n",
    "        t_predict_list.append(train_prediction)\n",
    "        wandb.log({'t_loss':t_loss})\n",
    "\n",
    "        train_acc = (t_correct/len(train)*100)\n",
    "        print('train accuracy: ', train_acc )\n",
    "        t_accuracy_list.append(train_acc)\n",
    "        wandb.log({'train_acc':train_acc})\n",
    "\n",
    "        \n",
    "            \n",
    "        print('validating...')\n",
    "        \n",
    "        v_loss, val_prediction, val_correct= loop_batch(model, val, loss_fn, device, optimizer =None, scheduler= None, train =False)\n",
    "        #\n",
    "        #scheduler.step()\n",
    "        v_loss_list.append(v_loss)\n",
    "        v_predict_list.append(val_prediction)\n",
    "        wandb.log({'v_loss':v_loss})\n",
    "        #wandb.log({'v_predict_list':val_prediction})\n",
    "        #wandb.log({'y_val':list(y_val)})\n",
    "        val_acc = (val_correct/len(val)*100)\n",
    "        v_accuracy_list.append(val_acc)\n",
    "        print('validation accuracy: ', val_acc )\n",
    "        wandb.log({'val_acc':val_acc})\n",
    "\n",
    "        total_epochs += 1\n",
    "        \n",
    "    save_dict['Current_Epoch'] = epochs\n",
    "    save_dict['training_samples'] = len(train)\n",
    "    save_dict['validation_samples'] = len(val)\n",
    "\n",
    "    save_dict['t_accuracy_list'] = t_accuracy_list \n",
    "    save_dict['v_accuracy_list'] = v_accuracy_list  #\n",
    "            \n",
    "    #model = best_model\n",
    "    save_dict['t_loss_list'] = t_loss_list\n",
    "    save_dict['v_loss_list'] = v_loss_list\n",
    "    \n",
    "    save_dict['t_labels'] = y_train\n",
    "    save_dict['v_labels'] = y_val\n",
    "    \n",
    "    save_dict['t_predict_list'] = t_predict_list \n",
    "    save_dict['v_predict_list'] = v_predict_list  #\n",
    "\n",
    "    return model, save_dict\n",
    "\n",
    "def loop_batch(model, data, loss_fn, device, optimizer =None, scheduler= None, train =True):\t# Train and Val loops. Default is train\n",
    "    #for t, l in data:\n",
    "    #    print(\"loop_batch  \",type(t), type(l))\n",
    "    #    break\n",
    "    model = model\n",
    "    total_samples = len(data)\n",
    "    if train:\n",
    "        model.train()\n",
    "        #lr_ls = []\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    predict_list = []\n",
    "    total_count = 0\n",
    "    num_correct = 0\n",
    "    current_loss = 0\n",
    "\n",
    "    #print(model_name)\n",
    "\n",
    "    for x_batch,y_batch  in data:\n",
    "        #print(\"loop_batch_1 \\n\",type(tense), tense.shape,\"\\n\", type(label), label.shape)\n",
    "        x_batch = x_batch.to(device)\n",
    "        print(\"x_batch shape  \",x_batch.shape)\n",
    "        y_batch = y_batch.to(device)\n",
    "        #print(type(tense), type(label))\n",
    "       \n",
    "        prediction = model.forward(x_batch)\n",
    "        #label = label.unsqueeze(1)\n",
    "        #prediction = prediction.unsqueeze(1)\n",
    "        print(\"pred shape  \",prediction.shape)\n",
    "        print(\"lab / y_batch shape  \",y_batch.shape)\n",
    "        loss = loss_fn(prediction, y_batch)\n",
    "        predict_list.append(prediction.argmax())\n",
    "\n",
    "        if prediction.argmax() == y_batch.argmax():\n",
    "            num_correct +=1\n",
    "\n",
    "        total_count+=1\n",
    "        current_loss += loss.item()\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    if train:\n",
    "        return current_loss, predict_list, num_correct, model, optimizer #, lr_ls\n",
    "    else:\n",
    "        return current_loss, predict_list, num_correct\n",
    "\n",
    "\n",
    "def test_loop(model, model_name, X, Y, res, pad, save_dict, loss_fn, device, av_lum, num_classes=11):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    current_loss = 0\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    colour ='colour'\n",
    "    size =  res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print('Testing...') \n",
    "        for idx, img in enumerate(X):\n",
    "\n",
    "            #image pre processing\n",
    "            prepro = ImageProcessor(device)\n",
    "            if model_name == 'vgg16':\n",
    "                tense = prepro.colour_size_tense(img, colour, size, av_lum, pad, vg=True) #[29, 9], 15, 5, [8,3]\n",
    "            elif (model_name == '7c3l' and size == [29, 9]) or (model_name == '7c3l' and size == [15, 5]) or (model_name == '7c3l' and size ==[8, 3]):\n",
    "                tense = prepro.colour_size_tense(img, colour, size, av_lum, pad, vg=True)\n",
    "            else:\n",
    "                tense = prepro.colour_size_tense(img, colour, size,av_lum,  pad)\n",
    "\n",
    "            # send through model\n",
    "            prediction = model.forward(tense)\n",
    "            label = label_oh_tf(Y[idx], num_classes).to(device)\n",
    "            loss = loss_fn(prediction, label)\n",
    "\n",
    "            if prediction.argmax()==label.argmax():\n",
    "                num_correct +=1\n",
    "            total_count +=1\n",
    "            correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "\n",
    "            predict_list.append(prediction.argmax())\n",
    "\n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        current_loss += loss.item()\n",
    "        \n",
    "    return accuracy, predict_list, Y, current_loss\n",
    "\n",
    "##                  model, data, loss_fn, device, optimizer =None, scheduler= None, train =True\n",
    "def test_loop_batch(model,data, loss_fn, device):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for label, tense in enumerate(data):\n",
    "            #tense = tense.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            prediction = model.forward(tense.to(device))\n",
    "            #label = label_oh_tf(Y[idx], device, num_classes)\n",
    "    \n",
    "            if prediction.argmax()==label.argmax():\n",
    "                num_correct +=1\n",
    "            total_count +=1\n",
    "            correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "    \n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "    \n",
    "        X = list(X)\n",
    "        log_test_score(acc, accuracy, X)\n",
    "\n",
    "\n",
    "def get_data(random_seed):\n",
    "    file_path =  data_path\n",
    "    #print(file_path)\n",
    "    img_len = len(os.listdir(file_path))\n",
    "    \n",
    "    x, y = import_imagedata(file_path)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "    \n",
    "def get_lin_lay(model_card, resolution):\n",
    "    if resolution == [452, 144]:\n",
    "        lin_lay = model_card['f_lin_lay'][0]\n",
    "    elif resolution == [226, 72]:\n",
    "        lin_lay = model_card['f_lin_lay'][1]\n",
    "    elif resolution == [113, 36]:\n",
    "        lin_lay = model_card['f_lin_lay'][2]\n",
    "    elif resolution == [57, 18]:\n",
    "        lin_lay = model_card['f_lin_lay'][3]\n",
    "    elif resolution == [29, 9]:\n",
    "        lin_lay = model_card['f_lin_lay'][4]\n",
    "    elif resolution == [15, 5]:\n",
    "        lin_lay = model_card['f_lin_lay'][5]\n",
    "    elif resolution == [8, 3]:\n",
    "        lin_lay = model_card['f_lin_lay'][6]\n",
    "    else:\n",
    "        print(\"PARAMETER NOT FOUND: \\n f_lin_lay FROM MODEL CARD\")\n",
    "    return lin_lay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bf5ca7f-b59a-427b-8da3-2848fa6d3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def _go(config=None):\n",
    "    \n",
    "    if len(gitHASH) <1:\n",
    "        print(\"YOU FORGET THE GIT HASH\")\n",
    "        return\n",
    "    else:\n",
    "        print('Git Hash registered')\n",
    "        \n",
    "    with wandb.init(config=config, project=f\"test Big Loop batching\", notes=\"First logging test of big loop batcing . limitied data\",):\n",
    "        config = wandb.config\n",
    "        start = time.process_time()\n",
    "    \n",
    "        for model_idx, model_card in enumerate(config['model_cards']):\n",
    "            \n",
    "            model_name = model_card['model']\n",
    "            model_index = model_card['idx']\n",
    "            dropout = model_card['dropout'] \n",
    "            \n",
    "            \n",
    "            for res_idx, resolution_card in enumerate(config['resolution_cards']):\n",
    "    \n",
    "                resolution = resolution_card['resolution']\n",
    "                pad = resolution_card['padding']\n",
    "               \n",
    "                lin_lay = get_lin_lay(model_card, resolution)\n",
    "    \n",
    "                \n",
    "                for lr_idx, lr in enumerate(config['learning_rate_cards']):\n",
    "                    for wd_idx, wd_card in enumerate(wd_cards):\n",
    "                        for sched_idx, scheduler_value in enumerate(config['scheduler_cards']):\n",
    "                            for seed_idx, seed in enumerate(config['seeds']):\n",
    "                                seed = seed\n",
    "                                for lossfn_idx, lossfn in enumerate(config['loss_fn_cards']):\n",
    "                                    \n",
    "                                    \n",
    "                                    #print('Model: ', str(model_name), f\" idx: {model_idx} / {len(config.model_cards)}\")\n",
    "                                    #print(config.model_cards, len(config.model_cards), type(config.model_cards))\n",
    "                                    print('Model: ', str(model_name), f\" idx: {model_idx} / {len(config.model_cards)}\")\n",
    "                                    print('resolution: ', str(resolution), f\"  idx: {res_idx} / {len(config['resolution_cards'])}\")\n",
    "                                    print('learning rate: ', str(lr), f\"  idx: {lr_idx} / {len(config['learning_rate_cards'])}\")\n",
    "                                    print('weight decay: ', str(wd_card), f\"  idx: {wd_idx} / {len(config['wd_cards'])}\")\n",
    "                                    print('scheduler: ', str(scheduler_value), f\"  idx: {sched_idx} / {len(config['scheduler_cards'])}\")\n",
    "                                    print('seed: ', str(seed), f\"  idx:  {seed_idx} / {len(config['seeds'])}\")\n",
    "                                    print('loss function: ', str(lossfn), f\" idx: {lossfn_idx} / {len(config['loss_fn_cards'])}\")\n",
    "                                    run_start_time = time.process_time()\n",
    "                                    print(run_start_time)\n",
    "   \n",
    "                                    print(time.process_time() - start)\n",
    "                                    \n",
    "        \n",
    "                                    epochs = 2 #40\n",
    "\n",
    "                                    IP = ImageProcessor(device)\n",
    "\n",
    "                                    print(f\"Total epochs: {epochs}\")\n",
    "                                     \n",
    "                                    wandb.log({'gitHash':gitHASH})\n",
    "                                    wandb.log({'Epochs': epochs})\n",
    "                                    # set save dictionary\n",
    "                                    save_dict = {'Run' : f\"{model_name}_{date}\",\n",
    "                                                 'Current_Epoch': 0,\n",
    "                                                 'save_location' : _save_location}\n",
    "                                    \n",
    "                                    # set model\n",
    "                                    model = choose_model(model_name, lin_lay, dropout).to(device)\n",
    "                                    #print(model, '\\n', type(config))\n",
    "                                    # get image data\n",
    "                                    x_train, y_train, x_val, y_val, x_test, y_test = get_data(seed)\n",
    "                                    av_lum = IP.new_luminance(x_train)\n",
    "                                    \n",
    "                                    train_ds = IDSWDataSetLoader2(x_train, y_train, resolution,pad,av_lum,model_name, device)# av_lum, res,pad,\n",
    "                                    train = DataLoader(train_ds, batch_size=5, shuffle=True, drop_last=True) #, num_workers=2\n",
    "                                    #for i,j in train:\n",
    "                                    #    print(\"_go: \",type(i), type(j))\n",
    "                                    #    break\n",
    "                                    \n",
    "                                    test_ds = IDSWDataSetLoader2(x_test, y_test, resolution,pad,av_lum,model_name, device)\n",
    "                                    test = DataLoader(test_ds, batch_size=5, shuffle=True, drop_last=True) #, num_workers=2\n",
    "                                    \n",
    "                                    val_ds = IDSWDataSetLoader2(x_val, y_val, resolution,pad,av_lum,model_name, device)\n",
    "                                    val = DataLoader(val_ds, batch_size=5, shuffle=True, drop_last=True) #, num_workers=2\n",
    "                                    \n",
    "                                    # set loss function\n",
    "                                    loss_fn = set_lossfn(lossfn)\n",
    "                                    \n",
    "                                    # set optimizer\n",
    "                                    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "                   \n",
    "                                    #scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=scheduler_value, last_epoch=-1) \n",
    "\n",
    "                                    \n",
    "                                    wandb.watch(model, loss_fn, log='all', log_freq=2, idx = model_index)\n",
    "                                    model, save_dict=  train_val_batch(model, train,val, save_dict, lr, loss_fn,epochs, optimizer, scheduler_value, device)\n",
    "\n",
    "                                    #test                                               Y,          \n",
    "                                    test_acc,test_predict_list, y_test, test_loss = test_loop_batch(model,test, loss_fn, device) #model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\n",
    "                                    \n",
    "                                    #print(test_predict_list)\n",
    "                                    print(' \\n train acc: ', save_dict['t_accuracy_list'][-1])\n",
    "                                    print(' \\n val acc: ', save_dict['v_accuracy_list'][-1])\n",
    "                                    print(' \\n test acc: ', test_acc)\n",
    "                                    \n",
    "                                    save_dict.update({'test_acc': test_acc})\n",
    "                                    save_dict.update({'test_predict': test_predict_list})\n",
    "                                    save_dict.update({'test_labels': list(y_test)})\n",
    "                                    save_dict.update({'test_loss':test_loss})\n",
    "\n",
    "                                    loop_run_name = f\"{save_dict['Run']}_{resolution}_{lr}_{scheduler_value}_{seed}_{lossfn}\"\n",
    "\n",
    "\n",
    "                                    learning_curve(save_dict['t_loss_list'], save_dict['v_loss_list'], save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                                    accuracy_curve(save_dict['t_accuracy_list'], save_dict['v_accuracy_list'],save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                                    test_predict_list=[pred.cpu() for pred in test_predict_list]\n",
    "                                    plot_confusion(predictions= test_predict_list, actual= y_test, title = \"Test Confusion matrix\", run_name = loop_run_name,save_location =save_dict['save_location'])\n",
    "                                    \n",
    "                                    wandb.log({'test_acc': test_acc})\n",
    "                                    wandb.log({'test_predict': test_predict_list})\n",
    "                                    wandb.log({'test_labels': list(y_test)})\n",
    "                                    #saving\n",
    "                                    diction = {}\n",
    "                                    d = date.today()\n",
    "                                    d=str(d)\n",
    "                                    diction.update({'Date':d})\n",
    "                                    diction.update({'gitHASH':str(gitHASH)})\n",
    "                                    diction.update({'model_name': str(model_name)})\n",
    "                                    diction.update({'loss_fn': str(lossfn)})\n",
    "                                    diction.update({'lr': str(lr)})\n",
    "                                    diction.update({'wd': str(wd_card)})\n",
    "                                    diction.update({'scheduler value': str(scheduler_value)})\n",
    "                                    diction.update({'seed': str(seed)})\n",
    "                                    diction.update({'resolution': str(resolution)})\n",
    "                                    diction.update({'pad': int(pad)})\n",
    "                                    diction.update({'lin_lay': int(lin_lay)})\n",
    "                                    diction.update({'run time': (time.process_time() - run_start_time)})\n",
    "                                    diction.update(save_dict)\n",
    "                                    \n",
    "                                    save_location = save_dict['save_location']\n",
    "                                    title = save_dict['Run']\n",
    "                                    save2json(diction, title, save_location)\n",
    "                                    save2csv(diction, title, save_location)\n",
    "        \n",
    "                                    diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "        \n",
    "                                    with open(f\"{save_location}{loop_run_name}.pkl\", 'wb+') as f:\n",
    "                                        pickle.dump(diction, f)\n",
    "                                    \n",
    "                                    #clear_output()\n",
    "                                    \n",
    "                                    print(f' \\n END {model_name} {resolution} Run Time: ',time.process_time() - run_start_time)\n",
    "\n",
    "        print('Final Run time:  ',time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b58d7d27-ef9d-43d9-98a8-1f11ff50090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git Hash registered\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/its/home/nn268/antvis/antvis/optics/wandb/run-20240409_105908-8ibkgb47</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antvis/test%20Big%20Loop%20batching/runs/8ibkgb47' target=\"_blank\">twilight-brook-64</a></strong> to <a href='https://wandb.ai/antvis/test%20Big%20Loop%20batching' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antvis/test%20Big%20Loop%20batching' target=\"_blank\">https://wandb.ai/antvis/test%20Big%20Loop%20batching</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antvis/test%20Big%20Loop%20batching/runs/8ibkgb47' target=\"_blank\">https://wandb.ai/antvis/test%20Big%20Loop%20batching/runs/8ibkgb47</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  2c2l  idx: 0 / 1\n",
      "resolution:  [452, 144]   idx: 0 / 7\n",
      "learning rate:  0.0001   idx: 0 / 1\n",
      "weight decay:  0   idx: 0 / 1\n",
      "scheduler:  0   idx: 0 / 1\n",
      "seed:  8   idx:  0 / 1\n",
      "loss function:  MSE  idx: 0 / 1\n",
      "177.413811126\n",
      "0.0012143099999946116\n",
      "Total epochs: 2\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "x_batch shape   torch.Size([5, 3, 144, 462])\n",
      "pred shape   torch.Size([11])\n",
      "lab / y_batch shape   torch.Size([5, 11])\n",
      "x_batch shape   torch.Size([5, 3, 144, 462])\n",
      "pred shape   torch.Size([11])\n",
      "lab / y_batch shape   torch.Size([5, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/nn268/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "/its/home/nn268/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 11])) that is different to the input size (torch.Size([11])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|                                                         | 0/2 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_253240/1407284892.py\", line 96, in _go\n",
      "    model, save_dict=  train_val_batch(model, train,val, save_dict, lr, loss_fn,epochs, optimizer, scheduler_value, device)\n",
      "  File \"/tmp/ipykernel_253240/2843407167.py\", line 33, in train_val_batch\n",
      "    t_loss, train_prediction, t_correct, model, optimizer = loop_batch(model, train, loss_fn, device, optimizer =optimizer, scheduler= scheduler_value, train =True) #,   scheduler =scheduler\n",
      "  File \"/tmp/ipykernel_253240/2843407167.py\", line 123, in loop_batch\n",
      "    loss.backward()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/wandb_torch.py\", line 266, in <lambda>\n",
      "    handle = var.register_hook(lambda grad: _callback(grad, log_track))\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/wandb_torch.py\", line 264, in _callback\n",
      "    self.log_tensor_stats(grad.data, name)\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/wandb/wandb_torch.py\", line 157, in log_tensor_stats\n",
      "    tensor = tensor.detach().clone()\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 23.65 GiB of which 535.50 MiB is free. Process 172936 has 468.00 MiB memory in use. Including non-PyTorch memory, this process has 22.66 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 1.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epochs</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epochs</td><td>2</td></tr><tr><td>gitHash</td><td>test</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-brook-64</strong> at: <a href='https://wandb.ai/antvis/test%20Big%20Loop%20batching/runs/8ibkgb47' target=\"_blank\">https://wandb.ai/antvis/test%20Big%20Loop%20batching/runs/8ibkgb47</a><br/> View job at <a href='https://wandb.ai/antvis/test%20Big%20Loop%20batching/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE1OTcxOTczMA==/version_details/v4' target=\"_blank\">https://wandb.ai/antvis/test%20Big%20Loop%20batching/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE1OTcxOTczMA==/version_details/v4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240409_105908-8ibkgb47/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 23.65 GiB of which 535.50 MiB is free. Process 172936 has 468.00 MiB memory in use. Including non-PyTorch memory, this process has 22.66 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 1.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m_go\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 96\u001b[0m, in \u001b[0;36m_go\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m#scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=scheduler_value, last_epoch=-1) \u001b[39;00m\n\u001b[1;32m     95\u001b[0m wandb\u001b[38;5;241m.\u001b[39mwatch(model, loss_fn, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, log_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, idx \u001b[38;5;241m=\u001b[39m model_index)\n\u001b[0;32m---> 96\u001b[0m model, save_dict\u001b[38;5;241m=\u001b[39m  \u001b[43mtrain_val_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#test                                               Y,          \u001b[39;00m\n\u001b[1;32m     99\u001b[0m test_acc,test_predict_list, y_test, test_loss \u001b[38;5;241m=\u001b[39m test_loop_batch(model,test, loss_fn, device) \u001b[38;5;66;03m#model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 33\u001b[0m, in \u001b[0;36mtrain_val_batch\u001b[0;34m(model, train, val, save_dict, lr, loss_fn, epochs, optimizer, scheduler_value, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03mmodel, X, Y, loss_fn, device, size, pad, num_classes, model_name, av_lum,colour= 'colour', optimizer =None, scheduler= None, train =True\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m t_loss, train_prediction, t_correct, model, optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mloop_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#,   scheduler =scheduler\u001b[39;00m\n\u001b[1;32m     35\u001b[0m t_loss_list\u001b[38;5;241m.\u001b[39mappend(t_loss)\n\u001b[1;32m     36\u001b[0m t_predict_list\u001b[38;5;241m.\u001b[39mappend(train_prediction)\n",
      "Cell \u001b[0;32mIn[19], line 123\u001b[0m, in \u001b[0;36mloop_batch\u001b[0;34m(model, data, loss_fn, device, optimizer, scheduler, train)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[1;32m    122\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 123\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/wandb_torch.py:266\u001b[0m, in \u001b[0;36mTorchHistory._hook_variable_gradient_stats.<locals>.<lambda>\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_tensor_stats(grad\u001b[38;5;241m.\u001b[39mdata, name)\n\u001b[0;32m--> 266\u001b[0m handle \u001b[38;5;241m=\u001b[39m var\u001b[38;5;241m.\u001b[39mregister_hook(\u001b[38;5;28;01mlambda\u001b[39;00m grad: \u001b[43m_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_track\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_handles[name] \u001b[38;5;241m=\u001b[39m handle\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m handle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/wandb_torch.py:264\u001b[0m, in \u001b[0;36mTorchHistory._hook_variable_gradient_stats.<locals>._callback\u001b[0;34m(grad, log_track)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m log_track_update(log_track):\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_tensor_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/wandb_torch.py:157\u001b[0m, in \u001b[0;36mTorchHistory.log_tensor_stats\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m    154\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m tensor \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[1;32m    155\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([t\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tensor])\n\u001b[0;32m--> 157\u001b[0m tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# checking for inheritance from _TensorBase didn't work for some reason\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 23.65 GiB of which 535.50 MiB is free. Process 172936 has 468.00 MiB memory in use. Including non-PyTorch memory, this process has 22.66 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 1.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "_go(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964b31e-4bae-4f65-bc46-ee1334a8f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.04 GiB is free\n",
    "23.65-8.04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59daceaa-fa47-4c76-90d6-f23550f85694",
   "metadata": {},
   "source": [
    "\n",
    "pred   torch.Size([11])\n",
    "\r\n",
    "lab    torch.Size([5, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5d251-dbcc-482b-aac0-ac24617279e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
