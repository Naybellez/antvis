{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as maths\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "#from torchsummary import summary\n",
    "#import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "\n",
    "from functions import Unwrap,  label_oh_tf, loop, import_imagedata, test_loop, get_data\n",
    "from functions import ImageProcessor\n",
    "from architectures import build_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaughticalnonsence\u001b[0m (\u001b[33mantvis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"'distribution': 'log_uniform_values',\n",
    "            'min': 1e-5,\n",
    "            'max': 7e-5\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 36wsgole\n",
      "Sweep URL: https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/sweeps/36wsgole\n"
     ]
    }
   ],
   "source": [
    "# HP sweep\n",
    "\n",
    "config = {\n",
    "    'method': 'random',\n",
    "    'metric':{\n",
    "        'goal': 'minimize',\n",
    "        'name': 'val_loss'},\n",
    "    'parameters': {\n",
    "        'dropout':{\n",
    "            'values': [0.4] #0.5, 0.45, 0.55\n",
    "        },\n",
    "        'weight_decay':{\n",
    "            'values': [4e-5,1e-5] #1e-5,2e-5, 3e-5,1e-4, 1e-6,2e-5, 3e-5\n",
    "        },\n",
    "        'epochs':{\n",
    "            'value': 80\n",
    "        },\n",
    "        'lin_layer_size': {\n",
    "            'values': [100]\n",
    "        },\n",
    "        'first_lin_lay':{\n",
    "            'values':[10240] #1x10240 and 12288x100)\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam']\n",
    "        },\n",
    "        'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'log_uniform_values',\n",
    "        'min': 0.000001,\n",
    "        'max': 0.001\n",
    "        },\n",
    "        'kernal_size': {\n",
    "            'values': [(3,5), (3,4), (4,5)] #,(3,5), (4,5), (4,6)  ### KERNAL SIZE AFFECTS CONV OUTPUT SIZE!\n",
    "        },\n",
    "        'loss_fn': {\n",
    "            'values': ['MSE', 'CrossEntropy']\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(config, project='HPS_basedon_decent-sweep-24_UNwrapped_36113')\n",
    "\n",
    "\n",
    "col_dict={\n",
    "    'colour': 'colour',\n",
    "    'size': [113,36]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# training\n",
    "\n",
    "config = dict(\n",
    "    epochs= 100, \n",
    "    learning_rate =1e-5,\n",
    "    dataset= 'IDSW',\n",
    "    architecture ='CNN',\n",
    "    optimizer= 'adam',\n",
    "    weight_decay= 1e-4\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "col_dict={\n",
    "    'colour': 'colour',\n",
    "    'size': [36,113]\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = get_data()\n",
    "                            # Common functions\n",
    "\n",
    "def build_optimizer(network, optimizer, learning_rate, weight_decay=0):\n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        if weight_decay == 0:\n",
    "            optimizer = torch.optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "        optimizer = torch.optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate, weight_decay=weight_decay)\n",
    "    return optimizer\n",
    "\n",
    "def train_log(t_loss, v_loss, sample_count, epoch):\n",
    "    wandb.log({'epoch': epoch,\n",
    "              't_loss': t_loss,\n",
    "              'v_loss': v_loss},\n",
    "             step=sample_count)\n",
    "    print(f'loss after {str(sample_count).zfill(5)} examples: {v_loss:.3f}')\n",
    "\n",
    "                                # HP Sweep\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        model = build_net(config.lin_layer_size,config.dropout, config.first_lin_lay, config.kernal_size).to(device)\n",
    "        if config.loss_fn == 'MSE':\n",
    "            loss_fn = nn.MSELoss()\n",
    "        elif config.loss_fn == 'CrossEntropy':\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "        e_count = 0\n",
    "        #optimizer = build_optimizer(network, config.optimizer, config.learning_rate, config.weight_decay)\n",
    "        if e_count >= 20:\n",
    "            optimizer = build_optimizer(model, config.optimizer, config.learning_rate, config.weight_decay)\n",
    "        else:\n",
    "            optimizer = build_optimizer(model, config.optimizer, config.learning_rate)\n",
    "        \n",
    "        for epoch in range(config.epochs):\n",
    "\n",
    "            t_loss, predict_list, t_num_correct, model, optimizer = loop(model, x_train, y_train, epoch, loss_fn, device, col_dict, optimizer=optimizer)\n",
    "            \n",
    "            t_accuracy = (t_num_correct /len(x_train))*100\n",
    "            \n",
    "            v_loss, __, v_num_correct= loop(model, x_val, y_val, epoch, loss_fn, device,col_dict, train=False) \n",
    "            \n",
    "            v_accuracy= (v_num_correct / len(x_val))*100\n",
    "            \n",
    "            t_avg_loss =t_loss/len(x_train)\n",
    "            v_avg_loss = v_loss /len(x_val)\n",
    "            \n",
    "            e_count +=1\n",
    "            \n",
    "            wandb.log({'avg_train_loss': t_avg_loss, 'epoch':epoch})\n",
    "            wandb.log({'avg_val_loss': v_avg_loss, 'epoch':epoch})\n",
    "            wandb.log({'train_loss': t_loss, 'epoch':epoch})\n",
    "            wandb.log({'val_loss': v_loss, 'epoch':epoch})\n",
    "            wandb.log({'train_accuracy_%': t_accuracy})\n",
    "            wandb.log({'val_accuracy_%': v_accuracy})\n",
    "\n",
    "                                #Training\n",
    "            \n",
    "def train_model(model, x_train, y_train, x_val, y_val,loss_fn, config):\n",
    "    wandb.watch(model, loss_fn, log='all', log_freq=10)\n",
    "    \n",
    "    sample_count =0\n",
    "    batch_count = 0\n",
    "    e_count = 0\n",
    "    \n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        if e_count >= 20:\n",
    "            optimizer = build_optimizer(model, config.optimizer, config.learning_rate, config.weight_decay)\n",
    "        else:\n",
    "            optimizer = build_optimizer(model, config.optimizer, config.learning_rate)\n",
    "            \n",
    "        #train\n",
    "        t_loss, predict_list, t_num_correct, model, optimizer = loop(model, x_train, y_train, epoch, loss_fn, device, col_dict, optimizer=optimizer)\n",
    "        sample_count += len(x_train)\n",
    "       \n",
    "        # validation\n",
    "        v_loss, __, v_num_correct= loop(model, x_val, y_val, epoch, loss_fn, device,col_dict, train=False) \n",
    "        batch_count +=1\n",
    "        \n",
    "        if (batch_count +1)%25 ==0:\n",
    "            train_log(t_loss,v_loss, sample_count, epoch)\n",
    "        e_count +=1\n",
    "        clear_output()\n",
    "        \n",
    "    \n",
    "if col_dict['size'][0]!= col_dict['size'][1]:\n",
    "    wrap = 'UNwrapped'\n",
    "elif col_dict['size'][0]== col_dict['size'][1]:\n",
    "    wrap = 'Wrapped'\n",
    "\n",
    "def pipeline(hp): \n",
    "    title = f\"{col_dict['colour']}_{wrap}_{col_dict['size']}\"\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = get_data()\n",
    "    \n",
    "    with wandb.init(project=title, config=hp):\n",
    "        config = wandb.config\n",
    "        model = build_net(lin_layer_size=100,dropout=0, first_lin_lay=14336).to(device)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        \n",
    "        train_model(model, x_train, y_train, x_val, y_val,loss_fn, config)\n",
    "        test_loop(model, x_test, y_test, loss_fn, device, col_dict,title, wandb=True)\n",
    "        \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 79/80 [2:11:12<01:31, 91.88s/it]"
     ]
    }
   ],
   "source": [
    "#model = pipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ykh64eg1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_lin_lay: 10240\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernal_size: [3, 5]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008285560907048908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlin_layer_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_fn: MSE\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/its/home/nn268/optics/wandb/run-20231002_161659-ykh64eg1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/runs/ykh64eg1' target=\"_blank\">apricot-sweep-1</a></strong> to <a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/sweeps/36wsgole' target=\"_blank\">https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/sweeps/36wsgole</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113' target=\"_blank\">https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/sweeps/36wsgole' target=\"_blank\">https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/sweeps/36wsgole</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/runs/ykh64eg1' target=\"_blank\">https://wandb.ai/antvis/HPS_basedon_decent-sweep-24_UNwrapped_36113/runs/ykh64eg1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
